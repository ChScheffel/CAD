---
title             : "When easy is not preferred: A discounting paradigm to assess load-independent task preference"
shorttitle        : "The CAD paradigm to assess task preference"
author: 
  - name          : "Josephine Zerna"
    orcid         : "0000-0003-2892-884X"
    affiliation   : "1"
    corresponding : yes
    address       : "Zellescher Weg 17, 01069 Dresden, Germany"
    email         : "josephine.zerna@tu-dresden.de"
    equal_contrib : yes
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - Conceptualization
      - Methodology
      - Funding acquisition
      - Formal analysis
      - Investigation
      - Project administration
      - Software
      - Visualization
      - Writing - original draft preparation
      - Writing - review & editing
  - name          : "Christoph Scheffel"
    orcid         : "0000-0001-5963-9229"
    affiliation   : "1"
    equal_contrib : yes
    role:
      - Conceptualization
      - Methodology
      - Funding acquisition
      - Investigation
      - Project administration
      - Software
      - Writing - review & editing
  - name          : "Corinna Kührt"
    orcid         : "0000-0002-6418-6479"
    affiliation   : "1"
    role:
      - Formal analysis
      - Writing - review & editing
      - Visualization
  - name          : "Alexander Strobel"
    orcid         : "0000-0002-9426-5397"
    affiliation   : "1"
    role: 
      - Conceptualization
      - Funding acquistion
      - Writing - review & editing
affiliation:
  - id            : "1"
    institution   : "Faculty of Psychology, Technische Universität Dresden, 01069 Dresden, Germany"
authornote: |
abstract: |
  When individuals set goals, they consider the subjective value (SV) of the anticipated reward and the required effort, a trade-off that is of great interest to psychological research.
  One approach to quantify the SVs of levels of a cognitive task is the Cognitive Effort Discounting Paradigm by Westbrook and colleagues (2013).
  However, it fails to acknowledge the highly subjective nature of effort, as it assumes a unidirectional, inverse relationship between task load and SVs.
  Therefore, it cannot map differences in effort perception that arise from traits like Need for Cognition, since individuals who enjoy effortful cognitive activities likely do not prefer the easiest level.
  We replicated the analysis of Westbrook and colleagues with our adaptation, the Cognitive and Affective Discounting (CAD) Paradigm, which quantifies SVs without assuming that the easiest level is preferred, thereby enabling the quantification of SVs for tasks without objective order of task load.
  
keywords          : "effort discounting, registered report, specification curve analysis, need for cognition, $n$-back"
wordcount         : "~ 4,300"
bibliography      : CAD.bib
floatsintext      : yes
figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no
documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
csl               : nature.csl
always_allow_html : true
header-includes   :
    - \usepackage{booktabs}
    - \usepackage{longtable}
    - \usepackage{array}
    - \usepackage{multirow}
    - \usepackage{wrapfig}
    - \usepackage{float}
    - \usepackage{colortbl}
    - \usepackage{pdflscape}
    - \usepackage{tabu}
    - \usepackage{threeparttable}
    - \usepackage{threeparttablex}
    - \usepackage[normalem]{ulem}
    - \usepackage{makecell}
    - \usepackage{xcolor}
    - \usepackage{setspace}\doublespacing
    - \usepackage[final]{pdfpages}
    - \usepackage{chngcntr}

---
\renewcommand\thesection{\Alph{section}}
\counterwithout{figure}{section}
\setcounter{figure}{0}

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}

  # set the output for figures and tables to the width of the text throughout the entire script

  knitr::opts_chunk$set(out.width = "\\textwidth")

  # load libraries

  library(bibtex)       # for referencing, "bibtex" package
  library(here)         # for path independent file referencing, "here" package
  library(papaja)       # APA conform output, "papaja" package
  options(papaja.na_string = "")
  library(kableExtra)   # for great tables in R Markdown, "kableExtra" package
  library(interactions) # for simple slopes plots, "interactions" package
  library(BayesFactor)  # computing Bayes factors, "BayesFactor" package
  library(ggplot2)      # for plotting, "ggplot2" package
  library(egg)          # for paneling plots, "egg" package
  library(knitr)        # for including plots and such, "knitr" package
  library(effectsize)   # for effect sizes and CIs, "effectsize" package
  
  # set top level directory to source file

  here::i_am("flag_project_root_CAD.txt")
  
  # load the workspace variables that have been computed with the Analysis.R script
  
  load(here("06_Paper","COG-ED","Stage 2","Workspace.RData"))

```

# Introduction

In everyday life, effort and reward are closely intertwined[@Botvinick2009].
With each decision a person makes, they have to evaluate whether the effort required to reach a goal is worth being exerted, given the reward they receive when reaching the goal.
A reward is subjectively more valuable if it is obtained with less effort, so the required effort is used as a reference point for estimating the reward value[@Botvinick2009].
However, the cost of the effort itself is also subjective, and research has not yet established which function best describes the relationship between effort and cost[@Kool2018].
Investigating effort and cost is challenging because "effort is not a property of the target task alone, but also a function of the individual's cognitive capacities, as well as the degree of effort voluntarily mobilized for the task, which in turn is a function of the individual's reward sensitivity" (p. 209)[@Kool2018].

One task that is often used to investigate effort is the $n$-back task, a working memory task in which a continuous stream of stimuli, e.g. letters, is presented on screen.
Participants indicate via button press whether the current stimulus is the same as $n$ stimuli before, with $n$ being the level of difficulty between one and six[@Mackworth1959].
The $n$-back task is well suited to investigate effort because it is an almost continuous manipulation of task load as has been shown by monotonic increases in error rates, reaction times[@Jaeggi2010], and brain activity in areas associated with working memory[@Jonides1997; @Owen2005].
However, its reliability measures are mixed, and associations of $n$-back performance and measures such as executive functioning and fluid intelligence are often inconsistent[@Jaeggi2010].

A way to quantify the subjective cost of each $n$-back level has been developed by Westbrook, Kester, and Braver[-@Westbrook2013], called the Cognitive Effort Discounting Paradigm (COG-ED).
First, the participants complete the $n$-back levels to familiarize themselves with the task.
Then, 1-back is compared with each more difficult level by asking the participants to decide between receiving a fixed 2\$ for the more difficult level or the flexible starting value of 1\$ for 1-back.
If they choose the more difficult level, the reward for 1-back increases by 0.50\$, if they choose 1-back, it decreases by 0.50\$.
This is repeated five more times, with each adjustment of the 1-back reward being half of the previous step, while the reward for the more difficult level remains fixed at 2\$.
The idea is to estimate the point of subjective equivalence, i.e., the monetary ratio at which both offers are equally preferred[@Westbrook2013].
The subjective value (SV) of each more difficult level is then calculated by dividing the final reward value of 1-back by the fixed 2\$ reward.
Westbrook et al.[-@Westbrook2013] used these SVs to investigate inter-individual differences in effort discounting.
Younger participants showed lower effort discounting, i.e., they needed a lower monetary incentive for choosing the more difficult levels over 1-back.

The individual degree of effort discounting in the study by Westbrook et al.[-@Westbrook2013] was also associated with the participants' scores in Need for Cognition (NFC), a personality trait describing an individual's tendency to actively seek out and enjoy effortful cognitive activities[@Cacioppo1982].
Westbrook et al.[-@Westbrook2013] conceptualized NFC as a trait measure of effortful task engagement, providing a subjective self-report of effort discounting for each participant which could then be related to the SVs as an objective measure of effort discounting.
On the surface, this association stands to reason, as individuals with higher NFC are more motivated to mobilize cognitive effort because they perceive it as intrinsically rewarding.
Additionally, it has been shown that individuals avoid cognitive effort only to a certain degree, possibly to retain a sense of self-control[@Wu2021], a trait more prominent in individuals with high NFC[@Bertrams2012; @Nishiguchi2016; @Xu2021].
However, the relation of NFC and SVs might be confounded, since other studies utilizing the COG-ED paradigm found the association of NFC and SVs to disappear after correcting for performance[@Kramer2021] or found no association of NFC and SVs at all[@Crawford2021].
On the other hand, task load has been shown to be a better predictor of SVs than task performance[@Culbreth2016; @Westbrook2013; @Westbrook2019], so more research is needed to shed light on this issue.

With the present study, we alter one fundamental assumption of the original COG-ED paradigm: That the easiest $n$-back level has the highest SV.
We therefore adapted the COG-ED paradigm in a way that allows the computation of SVs for different $n$-back levels without presuming that all individuals inherently prefer the easiest level.
Since we also aim to establish this paradigm for the assessment of tasks with no objective task load, e.g., emotion regulation tasks[@ScheffelZerna2022], we call it the Cognitive and Affective Discounting Paradigm (CAD).
In the present study, we validated the CAD paradigm by conceptually replicating the findings of Westbrook et al.[-@Westbrook2013].
Additionally, we compared the effort discounting behavior of participants regarding the $n$-back task and an emotion regulation task.
The full results of the latter are published in a second Registered Report[@ScheffelZerna2022].
The COG-ED paradigm has been applied to tasks in different domains before, showing that SVs across task domains correlate[@Crawford2021], but these tasks had an objective order of task load, which is not the case for the choice of emotion regulation strategies or other paradigms where there is no objective order of task load.

Our hypotheses were derived from the results of Westbrook et al.[-@Westbrook2013].
As a manipulation check, we hypothesized that with increasing $n$-back level the (1a) the signal detection parameter $d'$ declines, while (1b) reaction time and (1c) perceived task load increase.
Regarding the associations of task load and effort discounting we hypothesized that (2a) SVs decline with increasing $n$-back level, and (2b) they do so even after controlling for declining task performance.
And finally, we hypothesized that the CAD paradigm can show interindividual differences in effort discounting, such that participants with higher NFC have (3a) lower SVs for 1-back but higher SVs for 2- and 3-back, (3b) lower perceived task load across all levels, and (3c) higher aversion against 1-back but lower aversion against 2- and 3-back.
Each hypothesis is detailed in the [Design Table](#DesignTableSection) in the Appendix.

# Methods

We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study[cf. @Simmons2012].
The paradigm was written and presented using *Psychopy*[@Peirce2019].
We used *R* with *R Studio*[@RCT2020; @RStudioTeam2020] with the main packages *afex*[@Singmann2021] and *BayesFactor*[@Morey2021] for all our analyses.

## Ethics information

The study protocol complies with all relevant ethical regulations and was approved by the ethics committee of the Technische Universität Dresden (reference number SR-EK-50012022).
Prior to testing, written informed consent was obtained.
Participants received 24€ in total or course credit for participation.

## Design

### CAD Paradigm
Figure\ 1 illustrates how different modifications of the COG-ED paradigm [@Westbrook2013] return SVs that do or do not reflect the true preference of a hypothetical participant, who likes 2-back most, 3-back less, and 1-back least (for reasons of clarity there are only three levels in the example).
The COG-ED paradigm, which compares every more difficult level with 1-back sets the SV of 1-back to 1, regardless of the response pattern.
Adding a comparison of the more difficult levels with each other allows the SVs of those two levels to be more differentiated, but leaves the SV of 1-back unchanged.
Adding those same pairs again, but with the opposite assignment of fixed and flexible level, does approach the true preference, but has two disadvantages.
First, the SVs are still quite alike across levels due to the fact that every more difficult level has only been compared with the easiest level, and second, having more task levels than just three would lead to an exponential increase in comparisons.
Therefore, the solution lies in reducing the number of necessary comparisons by presenting only one effort discounting round for each possible pair of levels after determining for each pair which level should be fixed and which should be flexible.
This is determined by presenting each possible pair of levels on screen with the question "Would you prefer 1\ € for level A or 1\ € for level B?".
Participants respond by clicking the respective on-screen button.
Each pair is presented three times, resulting in 18 presented pairs, which are fully randomized in order and in the assignment of which level is on the left or right of the screen.
For each pair, the level that was chosen by the participant at least two out of three times will be used as the level with a flexible value, which starts at 1\ € and is changed in every iteration.
The other level in the pair will be set to a fixed value of 2\ €.
Then, the effort discounting sensu Westbrook et al.[-@Westbrook2013] begins, but with all possible pairs and with the individually determined assignment of fixed and flexible level.
The order in which the pairs are presented is fully randomized, and each pair goes through all iteration steps of adding/subtracting 0.50\ €, 0.25\ €, 0.13\ €, 0.06\ €, 0.03\ €, 0.02\ € to/from the flexible level's reward (each adjustment half of the previous one, rounded to two decimals) before moving on to the next one.
This procedure allows to compute SVs based on actual individual preference instead of objective task load.
For each pair, the SV of the flexible level is 1, as it was preferred when faced with equal rewards, and the SV of the fixed level is the final reward of the flexible level divided by 2\ €.
Each level's "global" SV is calculated as the mean of this level's SVs from all pairs in which it appeared.
If the participant has a clear preference for one level, this level's SV will be 1.
If not, then no level's SV will be 1, but each level's SV can still be interpreted as an absolute and relative value, so each participant's effort discounting behaviour can still be quantified.
The interpretation of SVs in Westbrook et al.[-@Westbrook2013] was "The minimum relative reward required for me to choose 1-back over this level".
So if the SV of 3-back was 0.6, the participant would need to be rewarded with at least 60\ % of what they are being offered for doing 3-back to do 1-back instead, forgoing the higher reward for 3-back.
In this study, the SV can be interpreted as "The minimum relative reward required for me to choose any other level over this level".
Therefore, an SV of 1 indicates that this level is preferred over all others, while SVs lower than 1 indicate that in at least one pair, a different level was preferred over this one.

INSERT FIGURE 1 HERE

```{r figure1, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="An example for subjective values for an $n$-back task with three levels, returned by different modifications of the COG-ED paradigm for a hypothetical participant with the true preference 2-back > 3-back > 1-back. The grey boxes are the choice options shown to the participant. The participant's final reward value of the flexible level is displayed after the first arrow. The resulting subjective value of each level is displayed after the second arrow, in the notation \"SV 3-back(1-back)\" for the subjective value of 3-back when 1-back is the other choice. The Solution and Additional Benefit panel follow the same logic, but are preceded by a choice between equal rewards, and the participant's first choice indicated by an exclamation mark.", fig.pos="H"} 
  
  include_graphics(here("06_Paper", "Inkscape Figures", "Paradigm_Scheme.png"))

```


### Study procedure
Healthy participants aged 18 to 30\ years were recruited using the software *ORSEE*[@Greiner2015].
Participants completed the personality questionnaires online and then visited the lab for two sessions one week apart.
NFC was assessed using the 16-item short form of the Need for Cognition Scale [@Cacioppo1984; @Bless1994].
Responses to each item (e.g., "Thinking is not my idea of fun", recoded) were recorded on a 7-point Likert scale.
The NFC scale shows comparably high internal consistency (Cronbach's $\alpha>.80$) [@Bless1994; @Fleischhauer2010].
Several other personality questionnaires were used in this study but are the topic of the Registered Report for the second lab session[@ScheffelZerna2022].
A full list of measures can be found in our [Github repository](https://github.com/ChScheffel/CAD).
In the first session, participants provided informed consent and demographic data before completing the computer-based paradigm.
The paradigm started with the $n$-back levels one to four, presented sequentially with two runs per level, consisting of 64 consonants (16 targets, 48 non-targets) per run.
The levels were referred to by color (1-back black, 2-back red, 3-back blue, 4-back green) to avoid anchor effects in the effort discounting procedure.
To assess perceived task load, we used the 6-item NASA Task Load Index (NASA-TLX)[@Hart1988], where participants evaluate their subjective perception of mental load, physical load, effort, frustration, performance, and time pressure during the task on a 20-point scale.
At the end of each level, participants filled out the NASA-TLX on a tablet, plus an item with the same response scale, asking them how aversive they found this $n$-back level.
After the $n$-back task, participants completed the CAD paradigm on screen and were instructed to do so as realistically as possible, even though the displayed rewards were not paid out on top of their compensation.
They were told that one of their choices would be randomly picked for the final run of $n$-back, the data of which was not analyzed as it only served to incentivise truthful behavior and stay close to the design of Westbrook et al.[-@Westbrook2013].
After the CAD paradigm, participants filled out a short questionnaire on the tablet, indicating whether they adhered to the instructions (yes/no) and what the primary motivation for their decisions during the effort discounting procedure was (avoid boredom/relax/avoid effort/seek challenge/other).  
The second session consisted of an emotion regulation task with negative pictures and the instruction to suppress facial reactions, detach cognitively from the picture content, and distract oneself, respectively.
The paradigm followed the same structure of task and effort discounting procedure, but participants could decide which strategy they wanted to reapply in the last block.
Study data was collected and managed using REDCap electronic data capture tools hosted at Technische Universität Dresden[@Harris2009; @Harris2019].

## Sampling plan

Sample size determination was mainly based on the results of the analyses of Westbrook et al.[-@Westbrook2013] (see [Design Table](#DesignTableSection)).
The hypothesis that yielded the largest necessary sample size was a repeated measures ANOVA with within-between interaction of NFC and $n$-back level influencing SVs.
Sample size analysis with *G\*Power*[@Faul2007; @Faul2009] indicated that we should collect data from at least 72 participants, assuming $\alpha=.05$ and $\beta=.95$.
However, the sample size analysis for the hypotheses of the second lab session revealed a larger necessary sample size of 85 participants to find an effect of $d=-0.32$ of emotion regulation on facial muscle activity with $\alpha=.05$ and $\beta=.95$.
To account for technical errors, noisy physiological data, or participants who indicate that they did not follow the instructions, we aimed to collect about $50\%$ more data sets than necessary, $N=120$ in total.

## Analysis plan

Data collection and analysis were not performed blind to the conditions of the experiments.
We excluded the data of a participant from all analyses, if the participant stated that they did not follow the instructions, if the investigator noted that the participant misunderstood the instructions, or if the participant withdrew their consent.
No data was replaced.
The performance measure $d'$ was computed as the difference of the *z*-transformed hit rate and the *z*-transformed false alarm rate[@Macmillan1990].
Reaction time (RT) data was trimmed by excluding all trials with responses faster than 100\ ms, as the relevant cognitive processes cannot have been completed before[@Whelan2008; @Berger2021].
Aggregated RT values were described using the median and the median of absolute deviation ($MAD$) as robust estimates of center and variability, respectively[@Lachaud2011].
Error- and post-error trials were excluded, because RT in the latter is longer due to more cautious behavior[@Dutilh2012; @Houtman2012].
To test our hypotheses, we performed a series of rmANOVAs and an MLM with orthogonal sum-to-zero contrasts in order to meaningfully interpret results[@Singmann2019].

*Manipulation check.*
Declining performance was investigated by calculating an rmANOVA with six paired contrasts comparing $d'$ between two levels of 1- to 4-back at a time.
Another rmANOVA with six paired contrasts was computed to compare the median RT between two levels of 1- to 4-back at a time.
To investigate changes in NASA-TLX ratings, six rmANOVAs were computed, one for each NASA-TLX subscale, and each with six paired contrasts comparing the ratings between two levels of 1- to 4-back at a time.

*Subjective values.*
For each effort discounting round, the SV of the fixed level was calculated by adding or subtracting the last adjustment of 0.02\ € from the last monetary value of the flexible level, depending on the participant's last choice, and dividing this value by 2\ €.
This yielded an SV between 0 and 1 for the fixed compared with the flexible level, while the SV of the flexible level was 1.
The closer the SV of the fixed level is to 0, the stronger the preference for the flexible level.
All SVs of each level were averaged to compute one "global" SV for each level.
An rmANOVA with four different contrasts were computed to investigate the association of SVs and the $n$-back levels: Declining linear (3,1,-1,-3), ascending quadratic (-1,1,1,-1), declining logistic (3,2,-2,-3), and positively skewed normal (1,2,-1,-2).
Depending on whether the linear or one of the other three contrasts fit the curve best, we applied a linear or nonlinear multi-level model in the next step, respectively.

To determine the influence of task performance on the association of SVs and $n$-back level, we performed MLM. 
We applied restricted maximum likelihood (REML) to fit the model.
As an effect size measure for random effects we first calculated the intraclass correlation (ICC), which displays the proportion of variance that is explained by differences between persons.
Second, we estimated a random slopes model of $n$-back level (level 1, fixed, and random factor: 0-back, 1-back, 2-back, 3-back) predicting SV nested within subjects.
As Mussel et al.[-@Mussel2016] could show, participants with high versus low NFC not only have a more shallow decline in performance with higher $n$-back levels, but show a demand-specific increase in EEG theta oscillations, which has been associated with mental effort.
We controlled for performance, i.e., $d'$ (level 1, fixed factor, continuous), median RT (level 1, fixed factor, continuous) in order to eliminate a possible influence of declining performance on SV ratings.
$$
SV \sim level\ + d' + median RT + (level|subject)
$$
Level-1-predictors were centered within cluster as recommended by Enders & Tofighi[-@Enders2007]. 
By this, the model yields interpretable parameter estimates. 
If necessary, we will adjusted the optimization algorithm to improve model fit. 
We visually inspected the residuals of the model for evidence to perform model criticism. 
This was done by excluding all data points with absolute standardized residuals above 3 SD. 
As effect size measures, we calculated pseudo $R^{2}$ for our model and $f^{2}$ to estimate the effect of $n$-back level according to Lorah[-@Lorah2018].
To ensure the validity of the association of SVs and $n$-back level, we conducted a specification curve analysis[@Simonsohn2020], which includes 63 possible preprocessing pipelines of the RT data.
These pipelines specify which transformation was applied (none, log, inverse, or square-root), which outliers were excluded (none, 2, 2.5, or 3\ $MAD$ from the median, RTs below 100\ or\ 200\ ms), and across which dimensions the transformations and exclusions were applied (across/within subjects and across/within $n$-back levels).
The rmANOVA was run with each of the 63\ pipelines, which will also include our main pipeline (untransformed data, exclusion of RTs below 100\ ms).
The ratio of pipelines that lead to significant versus non-significant effects provides an indication of how robust the effect actually is.
The specification curve analysis was linked to the MLM in the initial submission, and was assigned to hypothesis 3a during the review process and in the Stage 1 report.
Afterwards, we noticed that 3a does not contain any RT data, so the specification curve analysis was reassigned to the MLM with the agreement of the editor.

The association of SVs and NFC was examined with an rmANOVA.
We subtracted the SV of 1- from 2-back and 2- from 3-back, yielding two SV difference scores per participant.
The sample was divided into participants with low and high NFC using a median split.
We then computed an rmANOVA with the within-factor $n$-back level and the between-factor NFC group to determine whether there is a main effect of level and/or group, and/or an interaction between level and group on the SV difference scores.
Post-hoc tests were computed depending on which effect reached significance at $p<.01$.

The association of subjective task load with NFC was examined similarly.
We calculated NASA-TLX sum scores per participant per level, computed an rmANOVA with the within-factor $n$-back level and the between-factor NFC group, and applied post-hoc tests based on which effect reached significance at $p<.01$.
And the association of subjective aversiveness of the task with NFC was examined with difference scores as well, since we expected this curve to mirror the SV curve, i.e. as the SV rises, the aversiveness declines, and vice versa.
We subtracted the aversiveness ratings of 1- from 2-back and 2- from 3-back, yielding two aversiveness difference scores per participant.
Then, we computed an rmANOVA with the within-factor $n$-back level and the between-factor NFC group, and applied post-hoc tests based on which effect reached significance at $p<.01$.

The results of each analysis was assessed on the basis of both $p$-value and the Bayes factor $BF_{10}$, calculated with the *BayesFactor* package[@Morey2021] using the default prior widths of the functions *anovaBF*, *lmBF* and *ttestBF*.
We considered a $BF_{10}$ close to or above 3/10 as moderate/strong evidence for the alternative hypothesis, and a $BF_{10}$ close to or below .33/.10 as moderate/strong evidence for the null hypothesis [@Wetzels2015].

## Pilot data

The sample of the pilot study consisted of $N=15$ participants (53.3% female, $M=24.43$ ($SD=3.59$) years old).
One participant's data was removed because they misunderstood the instruction.
Due to a technical error the subjective task load data of one participant was incomplete, so the hypotheses involving the NASA Task Load Index were analyzed with $n=14$ data sets.
The results showed increases in subjective and objective task load measures with higher $n$-back level.
Importantly, SVs were lower for higher $n$-back levels, but not different between 1- and 2-back, which shows that the easiest level is not universally preferred.
The LMM revealed $n$-back level as a reliable predictor of SV, even after controlling for declining task performance ($d'$ and median RT).
NASA-TLX scores were higher with higher $n$, and lower for the group with lower NFC scores, but NFC and $n$-back level did not interact.
All results are detailed in the Supplementary Material.

## Data availability

The data of this study can be downloaded from [osf.io/vnj8x/](https://osf.io/vnj8x/).

## Code availability

The paradigm code as well as the R Markdown file used to analyze the data and write this document are available at [github.com/ChScheffel/CAD](https://github.com/ChScheffel/CAD).

## Protocol registration

The Stage 1 Registered Report protocol has been approved and is available at [osf.io/qa2bg/](https://osf.io/qa2bg/).

# Results

Data was collected between the 16th of August 2022 and the 3rd of February 2023.
All of the $N=`r n_quest`$ participants who filled out the online questionnaires came to the first lab session.
Based on the experimenters' notes, we excluded the data of seven participants from analysis for misunderstanding the instruction of the $n$-back task, and the data of one participant who reported that they confused the colours of the levels during effort discounting.
Our final data set therefore included $N=`r nrow(data_quest)`$ participants.

## Manipulation checks

The performance measure $d'$ did not change across $n$-back levels (`r apa_print(hypothesis1a_rmanova)$full_result$level`, `r apa_print(hypothesis1a_BF)$statistic`), but the median RT did (`r apa_print(hypothesis1b_rmanova)$full_result$level`, `r apa_print(hypothesis1b_BF)$statistic`).
Specifically, the median RT was higher for the more difficult level in every contrast, with two exceptions:
It did not differ between 2- and 4-back, and it was higher for 3- than for 4-back (Table\ \@ref(tab:H1b-contrasts)).

```{r H1b-contrasts, echo=FALSE, message=FALSE, warning=FALSE}
apa_table(
  hypothesis1b_contrasts,
  caption = "Paired contrasts for the rmANOVA comparing the median reaction time between $n$-back levels",
  note = "The column Contrast contains the $n$ of the $n$-back levels. $SE$ = standard error, $df$ = degrees of freedom, $t$ = $t$-statistic, $p$ = $p$-value, CI = confidence interval.",
  escape = FALSE,
  placement = "H"
)
```

All NASA-TLX subscale scores increased across $n$-back levels.
The effort subscale (`r apa_print(hypothesis1c_effort_rmanova)$full_result$level`, `r apa_print(hypothesis1c_effort_BF)$statistic`) increased across all levels, but the magnitude of change decreased from 1- to 2-back (`r apa_print(pairs(hypothesis1c_effort_emm))$statistic$X1_X2`, `r apa_print(BayesFactor::ttestBF(x = h1c_data$effort[h1c_data$level == 1], y = h1c_data$effort[h1c_data$level == 2], progress = FALSE, paired = TRUE))$statistic`) to 3- to 4-back (`r apa_print(pairs(hypothesis1c_effort_emm))$statistic$X3_X4`, `r apa_print(BayesFactor::ttestBF(x = h1c_data$effort[h1c_data$level == 3], y = h1c_data$effort[h1c_data$level == 4], progress = FALSE, paired = TRUE))$statistic`).
Three subscales had significant differences between all contrasts except for 3- versus 4-back:
While ratings on the frustration and time subscales were higher for more difficult levels (`r apa_print(hypothesis1c_frustration_rmanova)$full_result$level`, `r apa_print(hypothesis1c_frustration_BF)$statistic`, and `r apa_print(hypothesis1c_time_rmanova)$full_result$level`, `r apa_print(hypothesis1c_time_BF)$statistic`, respectively), ratings on the performance subscale decreased with higher $n$ (`r apa_print(hypothesis1c_performance_rmanova)$full_result$level`, `r apa_print(hypothesis1c_performance_BF)$statistic`).
Ratings on the mental subscale consistently increased across all levels (`r apa_print(hypothesis1c_mental_rmanova)$full_result$level`, `r apa_print(hypothesis1c_mental_BF)$statistic`).
Ratings on the physical subscale were higher for more difficult levels (`r apa_print(hypothesis1c_physical_rmanova)$full_result$level`, `r apa_print(hypothesis1c_physical_BF)$statistic`), apart from the contrasts 2- versus 3-back (`r apa_print(pairs(hypothesis1c_physical_emm))$statistic$X2_X3`, `r apa_print(BayesFactor::ttestBF(x = h1c_data$physical[h1c_data$level == 2], y = h1c_data$physical[h1c_data$level == 3], progress = FALSE, paired = TRUE))$statistic`) and 3- versus 4-back (`r apa_print(pairs(hypothesis1c_physical_emm))$statistic$X3_X4`, `r apa_print(BayesFactor::ttestBF(x = h1c_data$physical[h1c_data$level == 3], y = h1c_data$physical[h1c_data$level == 4], progress = FALSE, paired = TRUE))$statistic`).

## Decline of subjective values

When asking participants what motivated their decisions in the effort discounting, `r format(round((table(data_quest$motivation)[1]/sum(table(data_quest$motivation)))*100, digits = 1), nsmall = 1)`% stated that they wanted to avoid boredom, `r format(round((table(data_quest$motivation)[2]/sum(table(data_quest$motivation)))*100, digits = 1), nsmall = 1)`% stated that they wanted a challenge, `r format(round((table(data_quest$motivation)[3]/sum(table(data_quest$motivation)))*100, digits = 1), nsmall = 1)`% stated that they wanted to avoid effort, and `r format(round((table(data_quest$motivation)[4]/sum(table(data_quest$motivation)))*100, digits = 1), nsmall = 1)`% stated that they wanted to relax.
The remaining `r format(round((table(data_quest$motivation)[5]/sum(table(data_quest$motivation)))*100, digits = 1), nsmall = 1)`% of participants used the free text field and provided reasons such as "I wanted a fair relation of effort and reward.", "I wanted the fun that I had in the more challenging levels.", "I wanted to maximize reward first and minimize effort second.", or "I did not want to perform poorly when I was being paid for it.".
The rmANOVA showed a significant difference between the SVs across $n$-back levels (`r apa_print(hypothesis2a_rmanova)$full_result$level`, `r apa_print(hypothesis2a_BF)$statistic`).
All four pre-defined contrasts reached significance (Table\ \@ref(tab:H2a-contrasts)), so a purely linear contrast can be rejected.

```{r H2a-contrasts, echo=FALSE, message=FALSE, warning=FALSE}
apa_table(
  hypothesis2a_contrasts,
  caption = "Contrasts for the rmANOVA comparing the subjective values between $n$-back levels",
  note = "$SE$ = standard error, $df$ = degrees of freedom, $t$ = $t$-statistic, $p$ = $p$-value, CI = confidence interval.",
  escape = FALSE,
  placement = "H"
)
```

The declining logistic contrast had the highest effect estimate (`r apa_print(emmeans::contrast(hypothesis2a_emm, method = list("Declining Linear" = c(3,1,-1,-3),"Ascending Quadratic" = c(-1,1,1,-1),"Declining Logistic" = c(3,2,-2,-3),"Positively Skewed Normal" = c(1,2,-1,-2))))$statistic$DecliningLogistic`), suggesting a shallow decline of SVs between 1- and 2-back, and 3- and 4-back, respectively, and a steeper decline of SVs between 2- and 3-back.

Consequently, we had to adapt the multi level model to incorporate this non-linear trend.
To apply the contrast to the $n$-back levels, we had to turn the variables into a factor, with two consequences:
Centered variables cannot be turned into factors, so we entered the variable level in its raw form, and factors cannot be used as random slopes, so the model is now defined as:
$$
SV \sim level\ + d' + median RT + (1|subject)
$$
This means that the intercept still varies between subjects, but there are no random slopes anymore.
To provide more than one observation per factor level, we used the two rounds per $n$-back level per subject, rather than $n$-back levels per subject.
The ICC of the null model indicated that there is a correlation of $r=$ `r sub("^(-?)0.", "\\1.", sprintf("%.2f", round(model0_h2b_ICC, digits = 3)))` between the SVs of a subject, i.e. that `r paste0(formatC(model0_h2b_ICC * 100, format = "f", digits = 2), "%")` of variance in SVs can be explained by differences between participants.
We did not use an optimization algorithm to improve the fit of the random intercept model.
A total of `r nrow(excl_cases_h2b)` data points from `r length(unique(excl_cases_h2b$subject))` participants were excluded, because the residuals exceeded 3 SD above the mean.
The results of the final model are displayed in Table\ \@ref(tab:H2b-results).

```{r H2b-results, echo=FALSE, message=FALSE, warning=FALSE}
kable(h2b_result.table,
        caption = "Results of the multi level model on the influence of n-back level (as a declining logistic contrast) and task performance on subjective values.",
        booktabs = T,                          # no vertical lines
        escape = F,                            # correctly print special characters)
        align = c("l",rep("r",7))) %>%         # right aligns the text in every numerical column
    kable_styling(latex_options = c("striped")) %>%
    footnote(general = "$SE$ = standard error, $df$ = degrees of freedom, $SD$ = standard deviation.",
             escape = F,                    # correctly print special characters
             threeparttable = T)            # line breaks in the footnote
```

An exploratory was used ANOVA to compare the fit of the final model with a linear random intercept model, confirming that the two models were different from each other ($\chi^2 (`r compare_h2b$Df[2]`)$ = `r compare_h2b$Chisq[2]`, $p<.001$), and with an Akaike Information Criterion of $AIC=`r compare_h2b$AIC[2]`$ and a Bayesian Information Criterion of $BIC=`r compare_h2b$BIC[2]`$ the declining logistic model was superior to the linear model ($AIC=`r compare_h2b$AIC[1]`$, $BIC=`r compare_h2b$BIC[1]`$).
The final model had an effect size of $f^{2}=$ `r round(h2b_level_f2, digits = 2)` for the $n$-back levels and $f^{2}=$ `r round(h2b_dprime_f2, digits = 2)` for $d'$, which are considered large and small, respectively [@Cohen1992].
This means that the $n$-back level explained `r paste0(formatC(h2b_level_f2 * 100, format = "f", digits = 2), "%")` and $d'$ explained `r paste0(formatC(h2b_dprime_f2 * 100, format = "f", digits = 2), "%")` of variance in SVs relative to the unexplained variance, respectively.
The beta coefficients indicated that with every $n$-back level, the SV decreased by `r as.numeric(h2b_result.table[2,"Beta"])`, and for every 1-unit increase in $d'$, the SV increased by `r as.numeric(h2b_result.table[3,"Beta"])`.
The effect size of the median RT was $f^{2}=$ `r format(round(h2b_medianRT_f2, digits = 2), nsmall = 2)`.

To investigate the dependency of the model results on the RT preprocessing, we conducted a specification curve analysis (Figure\ \@ref(fig:sca-plot)).

INSERT FIGURE 2 HERE
```{r sca-plot, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Results of the multi level model for each of the 63 preprocessing pipelines. The lower panel indicates the type of preprocessing, the upper panel shows the beta coefficient of each predictor and its p-value. The colourbar indicates the BF10. The pipelines are sorted in descending order of the magnitude of the n-back level beta.", fig.pos="H"} 
  
  include_graphics(here("06_Paper", "COG-ED", "Stage 2", "Figures", "sca-plot.png"))

```

Regardless of the preprocessing pipeline, $n$-back level and $d'$ were significant predictors of SVs, and had stable effect estimates across all pipelines.
The only pipelines in which the median RT was a significant predictor of SVs, were the three pipelines with the highest Bayes Factors.
These three pipelines contain data that has been inverse transformed across subjects but within conditions, i.e. within the round of an $n$-back level.

## Differences between NFC groups

Figure\ \@ref(fig:nfc-sv) shows a scatterplot of SVs per $n$-back level, colored depending on the participant's NFC score.
There is a concentration of participants who have assigned their highest SV to 1-back, and this concentration fades across $n$-back levels.
At the same time, there is a subtle separation of SVs across $n$-back levels, depending on the participant's NFC score: While the SVs of those with higher NFC scores remain elevated, the SVs of those with lower NFC scores decline more strongly.
Specifically, $n=`r nrow(data_SV[data_SV$level==1 & data_SV$sv==1,])`$ participants had an absolute preference for 1-back, $n=`r nrow(data_SV[data_SV$level==2 & data_SV$sv==1,])`$ for 2-back, $n=`r nrow(data_SV[data_SV$level==3 & data_SV$sv==1,])`$ for 3-back, and $n=`r nrow(data_SV[data_SV$level==4 & data_SV$sv==1,])`$ for 4-back.
There were $n=`r length(setdiff(unique(data_SV$subject), data_SV$subject[data_SV$sv == 1]))`$ participants who did not have an absolute preference for any $n$-back level, i.e. none of their SVs was 1.

INSERT FIGURE 3 HERE

```{r nfc-sv, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Subjective values per n-back level. Each dot indicates a participant, the colours indicate their Need for Cognition score. $N=116$. There is a horizontal jitter of 0.4 and a vertical jitter of 0.05 for visual clarity.", fig.pos="H"} 
  
  include_graphics(here("06_Paper", "COG-ED", "Stage 2", "Figures", "nfc-sv.png"))

```


The median NFC was `r mediannfc`, with $n=`r nrow(h3b_data[h3b_data$nfcmedian == "low",])/(nrow(h3b_data)/length(unique(h3b_data$subject)))`$ subjects below and $n=`r nrow(h3b_data[h3b_data$nfcmedian == "high",])/(nrow(h3b_data)/length(unique(h3b_data$subject)))`$ above the median.
We used an rmANOVA to investigate whether the difference between the SVs of 1- and 2-back, and 2- and 3-back, respectively, depended on whether a participant's NFC score was above or below the median.
There was a main effect of the $n$-back level (`r apa_print(hypothesis3a_model)$full_result$nlevels`), but neither a main effect of the NFC group (`r apa_print(hypothesis3a_model)$full_result$nfcmedian`) nor an interaction of NFC group and $n$-back level (`r apa_print(hypothesis3a_model)$full_result$nfcmedian_nlevels`).
Post-hoc tests showed that the difference between the SVs of 2- and 3-back is slightly more negative than the difference between 1- and 2-back (`r apa_print(pairs(hypothesis3a_emm_nlevel))$statistic`), but there were large interindividual differences, especially for 2- and 3-back (Figure\ \@ref(fig:h3a-plot)).
This means that across the whole sample, there was a steeper decline in SVs from 2- to 3-back than from 1- to 2-back, but some participants showed a completely opposite pattern.

INSERT FIGURE 4 HERE


The rmANOVA on the association between NFC scores and NASA-TLX scores revealed a main effect of $n$-back level (`r apa_print(hypothesis3b_model)$full_result$level`, `r apa_print(hypothesis3b_BF_levels)$statistic$level`) and an interaction between $n$-back level and NFC scores (`r apa_print(hypothesis3b_model)$full_result$nfcmedian_level`), but no main effect of NFC scores (`r apa_print(hypothesis3b_model)$full_result$nfcmedian`, `r apa_print(hypothesis3b_BF_levels)$statistic$nfcmedian`).
Post-hoc tests showed that the participants with NFC scores below the median had higher NASA-TLX scores for 3-back (`r apa_print(pairs(hypothesis3b_emm_interact))$statistic$X3_High_low`, `r apa_print(BayesFactor::ttestBF(x = h3b_data$ntlx[h3b_data$nfcmedian == "low" & h3b_data$level == 3], y = h3b_data$ntlx[h3b_data$nfcmedian == "high" & h3b_data$level == 3], progress = FALSE, paired = FALSE))$statistic`) and for 4-back (`r apa_print(pairs(hypothesis3b_emm_interact))$statistic$X4_High_low`, `r apa_print(BayesFactor::ttestBF(x = h3b_data$ntlx[h3b_data$nfcmedian == "low" & h3b_data$level == 4], y = h3b_data$ntlx[h3b_data$nfcmedian == "high" & h3b_data$level == 4], progress = FALSE, paired = FALSE))$statistic`) than those with NFC scores above the median.
Regardless of NFC scores, NASA-TLX scores were higher for the more difficult level in each pair of $n$-back levels (**Supplement**).

With another rmANOVA was used to investigate whether the difference between the aversiveness scores of 1- and 2-back, and 2- and 3-back, respectively, depended on whether a participant's NFC score was above or below the median.
There was a main effect of NFC group (`r apa_print(hypothesis3c_model)$full_result$nfcmedian`, `r apa_print(hypothesis3c_BF_levels)$statistic$nfc`) and a main effect of the $n$-back level (`r apa_print(hypothesis3c_model)$full_result$nlevels`, `r apa_print(hypothesis3c_BF_levels)$statistic$levels`), but no interaction.
Post-hoc tests revealed that participants with NFC scores below the median reported higher aversiveness than participants with NFC scores above the median (`r apa_print(pairs(hypothesis3c_emm_nfc))$statistic`).
Regardless of NFC, the difference of the aversiveness scores of 2- and 3-back was smaller and more negative than that of 1- and 2-back (`r apa_print(pairs(hypothesis3c_emm_levels))$statistic`), but again, there were large interindividual differences.

# Discussion

This Registered Report aimed to adapt the Cognitive Effort Discounting Paradigm (COG-ED) paradigm by Westbrook et al.[-@Westbrook2013], which can estimate subjective values of different $n$-back levels, into the Cognitive and Affective Discounting (CAD) paradigm, which can estimate subjective values of tasks without assuming that the easiest level is inherently preferred.
For this purpose, we changed the way in which the discounting options are presented to the participants, basing the anchor on their own choices rather than on the objective task load.
The analyses were closely aligned with those in Westbrook et al.[-@Westbrook2013] to demonstrate the changes in SVs brought about by the new paradigm.
This study also applied the CAD paradigm to an emotion regulation task, the results of which are detailed in **Scheffel et al.**.

## Manipulation checks

The performance measure $d'$ did not differ across $n$-back levels, but the RT increased from 1- to 2- to 3-back and then remained on a high level for 4-back.
This points to three important characteristics of the $n$-back task in this context.
Firstly, RT as a valid group-level indicator of performance might only be useful for levels up to $n=3$, and could be used to investigate interindividual differences for $n>3$.
Secondly, there is a speed-accuracy tradeoff in the first three levels, that might even re-emerge in higher levels, where $d'$ would decline and RT would remain stable.
And lastly, the fact that neither accuracy and nor speed is an informative performance measure by itself has been observed before[@Meule2017] and both show different associations with various measures of intelligence[@Jaeggi2010], suggesting that they should always be reported as separate indices.

All NASA-TLX subscales differed across $n$-back levels, but the effort and mental load subscales were the only ones to consistently increase across all levels.
This would support the notion of the $n$-back task offering a continuous manipulation of task load, as least subjectively.
Ratings on the frustration and time subscales increased and ratings on the performance subscale decreased until 3-back and then remained stable.
This pattern is akin to the RT, which also increased and then remained stable.
Ratings on the physical load subscale increased with $n$-back levels, but not between 2- and 3-back and 3- and 4-back, respectively.

## Decline of subjective values

The rmANOVA with different pre-defined contrasts showed that all fit the SVs to a different degree, and that the SVs do not simply decline linearly across $n$-back levels.
The best fit was a declining logistic curve, reflecting that the majority of participants preferred 1-back and that SVs for 2-back were also high, before having more interindividual variance for 3- and 4-back.
The MLM with the logistic contrast showed that the $n$-back level explained the majority of variance in SVs, while the performance measure $d'$ also explained some variance in SVs, albeit less.
With increasing $n$-back level and decreasing $d'$, the SV decreased.
The median RT was not a significant predictor in this model, which was somewhat surprising because RT but not $d'$ yielded significant differences across levels in the manipulation checks.
However, participants might have deliberately or subconsciously used the feedback they received at the end of each round, i.e. twice per $n$-back level, as an anchor during the effort discounting.
This feedback was based on correct responses and not on RT, so if participants based their effort discounting choices at least partly on this feedback, they were either motivated to repeat a task in which they performed well and/or they were reluctant to accept a larger reward for a task in which they did not perform well.
Since more participants reported effort avoidance as their motivation in the effort discounting than those who reported seeking a challenge, we can assume that they were more motivated to repeat a task in which they performed well because their good performance coincided with low effort.

The declining logistic $n$-back levels and $d'$ remained significant predictors of SVs throughout all 63 preprocessing pipelines in the specification curve analysis, with betas that varied by less than 0.01.
In contrast to this stood the variability of the median RT betas, which ranged from about 0.11 to -0.01, and reached significance in only three pipelines.
These three pipelines had the highest $BF_{10}$ and applied inverse transformation to the RT data, across subjects but within conditions, and excluded data based on the MAD.
Interestingly, the curve of median RT betas in the upper panel of Figure\ \@ref(fig:sca-plot) mirrored the rectangular pipeline indicators in the transformation rows of the lower panel, so the transformation choice influenced the median RT much more than the dimension or the exclusion choice did.
As Fernandez et al.[-@Fernandez2020] found, applying more than one preprocessing step to the reaction time data of a Stroop task increased the risk of false positives beyond $\alpha=.05$, and transformation choices inflated this risk more than outlier exclusion or aggregation choices did.
Our data seems to corroborate this finding for $n$-back tasks as well.
Surprisingly, the $d'$ betas appear almost unaffected by the preprocessing pipeline, even though $d'$ was computed after the outlier exclusion.
This indicates that researchers who are interested in the correctness rather than the speed of responses can choose a simple preprocessing pipeline without risking false positives through elaborate transformations.

## Differences between NFC groups

The majority of participants (`r round(100*((nrow(data_SV[data_SV$level==1 & data_SV$sv==1,]))/nrow(data_quest)), digits = 1)`\ %) had an absolute preference for 1-back over the other levels, but that also means that there were `r round(100*((nrow(data_SV[data_SV$level!=1 & data_SV$sv==1,]))/nrow(data_quest)), digits = 1)`\ % who had an absolute preference for 2-, 3-, or 4-back, and `r round(100*((length(setdiff(unique(data_SV$subject), data_SV$subject[data_SV$sv == 1])))/nrow(data_quest)), digits = 1)`\ % who preferred no specific level over all others.

\newpage

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup

\newpage

# Acknowledgements

This research is partly funded by the German Research Foundation (DFG) as part of the Collaborative Research Center (CRC) 940, and partly funded by centralized funds of the Faculty of Psychology at Technische Universität Dresden.
The funders have/had no role in study design, data collection and analysis, decision to publish or preparation of the manuscript.


# Author Contributions

JZ, CS, and AS conceptualized the study and acquired funding.
JZ and CS developed the methodology, investigated, administered the project, and wrote the software.
JZ, CS, and CK did the formal analysis.
JZ visualized the results.
JZ and CK prepared the original draft.
All authors reviewed, edited, and approved the final version of the manuscript.


# Competing Interests

The authors declare no competing interests.

\newpage
\setcounter{figure}{0}

# Figures and figure Captions

INSERT FIGURE 1 HERE

<!--
```{r figure1appendix, echo=FALSE, message=FALSE, warning=FALSE}

  include_graphics(here("06_Paper", "Inkscape Figures", "Paradigm_Scheme.png"))

```
-->

*Figure 1.* An example for subjective values for an $n$-back task with three levels, returned by different modifications of the COG-ED paradigm for a hypothetical participant with the true preference 2-back > 3-back > 1-back. The grey boxes are the choice options shown to the participant. The participant's final reward value of the flexible level is displayed after the first arrow. The resulting subjective value of each level is displayed after the second arrow, in the notation "SV 3-back(1-back)" for the subjective value of 3-back when 1-back is the other choice. The Solution and Additional Benefit panel follow the same logic, but are preceded by a choice between equal rewards, and the participant's first choice indicated by an exclamation mark.

\newpage

# Design Table {#DesignTableSection}

INSERT DESIGN TABLE HERE

\newpage

# Supplement

INSERT SUPPLEMENT HERE

