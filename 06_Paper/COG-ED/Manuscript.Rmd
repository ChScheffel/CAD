---
title             : "COG-ED Manuscript"
author            : "Josephine"
date              : "13 8 2021"
output            : html_document
bibliography      : ref_COG-ED.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(bibtex)
```

# Introduction

In everyday life, effort and reward are closely intertwined [@Botvinick2009].
With each decision a person makes, they have to evaluate whether the effort required to reach a goal is worth being exerted, given the reward they receive when reaching the goal.
A reward is subjectively more valuable if it is obtained with less effort, so the required effort is used as a reference point for estimating the reward value [@Botvinick2009].
However, the cost of the effort itself is also subjective, and research has not yet established which function best describes the relationship between effort and cost [@Kool2018].
Investigating effort and cost is challenging because “effort is not a property of the target task alone, but also a function of the individual’s cognitive capacities, as well as the degree of effort voluntarily mobilized for the task, which in turn is a function of the individual’s reward sensitivity” [@Kool2018, p. 209].

One task that is often used to investigate effort is the n-back task.
In this working memory task, a continuous stream of stimuli, e.g. letters, is presented on screen.
Participants indicate via button press whether the current stimulus is the same as *n* stimuli before, with *n* being the level of difficulty between one and six [@Mackworth1959]; and are asked to respond as quickly and as accurately as they can.
The n-back task requires simultaneous storage of past stimuli and processing of new stimuli [@Jonides1997].
It is well suited to investigate effort because it is an almost continuous manipulation of task load, as has been shown by monotonic increases in error rates and reaction times [@Jaeggi2010] as well as monotonic increases in brain activity in areas associated with working memory [@Jonides1997; @Owen2005].
However, reliability measures of the n-back task are mixed, presumably due to ceiling effects in performance in the easiest level [@Jaeggi2010].
Additionally, associations of n-back performance and measures such as executive functioning and fluid intelligence are often inconsistent [@Jaeggi2010].

A way to quantify the subjective cost of each n-back level has been developed by Westbrook, Kester, and Braver [-@Westbrook2013], called the Cognitive Effort Discounting Paradigm (COG-ED).
First, the participants complete the n-back levels to familiarize themselves with the task.
Then, level one is compared with each more difficult level by asking the participants to decide between receiving 2\$ for the more difficult level or 1\$ for level one.
If they choose the more difficult level, the reward for level one increases by 0.50\$, if the choose level one, it decreases by 0.50\$.
This is repeated five more times, with each adjustment of the level one reward being half as big as in the previous step, while the reward for the more difficult level remains fixed at 2\$.
The idea is to estimate the point of subjective equivalence, i.e. the monetary ratio in which both offers are equally preferred [@Westbrook2013]. 
The subjective value (SV) of each difficult level is then calculated by dividing the final reward value of level one by the fixed 2\$ reward of the more difficult level.
Westbrook et al. [-@Westbrook2013] used these SVs to investigate inter-individual differences in effort discounting (ED) by computing an area under the curve (AUC).
Younger participants showed lower ED, i.e. they needed a lower monetary incentive for choosing the more difficult levels over level one.

## Effort discounting and Need for Cognition 
The individual degree of ED in the study by Westbrook et al. [-@Westbrook2013] was also associated with the participants' Need for Cognition (NFC) score, a personality trait describing individuals who actively seek and enjoy effortful cognitive activities [@Cacioppo1982].
Westbrook et al. [-@Westbrook2013] conceptualized NFC as a trait measure of effortful task engagement, providing a subjective self-report of ED for each participant which could then be related to the SVs as an objective measure of ED.
On the surface, this association stands to reason, as individuals with higher NFC are more motivated to mobilize cognitive effort because they perceive it as intrinsically rewarding.
However, the relation of NFC and SVs might be confounded with task performance itself, since subjective task values have been shown to depend on both the exerted effort [@Wang2017] and the expected performance [@Yee2021].
Findings on NFC and n-back performance are heterogenous.
On one hand individuals with higher NFC neither had better n-back performance [@Gaertner2021] nor better working memory [@Fleischhauer 2010; @Hill2013], on the other hand they showed greater attention allocation [@Enge2008] and brain flexibility [@He2019].
Nevertheless, a possible association of NFC and task performance might be secondary, since task load has been shown to be a better predictor of SVs than task performance [@Culbreth2016; @Westbrook2013; @Westbrook2019].
But since other studies utilizing the COG-ED paradigm found the association of NFC and SVs to disappear after correcting for performance [@Kramer2021] or found no association of NFC and SVs at all [@Crawford2021], more research is needed to shed light on this issue.

## Revising the COG-ED paradigm
The present study contributes to the investigation of effort and SVs by changing one fundamental assumption of the original COG-ED paradigm: The assumption that the easiest n-back level has the highest SV.
We adapted the COG-ED paradigm in such a way that it allows the computation of SVs for different n-back levels without presuming that all individuals inherently prefer the easiest level (i.e., 1-back).
Figure 1 illustrates how different modifications of the COG-ED paradigm by Westbrook et al. [-@Westbrook2013] return SVs that do or do not reflect the true preference of a hypothetical participant, who likes 2-back the most, 3-back less, and 1-back the least.
The COG-ED paradigm sets the SV of 1-back to 1, regardless of the response pattern.
Adding an ED round comparing 2-back and 3-back allows the SVs of those two levels to be more differentiated, but leaves the SV of 1-back unchanged.
Adding three ED rounds comparing the same levels but using the easier level as reference does approach the true preference, but has two disadvantages.
First, the SVs are still distorted by the non-true SVs returned by the original paradigm, and second, including more task levels would lead to an exponential growth of necessary comparisons.
Therefore, the solution lies in reducing the number of necessary comparisons by presenting an ED round for each possible pair of levels, and by starting each ED round with a choice between equal prices.
For example, the participant is presented with the choice of receiving 1€ for 2-back or 1€ for 4-back.
The n-back level chosen by the participant will then be used as the level with a flexible value, which starts at 1€ and is changed in every iteration.
The n-back level that was not chosen will be set to a fixed value of 2€.
This procedure allows to compute SVs based on actual individual preference instead of objective task load.
Each level's SV is calculated as the mean of this level's SVs from all comparisons in which it appeared.
If the participant has a clear preference for one level, this level's SV will be 1.
If not, then no level's SV will be 1, but each level's SV can still be interpreted as an absolute value and in relation to the other levels' SVs, so the computation of an AUC and therefore the quantification of the participant's ED behaviour is still possible.
Since we aim to establish this paradigm for the assessment of tasks with no objective task load, e.g. emotion regulation tasks, we call it the Cognitive and Emotion Regulation Effort Discounting Paradigm (COG-ER-ED).
In the present study, we will validate the COG-ER-ED paradigm by conceptually replicating the findings of Westbrook et al. [-@Westbrook2013].
Additionally, we will compare the ED behaviour of participants regarding the n-back task and an emotion regulation task.
The COG-ED paradigm has been applied to tasks with different domains before, showing that SVs across task domains correlate [@Crawford2021], but these tasks had an objective order of task load in the form of increasing n-back levels or decreasing intensity of auditory signals.

## Hypotheses
Our hypotheses were derived from the results of Westbrook et al. [-@Westbrook2013].
Regarding the associations of subjective and objective task load measures we hypothesized that (1a) performance measured by signal detection *d'* declines with increasing n-back level, (1b) performance measured by reaction time declines with increasing n-back level, and (1c) perceived task load increases with increasing n-back level.
Regarding the associations of task load and ED we hypothesized that (2a) SVs decline with increasing n-back level, and (2b) SVs decline with increasing n-back level even after controlling for declining task performance.
And regarding individual differences in ED we hypothesized that (3a) SVs predict individual NFC scores, and (3b) perceived task load does not predict individual NFC scores.
However, since NFC is conceptually related to cognitive but not physical effort, we added the hypothesis that (3c) perceived mental load and perceived effort predict individual NFC scores.

```{r libraries, echo=FALSE, message=FALSE, warning=FALSE}

  library(here)         # to set a directory without defined paths, "here" package
  library(tidyverse)    # plotting and managing data, "tidyverse" package
  library(bayestestR)   # computing area under the curve, "bayestestR" package

```

```{r import, echo=FALSE, message=FALSE, warning=FALSE}

  # set top level directory to source file

  here::i_am("flag_project_root_COGERED.txt")
  
  # import n-back and effort discounting data into a list each

  datalist_nback = lapply(list.files(here("04_RawData", "Sampledata"), pattern = '.*nback.*csv', full.names = TRUE),
                          read.csv, stringsAsFactors = FALSE, header = TRUE)
  datalist_ED = lapply(list.files(here("04_RawData", "Sampledata"), pattern = '.*_ED.*csv', full.names = TRUE),
                          read.csv, stringsAsFactors = FALSE, header = TRUE)
  
  # create empty data frames for loops to feed into
  
  data_nback <- data.frame(subject = character(), level = double(), target = character(),
                           response = character(), correct = double(), rt = double())
  data_ED <- data.frame(subject = character(), step = double(), choice = character(),
                           LBvalue = double(), LBlevel = double(), RBvalue = double(), RBlevel = double())

  
  # put relevant data into a dataframes
  
  for (i in 1:length(datalist_nback)) {
    
    newdata <- data.frame(datalist_nback[[i]][["Participant"]], datalist_nback[[i]][["currentlevel"]],
                          datalist_nback[[i]][["Stimulus"]], datalist_nback[[i]][["trial_resp.keys"]],
                          datalist_nback[[i]][["trial_resp.corr"]], datalist_nback[[i]][["trial_resp.rt"]])
    colnames(newdata) <- names(data_nback)
    data_nback <- rbind(data_nback, newdata)
  }
  
  for (i in 1:length(datalist_ED)) {
    
    newdata <- data.frame(datalist_ED[[i]][["Participant"]][2:length(datalist_ED[[i]][["Participant"]])],
                          datalist_ED[[i]][["EDround.thisN"]][2:length(datalist_ED[[i]][["EDround.thisN"]])],
                          datalist_ED[[i]][["EDclick.clicked_name"]][2:length(datalist_ED[[i]][["EDclick.clicked_name"]])],
                          datalist_ED[[i]][["EDleftbutton.value"]][2:length(datalist_ED[[i]][["EDleftbutton.value"]])],
                          datalist_ED[[i]][["EDleftbutton.nback"]][2:length(datalist_ED[[i]][["EDleftbutton.nback"]])],
                          datalist_ED[[i]][["EDrightbutton.value"]][2:length(datalist_ED[[i]][["EDrightbutton.value"]])],
                          datalist_ED[[i]][["EDrightbutton.nback"]][2:length(datalist_ED[[i]][["EDrightbutton.nback"]])])
    colnames(newdata) <- names(data_ED)
    data_ED <- rbind(data_ED, newdata)
  }
  
  # replace some columns with 'easy to work with' values
  
  # the target column will contain 1 for targets and 0 for all non-targets
  data_nback[data_nback == "Target"] <- 1
  data_nback[data_nback == "Pretarget"|data_nback == "Lure"|data_nback == "Distractor"] <- 0
  data_nback$target <- as.numeric(data_nback$target)
  # the response column will contain 1 for responses and 0 for all non-responses
  data_nback[data_nback == "left"|data_nback == "right"] <- 1
  data_nback[data_nback == "None"] <- 0
  data_nback$response <- as.numeric(data_nback$response)
  # the choice column will contain 1 for the left button and 2 for the right button
  data_ED[data_ED == "EDleftbutton"] <- 1
  data_ED[data_ED == "EDrightbutton"] <- 2
  data_ED$choice <- as.numeric(data_ED$choice)
  
  # since only the last choice of each comparison is relevant, we will keep only those rows
  
  data_ED <- data_ED[data_ED$step == 6,]
  data_ED <- subset(data_ED, select = -c(step))
  
  # import questionnaire data from RedCap
  
  data_quest <- read.csv(here("04_RawData", "Sampledata", "COGERED_DATA.csv"), stringsAsFactors = FALSE, header = TRUE)
  colnames(data_quest)[1] <- "set" # rename the first column
  
  # remove unnecessary variables from questionnaire data frame
  
  data_quest <- subset(data_quest, select = -c(vl, date, preparatory_coged_complete, general_questions_timestamp, state,
                                               general_questions_complete, inclusion, inclusion_0___1, inclusion_0___2, inclusion_0_2,
                                               researcher_questions_complete, nasatlx_timestamp, nasatlx_complete, t1_psychopy_ed_csv,
                                               t1_psychopy_ed_psydat, t1_psychopy_nback_csv, t1_psychopy_log, t1_psychopy_nback_psydat,
                                               t1_psychopy_randch_log, t1_psychopy_randch_psydat, files_coged_complete, record_id_2, vl_er,
                                               date_er, humid_bef_er, preparatory_ered_complete, emg_eeg, emg_vhdr, emg_vmrk,
                                               er_ed_psychopy_txt, er_ed_psychopy_psydat, files_ered_complete, followup_ered_timestamp,
                                               nachb_01, nachb_01_inhalt, nachb_02, nachb_02_inhalt, nachb_03, nachb_07, nachb_07_inhalt,
                                               nachb_08, nachb_08_inhalt, nachb_08_haeufig, nachb_08_zurueck, followup_ered_complete,
                                               nfc_timestamp, nfc_complete, bis_11_timestamp, bis_11_complete, bscs_timestamp,
                                               bscs_complete, srs_timestamp, srs_complete, erq_erqse_timestamp, erq_erqse_complete,
                                               who5_timestamp, who5_complete, acs_timestamp, acs_complete, cdrisc_timestamp,
                                               cdrisc_complete, flexer_timestamp, flexer_complete))

```

# Methods

We used *R Studio* [@RCT2020; @RStudioTeam2020] with the main packages *tidyverse* [@Wickham2019] and *basetestR* [@Makowski2019] for all our analyses.
The R Markdown file used to analyze the data and write this document, as well as the raw data and the materials are freely available at github.com/ChScheffel/COG-ER-ED.

## Questionnaires
To assess perceived task load, we used the NASA Task Load Index (NTLX) [@Hart1988], a 6-item questionnaire with the dimensions mental load, physical load, effort, frustration, performance, and time pressure.
Need for Cognition was assessed using the 16-item short form of the Need for Cognition Scale [@Bless1994; @Cacioppo1984].
Several other personality questionnaires were used in this study but are the topic of the registered report for the second lab session regarding ED in emotion regulation tasks and will not be analyzed here.
A full list of questionnaires and measures can be found in Appendix 1.

## Procedure
Participants for the pilot study were recruited using the software *ORSEE* [@Greiner2015].
The final sample consisted of $N=$ `r length(datalist_ED)` participants (`r round((table(data_quest$gender)[2]/length(datalist_ED))*100, digits = 1)`% female, $M=$`r round(mean(data_quest$age, na.rm = TRUE), digits = 1)`($SD=$`r round(sd(data_quest$age, na.rm = TRUE), digits = 1)`) years old).
Each participant completed two sessions in the lab one week apart, and a battery of personality questionnaires at least two days after the second session.
In the first session, participants provided informed consent and demographic data before completing the computer-based paradigm.
The paradigm started with the n-back levels one to four, presented sequentially with two runs per level, consisting of 64 consonants (16 targets, 48 non-targets) per run.
The levels were referred to by colour (1-back black, 2-back red, 3-back blue, 4-back green) to avoid anchor effects in the ED procedure.
After each level, participants filled out the NTLX on a tablet to provide a state measure of cognitive effort.
Then, they completed the ED procedure on screen, where each possible pairing of the four n-back levels was presented in a randomized order.
Participants were instructed to decide as realistically as possible, because one of their choices from the last iteration steps would be randomly chosen for one final run of n-back.
The level and its monetary value were presented on screen and participants completed one run, but this was only to incentivise truthful behaviour in the ED procedure, so the n-back data of this part was not analyzed.
The second session consisted of an emotion regulation task with negative pictures and the instruction to suppress facial reactions, detach cognitively from the picture content, and distract oneself, respectively.
The paradigm followed the same structure of task, ED procedure, and repetition of a random "level" as in session one.
There were many more measures and hypotheses regarding session two, which will be the topic of a different registered report.
Two days after the second session, participants received a link to the NFC scale and other personality questionnaires to provide a trait measure of preference for cognitive effort.
Participants received 8€ per hour or course credit for participation, plus payment for the randomly chosen level.
Study data were collected and managed using REDCap electronic data capture tools hosted at Technische Universität Dresden [@Harris2009; @Harris2019].

## Analysis
We conducted all analysis as described in Westbrook et al. [-@Westbrook2013].
The performance measure *d'* was computed as the difference of the *z*-transformed hit rate and the *z*-transformed false alarm rate [@Macmillan1990].
Declining performance was investigated by calculating an analysis of variance (ANOVA) with three linear contrasts comparing *d'* between two levels of 2-, 3-, and 4-back at a time.
Another ANOVA with three linear contrasts was computed to compare the mean reaction time (RT) between two levels of 2-, 3-, and 4-back at a time.
To investigate changes in NTLX ratings, six ANOVAs were computed, one for each NTLX subscale, and each with six linear contrasts comparing the ratings between two levels of 1-, 2-, 3-, and 4-back at a time.
The SVs were calculated by adding or subtracting the final iteration value of 0.015625 from the monetary value of the flexible level for each ED round, depending on the participant's choice in the last iteration.
Then, the final monetary values were divided by 2€, and the SV of each level per participant was computed by averaging all final monetary values of each level, regardless of whether it was fixed or flexible.
An ANOVA with six linear contrasts was computed, comparing the SVs between two levels of 1-, 2-, 3-, and 4-back at a time.
Each ANOVA in the analysis was followed up by a Tukey's test.
To determine the influence of task performance in the association of SVs and n-back level, we set up a multi-level model.
**MLM explanation goes here**
The association of ED and NFC was done using three separate regressions.
One regression used the AUC of each participant's SVs to predict their NFC score.
The second regression additionally included the mean of the NTLX subscales' AUCs of each participant as a predictor.
And the last regression used the AUC of each participant's SV, the AUC of the NTLX mental load subscale, and the AUC of the NTLX effort subscale to predict each participant's NFC score.


```{r SVcomputation, echo=FALSE, message=FALSE, warning=FALSE}

  # apply the addition or subtraction of 0.015625 to the last choices

  for (i in 1:nrow(data_ED)) {
    
    data_ED$fixedlevel[i] <- data_ED[i,grep("Bvalue", colnames(data_ED))[which(data_ED[i,grep("Bvalue", colnames(data_ED))] == 2.00)] + 1]
    data_ED$flexlevel[i] <- data_ED[i,grep("Bvalue", colnames(data_ED))[which(data_ED[i,grep("Bvalue", colnames(data_ED))] != 2.00)] + 1]
    
    if (data_ED$choice[i] == 1) {
      if (data_ED$LBvalue[i] == 2.00) {
        data_ED$flexvalue[i] <- round(data_ED$RBvalue[i] + 0.015625, digits = 2)
      } else {
        data_ED$flexvalue[i] <- round(data_ED$LBvalue[i] - 0.015625, digits = 2)
      }
    } else {
      if (data_ED$RBvalue[i] == 2.00) {
        data_ED$flexvalue[i] <- round(data_ED$LBvalue[i] + 0.015625, digits = 2)
      } else {
        data_ED$flexvalue[i] <- round(data_ED$RBvalue[i] - 0.015625, digits = 2)
      }
    }
    
  }

  # create vector indicating in which rows the data of a new subject begins

  subjectindex <- c(1,which(data_ED$subject != dplyr::lag(data_ED$subject)),nrow(data_ED))
  
  # create empty data frame for the loop to feed into
  
  data_SV <- data.frame(subject = character(), level = double(), sv = double())
  
  # compute subjective values per n-back level and feed into data frame
  
  for (i in 1:(length(subjectindex)-1)) {
    
    # initialize empty vectors
    
    tempone <- double()
    temptwo <- double()
    tempthree <- double()
    tempfour <- double()
    
    # check for every number, whether it appears in the fixedlevel and flexlevel columns
    # divide flexvalue by 2 if it appears in the fixedlevel columns
    # append 1 if it appears in the flexlevel column
    
    # for 1-back
    
        if (is_empty(which(data_ED$fixedlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 1)) == FALSE) {
          tempone <- append(tempone, data_ED$flexvalue[subjectindex[i]-1 +
                                                         which(data_ED$fixedlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 1)]/2)
        } else {
          # do nothing
        }
        
        if (is_empty(which(data_ED$flexlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 1)) == FALSE) {
          tempone <- append(tempone, rep(1, length(which(data_ED$flexlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 1))))
        } else {
          # do nothing
        }
    
    # for 2-back
    
        if (is_empty(which(data_ED$fixedlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 2)) == FALSE) {
          temptwo <- append(temptwo, data_ED$flexvalue[subjectindex[i]-1 +
                                                         which(data_ED$fixedlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 2)]/2)
        } else {
          # do nothing
        }
        
        if (is_empty(which(data_ED$flexlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 2)) == FALSE) {
          temptwo <- append(temptwo, rep(1, length(which(data_ED$flexlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 2))))
        } else {
          # do nothing
        }
    
    # for 3-back
    
        if (is_empty(which(data_ED$fixedlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 3)) == FALSE) {
          tempthree <- append(tempthree, data_ED$flexvalue[subjectindex[i]-1 +
                                                             which(data_ED$fixedlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 3)]/2)
        } else {
          # do nothing
        }
        
        if (is_empty(which(data_ED$flexlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 3)) == FALSE) {
          tempthree <- append(tempthree, rep(1, length(which(data_ED$flexlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 3))))
        } else {
          # do nothing
        }
    
    # for 4-back
    
        if (is_empty(which(data_ED$fixedlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 4)) == FALSE) {
          tempfour <- append(tempfour, data_ED$flexvalue[subjectindex[i]-1 +
                                                           which(data_ED$fixedlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 4)]/2)
        } else {
          # do nothing
        }
        
        if (is_empty(which(data_ED$flexlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 4)) == FALSE) {
          tempfour <- append(tempfour, rep(1, length(which(data_ED$flexlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 4))))
        } else {
          # do nothing
        }
    
    # put the mean subjective value of the three values per n-back level in the respective column and add to data frame
    
    newdata <- data.frame(subject = rep(data_ED$subject[subjectindex[i]],4),
                          level = c(1:4),
                          sv = c(mean(tempone), mean(temptwo), mean(tempthree), mean(tempfour)))
    data_SV <- rbind(data_SV, newdata)
    
  }
  
  # remove temporary variables
  
  remove(tempone, temptwo, tempthree, tempfour)
  
```

```{r Hypothesis_1a, echo=FALSE, message=FALSE, warning=FALSE}

  # H1a: Performance measured by signal detection d’ declines with increasing n-back level.

  # set the number of targets and non-targets, so in case the paradigm will be changed it is easily accessible
  # they are multiplied by 2, because there are two runs per n-back level

  num_targets <- 16*2
  num_nontargets <- 48*2
  
  # compute index of rows in which the levels change
  
  levelindex <- c(1,which(data_nback$level != dplyr::lag(data_nback$level)),nrow(data_nback))
  
  # set up empty data frame for the loop to feed into
  
  dprime <- data.frame(subject = character(), level = double(), hitrate = double(), falsealarmrate = double())
  
  # calculate hits and false alarms per participant
  
  for (i in 1:(length(levelindex)-1)) {
    
    hits <- length(which(data_nback$target[c(levelindex[i]:(levelindex[i+1])-1)] == 1 &
                           data_nback$correct[c(levelindex[i]:(levelindex[i+1])-1)] == 1) + (levelindex[i]-1))
    falsealarms <- length(which(data_nback$target[c(levelindex[i]:(levelindex[i+1])-1)] == 0 &
                           data_nback$correct[c(levelindex[i]:(levelindex[i+1])-1)] == 0) + (levelindex[i]-1))
    newdata <- data.frame(subject = data_nback$subject[levelindex[i]],
                          level = data_nback$level[levelindex[i]],
                          hitrate = hits/num_targets,
                          falsealarmrate = falsealarms/num_nontargets)
    dprime <- rbind(dprime, newdata)
    
  }
  
  # z-transform the hit rate and the false alarm rate
  
  for (i in 1:4) {
    
    # calculate the mean and sd of hit rate and false alarm rate per n-back level i
    
    mean_hitrate <- mean(dprime$hitrate[dprime$level == i])
    sd_hitrate <- sd(dprime$hitrate[dprime$level == i])
    mean_falsealarmrate <- mean(dprime$falsealarmrate[dprime$level == i])
    sd_falsealarmrate <- sd(dprime$falsealarmrate[dprime$level == i])
    
    for (j in 1:length(which(dprime$level == i))) {
      
      # z-transform each subject j's hit rate and false alarm rate within the level i
      
      dprime$hitrate[which(dprime$level == i)[j]] <- (dprime$hitrate[which(dprime$level == i)[j]] - mean_hitrate)/sd_hitrate
      dprime$falsealarmrate[which(dprime$level == i)[j]] <- (dprime$falsealarmrate[which(dprime$level == i)[j]] -
                                                               mean_falsealarmrate)/sd_falsealarmrate
    }
  }
  
  # remove temporary variables
  
  remove(mean_hitrate, sd_hitrate, mean_falsealarmrate, sd_falsealarmrate)
  
  # calculate d'
  
  dprime$d <- dprime$hitrate - dprime$falsealarmrate
  
  # ANOVA with three linear contrasts, contrasting the d’ of two n-back levels (2,3,4) at a time
  
      # make a temporary copy of the dprime data frame without 1-back
      
      h1a_data <- dprime[dprime$level != 1,]
      h1a_data$level <- as.factor(h1a_data$level)
      
      # define contrasts
      
      contrasts(h1a_data$level) <- cbind(c(1,-1,0), c(0,1,-1), c(1,0,-1))
      
      # calculate ANOVA
      
      hypothesis1a_anova <- summary(aov(h1a_data$d ~ h1a_data$level))
      hypothesis1a_posthoc <- TukeyHSD(aov(h1a_data$d ~ h1a_data$level))
      remove(h1a_data)

```

```{r Hypothesis_1b, echo=FALSE, message=FALSE, warning=FALSE}

  # H1b: Performance measured by reaction time declines with increasing n-back level.
  
  # set up empty data frame for the loop to feed into
  
  rt <- data.frame(subject = character(), level = double(), meanrt = double())
  
  # calculate mean reaction time per participant per level
  
  for (i in 1:(length(levelindex)-1)) {
    
    meanrt <- mean(data_nback$rt[which(data_nback$correct[c(levelindex[i]:(levelindex[i+1])-1)] == 1)
                                 +(levelindex[i]-1)], na.rm = TRUE)
    
    newdata <- data.frame(subject = data_nback$subject[levelindex[i]],
                          level = data_nback$level[levelindex[i]],
                          meanrt = meanrt)
    rt <- rbind(rt, newdata)
    
  }

  # ANOVA with three linear contrasts, contrasting the mean rt of two n-back levels (2,3,4) at a time
  
      # make a temporary copy of the rt data frame without 1-back
      
      h1b_data <- rt[rt$level != 1,]
      h1b_data$level <- as.factor(h1b_data$level)
      
      # define contrasts
      
      contrasts(h1b_data$level) <- cbind(c(1,-1,0), c(0,1,-1), c(1,0,-1))
      
      # calculate ANOVA
      
      hypothesis1b_anova <- summary(aov(h1b_data$meanrt ~ h1b_data$level))
      hypothesis1b_posthoc <- TukeyHSD(aov(h1b_data$meanrt ~ h1b_data$level))
      remove(h1b_data)

```

```{r Hypothesis_1c, echo=FALSE, message=FALSE, warning=FALSE}

  # H1c: Ratings on all NTLX dimensions increase with increasing n-back level.

  # compute index of rows in which the data sets change
  
  setindex <- c(1,which(data_quest$set != dplyr::lag(data_quest$set)),nrow(data_quest))

  # set up empty data frame for the loop to feed into

  data_ntlx <- data.frame(subject = character(), level = double(),
                          mental = double(), physical = double(), time = double(),
                          performance = double(), effort = double(), frustration = double())
  
  # feed NTLX data per participant per level into data frame
  
  for (i in 1:(length(setindex)-1)) {
    
    for (j in 1:4) {
      
      newdata <- data.frame(subject = data_quest$subject[setindex[i]], level = j,
                            mental = data_quest$nasa_tlx_01[setindex[i]+j+2],
                            physical = data_quest$nasa_tlx_02[setindex[i]+j+2],
                            time = data_quest$nasa_tlx_03[setindex[i]+j+2],
                            performance = data_quest$nasa_tlx_04[setindex[i]+j+2],
                            effort = data_quest$nasa_tlx_05[setindex[i]+j+2],
                            frustration = data_quest$nasa_tlx_06[setindex[i]+j+2])
      data_ntlx <- rbind(data_ntlx, newdata)
    }
  }

  # six ANOVAs with six linear contrasts, contrasting the subscale scores of two n-back levels (1,2,3,4) at a time
  
      # make a temporary copy of the NTLX data frame
      
      h1c_data <- data_ntlx
      h1c_data$level <- as.factor(h1c_data$level)
      
      # define contrasts
      
      contrasts(h1c_data$level) <- cbind(c(1,-1,0,0), c(0,1,-1,0), c(0,0,1,-1),
                                         c(1,0,-1,0), c(1,0,0,-1), c(0,1,0,-1))
      
      # calculate ANOVAs
      
      hypothesis1c1_anova <- summary(aov(h1c_data$mental ~ h1c_data$level))
      hypothesis1c1_posthoc <- TukeyHSD(aov(h1c_data$mental ~ h1c_data$level))

      hypothesis1c2_anova <- summary(aov(h1c_data$physical ~ h1c_data$level))
      hypothesis1c2_posthoc <- TukeyHSD(aov(h1c_data$physical ~ h1c_data$level))

      hypothesis1c3_anova <- summary(aov(h1c_data$time ~ h1c_data$level))
      hypothesis1c3_posthoc <- TukeyHSD(aov(h1c_data$time ~ h1c_data$level))

      hypothesis1c4_anova <- summary(aov(h1c_data$performance ~ h1c_data$level))
      hypothesis1c4_posthoc <- TukeyHSD(aov(h1c_data$performance ~ h1c_data$level))

      hypothesis1c5_anova <- summary(aov(h1c_data$effort ~ h1c_data$level))
      hypothesis1c5_posthoc <- TukeyHSD(aov(h1c_data$effort ~ h1c_data$level))

      hypothesis1c6_anova <- summary(aov(h1c_data$frustration ~ h1c_data$level))
      hypothesis1c6_posthoc <- TukeyHSD(aov(h1c_data$frustration ~ h1c_data$level))

      remove(h1c_data)

```

```{r Hypothesis_2a, echo=FALSE, message=FALSE, warning=FALSE}

  # H2a: Subjective values decline with increasing n-back level.

  # ANOVA with six linear contrasts, contrasting the SVs of two n-back levels (1,2,3,4) at a time
  
  # make a temporary copy of the SV data frame
  
  h2a_data <- data_SV
  h2a_data$level <- as.factor(h2a_data$level)
  
  # define contrasts
  
  contrasts(h2a_data$level) <- cbind(c(1,-1,0,0), c(0,1,-1,0), c(0,0,1,-1),
                                     c(1,0,-1,0), c(1,0,0,-1), c(0,1,0,-1))
  
  # calculate ANOVAs
  
  hypothesis2a_anova <- summary(aov(h2a_data$sv ~ h2a_data$level))
  hypothesis2a_posthoc <- TukeyHSD(aov(h2a_data$sv ~ h2a_data$level))
  
  remove(h2a_data)

```

```{r Hypothesis_2b, echo=FALSE, message=FALSE, warning=FALSE}

  # H2b: Subjective values decline with increasing n-back level, even after controlling for declining task
  # performance measured by signal detection d’ and reaction time.


```

```{r Hypothesis_3a, echo=FALSE, message=FALSE, warning=FALSE}

  # H3a: Subjective values predict individual NCS scores.

  # create an index for the rows in which the participants change

  subjectindex <- c(1,which(data_SV$subject != dplyr::lag(data_SV$subject)),nrow(data_SV))

  # prepare empty data frame for the loop to feed into

  data_hyp3 <- data.frame(subject = character(), auc_sv = double())

  # calculate AUC of SVs per subject
  
  for (i in 1:(length(subjectindex)-1)) {
    
    newdata <- data.frame(subject = data_SV$subject[subjectindex[i]],
                          auc_sv = auc(data_SV$level[subjectindex[i]:(subjectindex[i+1]-1)], data_SV$sv[subjectindex[i]:(subjectindex[i+1]-1)],
                                   method = "trapezoid", sort = FALSE))
    data_hyp3 <- rbind(data_hyp3, newdata)
    
  }

  # prepare temporary data frame for loop to feed into
  
  data_nfc <- data.frame(subject = character(), nfc = double())
  
  # calculate NFC scores for every subject
  
  for (i in 1:(length(setindex)-1)) {
    
    nfc <- data_quest[setindex[i] + 2, grep("nfc", colnames(data_quest))]
    nfc[ ,c(4,6,7,8,9,10,11,12,15,16)] <-  nfc[ ,c(4,6,7,8,9,10,11,12,15,16)] * -1
    
    data_nfc <- rbind(data_nfc, data.frame(subject = data_quest$subject[setindex[i]],
                                           nfc = sum(nfc)))
  }
  
  # merge the NFC data frame into the AUC data frame by row
  
  data_hyp3 <- merge(data_hyp3, data_nfc)
  
  # delete temporary variables
  
  remove(nfc, data_nfc)
  
  # calculate linear model to estimate prediction of NFC by SVs
  
  hypothesis3a <- summary(lm(data_hyp3$nfc ~ data_hyp3$auc_sv))

```

```{r Hypothesis_3b, echo=FALSE, message=FALSE, warning=FALSE}

  # H3b: NTLX scores do not predict individual NCS scores.
  
  # create an index for the rows in which the participants change

  subjectindex <- c(1,which(data_ntlx$subject != dplyr::lag(data_ntlx$subject)),nrow(data_ntlx))
  
  # prepare temporary data frame for loop to feed into
  
  ntlx <- data.frame(subject = character(), auc_mental = double(), auc_physical = double(), auc_time = double(),
                          auc_performance = double(), auc_effort = double(), auc_frustration = double())

  # calculate AUCs per NTLX subscale per participant

  for (i in 1:(length(subjectindex)-1)) {
    
    newdata <- data.frame(subject = data_ntlx$subject[subjectindex[i]],
                          auc_mental = auc(data_ntlx$level[subjectindex[i]:(subjectindex[i+1]-1)],
                                           data_ntlx$mental[subjectindex[i]:(subjectindex[i+1]-1)], method = "trapezoid", sort = FALSE),
                          auc_physical = auc(data_ntlx$level[subjectindex[i]:(subjectindex[i+1]-1)],
                                           data_ntlx$physical[subjectindex[i]:(subjectindex[i+1]-1)], method = "trapezoid", sort = FALSE),
                          auc_time = auc(data_ntlx$level[subjectindex[i]:(subjectindex[i+1]-1)],
                                           data_ntlx$time[subjectindex[i]:(subjectindex[i+1]-1)], method = "trapezoid", sort = FALSE),
                          auc_performance = auc(data_ntlx$level[subjectindex[i]:(subjectindex[i+1]-1)],
                                           data_ntlx$performance[subjectindex[i]:(subjectindex[i+1]-1)], method = "trapezoid", sort = FALSE),
                          auc_effort = auc(data_ntlx$level[subjectindex[i]:(subjectindex[i+1]-1)],
                                           data_ntlx$effort[subjectindex[i]:(subjectindex[i+1]-1)], method = "trapezoid", sort = FALSE),
                          auc_frustration = auc(data_ntlx$level[subjectindex[i]:(subjectindex[i+1]-1)],
                                           data_ntlx$frustration[subjectindex[i]:(subjectindex[i+1]-1)], method = "trapezoid", sort = FALSE))
    ntlx <- rbind(ntlx, newdata)
    
  }
  
  # add column containing the average of the NTLX subscale AUCs
  
  ntlx <- cbind(ntlx, auc_ntlx = rowMeans(ntlx[ ,grep("auc", colnames(ntlx))]))
  
  # merge data frames based on subject
  
  data_hyp3 <- merge(data_hyp3, ntlx)
  
  # delete temporary data frame
  
  remove(ntlx, newdata)
  
  # compute multiple linear regression to predict NCS based on SV AUC and NTLX AUC
  
  hypothesis3b <- summary(lm(data_hyp3$nfc ~ data_hyp3$auc_sv + data_hyp3$auc_ntlx))

```

```{r Hypothesis_3c, echo=FALSE, message=FALSE, warning=FALSE}

  # H3c: The NTLX dimensions effort and mental load predict individual NCS scores.

  # compute multiple linear regression to predict NCS based on SV AUC, Effort AUC and Mental Load AUC
  
  hypothesis3c <- summary(lm(data_hyp3$nfc ~ data_hyp3$auc_sv + data_hyp3$auc_mental + data_hyp3$auc_effort))

```

