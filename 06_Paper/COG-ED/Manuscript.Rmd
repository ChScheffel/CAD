---
title             : "When easy is not preferred: An effort discounting paradigm for estimating subjective values of tasks"
shorttitle        : "The CERED paradigm for estimating subjective values"
author: 
  - name          : "Josephine Zerna"
    orcid         : "0000-0003-2892-884X"
    affiliation   : "1,*"
    corresponding : yes
    address       : "Zellescher Weg 17, 01069 Dresden, Germany"
    email         : "josephine.zerna@tu-dresden.de"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - Conceptualization
      - Methodology
      - Formal analysis
      - Investigation
      - Project administration
      - Software
      - Visualization
      - Writing - original draft preparation
      - Writing - review & editing
  - name          : "Christoph Scheffel"
    orcid         : "0000-0001-5963-9229"
    affiliation   : "1,*"
    role:
      - Conceptualization
      - Methodology
      - Funding acquisition
      - Investigation
      - Project administration
      - Software
      - Writing - review & editing
  - name          : "Corinna Kührt"
    orcid         : "0000-0002-6418-6479"
    affiliation   : "1"
    role:
      - Formal analysis
      - Writing - original draft preparation
      - Writing - review & editing
      - Visualization
affiliation:
  - id            : "1"
    institution   : "Faculty of Psychology, Technische Universität Dresden, 01069 Dresden, Germany"
authornote: |
  * Shared first authorship
abstract: |
  When individuals set goals, they consider the subjective value (SV) of both the anticipated reward and the required effort, a trade-off that is of great interest to psychological research.
  However, the SV of effort is highly individual, and previous quantification approaches have had two crucial limitations: They presumed a unidirectional relationship between objective task load and the SV of effort, and as a consequence, they could only quantify the SVs of tasks with an objective order of task load.
  One of these approaches is the Cognitive Effort Discounting paradigm by Westbrook et al. (2013).
  We aim to replicate their analysis with our adaptation, the Cognitive and Emotion Regulation Effort Discounting (CERED) paradigm.
  We argue that the CERED paradigm allows two crucial things: Quantifying SVs without assuming that the easiest level is preferred, and quantifying SVs for tasks with no objective order of task load.
  
keywords          : "effort discounting, registered report, specification curve analysis, need for cognition, n-back"
wordcount         : "X"
bibliography      : CERED.bib
floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no
documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
csl               : nature.csl
header-includes   :
    - \usepackage{booktabs}
    - \usepackage{longtable}
    - \usepackage{array}
    - \usepackage{multirow}
    - \usepackage{wrapfig}
    - \usepackage{float}
    - \usepackage{colortbl}
    - \usepackage{pdflscape}
    - \usepackage{tabu}
    - \usepackage{threeparttable}
    - \usepackage{threeparttablex}
    - \usepackage[normalem]{ulem}
    - \usepackage{makecell}
    - \usepackage{xcolor}
    - \usepackage{setspace}\doublespacing
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE, echo=FALSE, message=FALSE, warning=FALSE}

  knitr::opts_chunk$set(echo = TRUE)
  library(bibtex)
  library(here)         # to set a directory without defined paths, "here" package
  library(tidyverse)    # plotting and managing data, "tidyverse" package
  library(bayestestR)   # computing area under the curve, "bayestestR" package
  library(papaja)       # APA conform output, "papaja" package
  library(lmerTest)     # for multilevel modeling
  library(afex)         # compute repeated measures ANOVA, "afex" package
  library(emmeans)      # for custom contrasts in ANOVAs, "emmeans" package
  library(sjPlot)       # plot MLM model fit
  library(kableExtra)   # for great tables in R Markdown
  library(interactions) # for simple slopes analysis
  library(huxtable)     # create huxtable
# library(glmmTMB)      # from the glmmTMB package for multi level models
  library(BayesFactor)  # computing Bayes factors, "BayesFactor" package
  library(ggplot2)      # for plotting, "ggplot2" package
  library(egg)          # for paneling plots, "egg" package

  set_sum_contrasts()   # sets orthogonal contrasts for mixed-effects model 
                        # and rmANOVA globally in order to get meaningful Type-III tests

  # we will add the package versions before submission

```

```{r import, echo=FALSE, message=FALSE, warning=FALSE}

  # set top level directory to source file

  here::i_am("flag_project_root_CERED.txt")
  
  # import n-back and effort discounting data into a list each

  datalist_nback = lapply(list.files(here("04_RawData", "pilot", "COG-ED"), pattern = '.*nback.*csv', full.names = TRUE),
                          read.csv, stringsAsFactors = FALSE, header = TRUE)
  datalist_ED = lapply(list.files(here("04_RawData", "pilot", "COG-ED"), pattern = '.*_ED.*csv', full.names = TRUE),
                          read.csv, stringsAsFactors = FALSE, header = TRUE)
  
  # create empty data frames for loops to feed into
  
  data_nback <- data.frame(subject = character(), level = double(), target = character(),
                           response = character(), correct = double(), rt = double())
  data_ED <- data.frame(subject = character(), step = double(), choice = character(),
                           LBvalue = double(), LBlevel = double(), RBvalue = double(), RBlevel = double())

  
  # put relevant data into data frames
  
  for (i in 1:length(datalist_nback)) {
    
    newdata <- data.frame(datalist_nback[[i]][["Participant"]], datalist_nback[[i]][["currentlevel"]],
                          datalist_nback[[i]][["Stimulus"]], datalist_nback[[i]][["trial_resp.keys"]],
                          datalist_nback[[i]][["trial_resp.corr"]], datalist_nback[[i]][["trial_resp.rt"]])
    colnames(newdata) <- names(data_nback)
    data_nback <- rbind(data_nback, newdata)
  }
  
  for (i in 1:length(datalist_ED)) {
    
    newdata <- data.frame(datalist_ED[[i]][["Participant"]][2:length(datalist_ED[[i]][["Participant"]])],
                          datalist_ED[[i]][["EDround.thisN"]][2:length(datalist_ED[[i]][["EDround.thisN"]])],
                          datalist_ED[[i]][["EDclick.clicked_name"]][2:length(datalist_ED[[i]][["EDclick.clicked_name"]])],
                          datalist_ED[[i]][["EDleftbutton.value"]][2:length(datalist_ED[[i]][["EDleftbutton.value"]])],
                          datalist_ED[[i]][["EDleftbutton.nback"]][2:length(datalist_ED[[i]][["EDleftbutton.nback"]])],
                          datalist_ED[[i]][["EDrightbutton.value"]][2:length(datalist_ED[[i]][["EDrightbutton.value"]])],
                          datalist_ED[[i]][["EDrightbutton.nback"]][2:length(datalist_ED[[i]][["EDrightbutton.nback"]])])
    colnames(newdata) <- names(data_ED)
    data_ED <- rbind(data_ED, newdata)
  }
  
  # change the name of a subject (it has the suffix "_neu" because the paradigm didn't start properly the first time)
  
  data_nback$subject[data_nback$subject == "E12K08_neu"] <- "E12K08"
  data_ED$subject[data_ED$subject == "E12K08_neu"] <- "E12K08"
  
  # remove one subject who did not understand the instructions of the n-back task and reacted only to every n-th stimulus
  
  data_nback <- data_nback[data_nback$subject != "M28B11", ]
  data_ED <- data_ED[data_ED$subject != "M28B11", ]

  # replace some columns with 'easy to work with' values
  
  # the target column will contain 1 for targets and 0 for all non-targets
  
  data_nback[data_nback == "Target"] <- 1
  data_nback[data_nback == "Pretarget"|data_nback == "Lure"|data_nback == "Distractor"] <- 0
  data_nback$target <- as.numeric(data_nback$target)
  
  # the response column will contain 1 for responses and 0 for all non-responses
  
  data_nback[data_nback == "left"|data_nback == "right"] <- 1
  data_nback[data_nback == "None"] <- 0
  data_nback$response <- as.numeric(data_nback$response)
  
  # for the multi level model to be able to assess the influence of post-error trials, we will include that as a regressor
  # so the nback data frame will contain a column of ones and zeros

  # add the "correct" column, but shifted down by one row

  data_nback$postcorrect = c(1,data_nback$correct[1:(length(data_nback$correct)-1)])

  # make sure to avoid transfer from the previous block by marking the first trial of each block as correct

  data_nback$postcorrect[c(1,seq(64,length(data_nback$postcorrect),64))] <- 1
  
  # correct subject code
  data_nback$subject[which(data_nback$subject == "E12K08_neu")] <- "E12K08"
  data_ED$subject[which(data_ED$subject == "E12K08_neu")] <- "E12K08"

  
  # the choice column will contain 1 for the left button and 2 for the right button
  
  data_ED[data_ED == "EDleftbutton"] <- 1
  data_ED[data_ED == "EDrightbutton"] <- 2
  data_ED$choice <- as.numeric(data_ED$choice)
  
  # since only the last choice of each comparison is relevant, we will keep only those rows
  
  data_ED <- data_ED[data_ED$step == 6,]
  data_ED <- subset(data_ED, select = -c(step))
  
  # import questionnaire data from RedCap
  
  data_quest <- read.csv(here("04_RawData", "pilot", "CERED_DATA.csv"), stringsAsFactors = FALSE, header = TRUE)
  colnames(data_quest)[1] <- "set" # rename the first column
  
  # remove the subject who misunderstood the instruction
  
  data_quest <- data_quest[data_quest$set != "M28B11", ]
  
  # remove unnecessary variables from questionnaire data frame
  
  data_quest <- subset(data_quest, select = -c(vl, date, preparatory_coged_complete, general_questions_timestamp, state,
                                               general_questions_complete, inclusion, inclusion_0___1, inclusion_0___2, inclusion_0_2,
                                               researcher_questions_complete, nasatlx_timestamp, nasatlx_complete, t1_psychopy_ed_csv,
                                               t1_psychopy_nback_csv, files_coged_complete, record_id_2, vl_er,
                                               date_er, preparatory_ered_complete, emg_eeg, emg_vhdr, emg_vmrk,
                                               files_ered_complete, followup_ered_timestamp,
                                               nachb_01, nachb_01_inhalt, nachb_02, nachb_02_inhalt, nachb_03, nachb_07, nachb_07_inhalt,
                                               nachb_08, nachb_08_inhalt, nachb_08_haeufig, nachb_08_zurueck, followup_ered_complete,
                                               nfc_timestamp, nfc_complete, bis_11_timestamp, bis_11_complete, bscs_timestamp,
                                               bscs_complete, srs_timestamp, srs_complete, erq_erqse_timestamp, erq_erqse_complete,
                                               who5_timestamp, who5_complete, acs_timestamp, acs_complete, cdrisc_timestamp,
                                               cdrisc_complete, flexer_timestamp, flexer_complete))
  
  # compute index of rows in which the data sets change
  
  setindex <- c(1,which(data_quest$set != dplyr::lag(data_quest$set)),nrow(data_quest))

```

```{r SVcomputation, echo=FALSE, message=FALSE, warning=FALSE}

  # apply the addition or subtraction of 0.015625 to the last choices

  for (i in 1:nrow(data_ED)) {
    
    data_ED$fixedlevel[i] <- data_ED[i,grep("Bvalue", colnames(data_ED))[which(data_ED[i,grep("Bvalue", colnames(data_ED))] == 2.00)] + 1]
    data_ED$flexlevel[i] <- data_ED[i,grep("Bvalue", colnames(data_ED))[which(data_ED[i,grep("Bvalue", colnames(data_ED))] != 2.00)] + 1]
    
    if (data_ED$choice[i] == 1) {
      if (data_ED$LBvalue[i] == 2.00) {
        data_ED$flexvalue[i] <- round(data_ED$RBvalue[i] + 0.015625, digits = 2)
      } else {
        data_ED$flexvalue[i] <- round(data_ED$LBvalue[i] - 0.015625, digits = 2)
      }
    } else {
      if (data_ED$RBvalue[i] == 2.00) {
        data_ED$flexvalue[i] <- round(data_ED$LBvalue[i] + 0.015625, digits = 2)
      } else {
        data_ED$flexvalue[i] <- round(data_ED$RBvalue[i] - 0.015625, digits = 2)
      }
    }
    
  }

  # create vector indicating in which rows the data of a new subject begins

  subjectindex <- c(1,which(data_ED$subject != dplyr::lag(data_ED$subject)),nrow(data_ED))
  
  # create empty data frame for the loop to feed into
  
  data_SV <- data.frame(subject = character(), level = double(), sv = double())
  
  # compute subjective values per n-back level and feed into data frame
  
  for (i in 1:(length(subjectindex)-1)) {
    
    # initialize empty vectors
    
    tempone <- double()
    temptwo <- double()
    tempthree <- double()
    tempfour <- double()
    
    # check for every number, whether it appears in the fixedlevel and flexlevel columns
    # divide flexvalue by 2 if it appears in the fixedlevel columns
    # append 1 if it appears in the flexlevel column
    
    # for 1-back
    
        if (is_empty(which(data_ED$fixedlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 1)) == FALSE) {
          tempone <- append(tempone, data_ED$flexvalue[subjectindex[i]-1 +
                                                         which(data_ED$fixedlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 1)]/2)
        } else {
          # do nothing
        }
        
        if (is_empty(which(data_ED$flexlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 1)) == FALSE) {
          tempone <- append(tempone, rep(1, length(which(data_ED$flexlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 1))))
        } else {
          # do nothing
        }
    
    # for 2-back
    
        if (is_empty(which(data_ED$fixedlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 2)) == FALSE) {
          temptwo <- append(temptwo, data_ED$flexvalue[subjectindex[i]-1 +
                                                         which(data_ED$fixedlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 2)]/2)
        } else {
          # do nothing
        }
        
        if (is_empty(which(data_ED$flexlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 2)) == FALSE) {
          temptwo <- append(temptwo, rep(1, length(which(data_ED$flexlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 2))))
        } else {
          # do nothing
        }
    
    # for 3-back
    
        if (is_empty(which(data_ED$fixedlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 3)) == FALSE) {
          tempthree <- append(tempthree, data_ED$flexvalue[subjectindex[i]-1 +
                                                             which(data_ED$fixedlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 3)]/2)
        } else {
          # do nothing
        }
        
        if (is_empty(which(data_ED$flexlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 3)) == FALSE) {
          tempthree <- append(tempthree, rep(1, length(which(data_ED$flexlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 3))))
        } else {
          # do nothing
        }
    
    # for 4-back
    
        if (is_empty(which(data_ED$fixedlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 4)) == FALSE) {
          tempfour <- append(tempfour, data_ED$flexvalue[subjectindex[i]-1 +
                                                           which(data_ED$fixedlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 4)]/2)
        } else {
          # do nothing
        }
        
        if (is_empty(which(data_ED$flexlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 4)) == FALSE) {
          tempfour <- append(tempfour, rep(1, length(which(data_ED$flexlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 4))))
        } else {
          # do nothing
        }
    
    # put the mean subjective value of the three values per n-back level in the respective column and add to data frame
    
    newdata <- data.frame(subject = rep(data_ED$subject[subjectindex[i]],4),
                          level = c(1:4),
                          sv = c(mean(tempone), mean(temptwo), mean(tempthree), mean(tempfour)))
    data_SV <- rbind(data_SV, newdata)
    
  }
  
  # remove temporary variables
  
  remove(tempone, temptwo, tempthree, tempfour)
  
  # add the SVs trial-wise to the nback-data-frame for the multi-level-model
  
  for (i in 1:nrow(data_nback)) {
    
    data_nback$sv[i] <- data_SV$sv[data_SV$subject == data_nback$subject[i] & data_SV$level == data_nback$level[i]]
    
  }
  
```

```{r NFCcomputation, echo=FALSE, message=FALSE, warning=FALSE}
  
  # prepare temporary data frame for loop to feed into
  
  data_nfc <- data.frame(subject = character(), nfc = double())
  
  # compute index of rows in which the data sets change
  
  setindex <- c(1,which(data_quest$set != dplyr::lag(data_quest$set)),nrow(data_quest))

  # calculate NFC scores for every subject
  
  for (i in 1:(length(setindex)-1)) {
    
    nfc <- data_quest[setindex[i] + 2, grep("nfc", colnames(data_quest))]
    
    # define and invert items to be recoded
    
    nfc[ ,c(4,6,7,8,9,10,11,12,15,16)] <-  nfc[ ,c(4,6,7,8,9,10,11,12,15,16)] * -1
    
    data_nfc <- rbind(data_nfc, data.frame(subject = data_quest$subject[setindex[i]],
                                           nfc = sum(nfc)))
  }
  
  # add the NFC scores trial-wise to the nback-data-frame for the multi-level-model
  
  for (i in 1:nrow(data_nback)) {
    
    data_nback$nfc[i] <- data_nfc$nfc[data_nfc$subject == data_nback$subject[i]]
    
  }
  
  # remove the temporary variables
  
  remove(nfc, data_nfc)

```

# Introduction

In everyday life, effort and reward are closely intertwined [@Botvinick2009].
With each decision a person makes, they have to evaluate whether the effort required to reach a goal is worth being exerted, given the reward they receive when reaching the goal.
A reward is subjectively more valuable if it is obtained with less effort, so the required effort is used as a reference point for estimating the reward value [@Botvinick2009].
However, the cost of the effort itself is also subjective, and research has not yet established which function best describes the relationship between effort and cost [@Kool2018].
Investigating effort and cost is challenging because "effort is not a property of the target task alone, but also a function of the individual's cognitive capacities, as well as the degree of effort voluntarily mobilized for the task, which in turn is a function of the individual's reward sensitivity" [@Kool2018, p. 209].

One task that is often used to investigate effort is the n-back task, a working memory task in which a continuous stream of stimuli, e.g. letters, is presented on screen.
Participants indicate via button press whether the current stimulus is the same as *n* stimuli before, with *n* being the level of difficulty between one and six [@Mackworth1959].
The n-back task is well suited to investigate effort because it is an almost continuous manipulation of task load, as has been shown by monotonic increases in error rates, reaction times [@Jaeggi2010], and brain activity in areas associated with working memory [@Jonides1997; @Owen2005].
However, its reliability measures are mixed, and associations of n-back performance and measures such as executive functioning and fluid intelligence are often inconsistent [@Jaeggi2010].

A way to quantify the subjective cost of each n-back level has been developed by Westbrook, Kester, and Braver [-@Westbrook2013], called the Cognitive Effort Discounting Paradigm (COG-ED).
First, the participants complete the n-back levels to familiarize themselves with the task.
Then, 1-back is compared with each more difficult level by asking the participants to decide between receiving 2\$ for the more difficult level or 1\$ for 1-back.
If they choose the more difficult level, the reward for 1-back increases by 0.50\$, if the choose 1-back, it decreases by 0.50\$.
This is repeated five more times, with each adjustment of the 1-back reward being half of the previous step, while the reward for the more difficult level remains fixed at 2\$.
The idea is to estimate the point of subjective equivalence, i.e. the monetary ratio at which both offers are equally preferred [@Westbrook2013].
The subjective value (SV) of each difficult level is then calculated by dividing the final reward value of 1-back by the fixed 2\$ reward.
Westbrook et al. [-@Westbrook2013] used these SVs to investigate inter-individual differences in effort discounting (ED).
Younger participants showed lower ED, i.e. they needed a lower monetary incentive for choosing the more difficult levels over 1-back.

The individual degree of ED in the study by Westbrook et al. [-@Westbrook2013] was also associated with the participants' Need for Cognition (NFC) score, a personality trait describing individuals who actively seek and enjoy effortful cognitive activities [@Cacioppo1982].
Westbrook et al. [-@Westbrook2013] conceptualized NFC as a trait measure of effortful task engagement, providing a subjective self-report of ED for each participant which could then be related to the SVs as an objective measure of ED.
On the surface, this association stands to reason, as individuals with higher NFC are more motivated to mobilize cognitive effort because they perceive it as intrinsically rewarding.
Additionally, it has been shown that individuals avoid cognitive effort only to a certain degree, possibly to retain a sense of self-control [@Wu2021], a trait more prominent in individuals with high NFC [@Bertrams2012; @Nishiguchi2016; Xu2021].
However, the relation of NFC and SVs might be confounded, since other studies utilizing the COG-ED paradigm found the association of NFC and SVs to disappear after correcting for performance [@Kramer2021] or found no association of NFC and SVs at all [@Crawford2021].
On the other hand, task load has been shown to be a better predictor of SVs than task performance [@Culbreth2016; @Westbrook2013; @Westbrook2019], so more research is needed to shed light on this issue.

The present study changes one fundamental assumption of the original COG-ED paradigm: That the easiest n-back level has the highest SV.
We adapted the COG-ED paradigm in such a way that it allows the computation of SVs for different n-back levels without presuming that all individuals inherently prefer the easiest level.
Figure 1 illustrates how different modifications of the COG-ED paradigm return SVs that do or do not reflect the true preference of a hypothetical participant, who likes 2-back most, 3-back less, and 1-back least.
The COG-ED paradigm sets the SV of 1-back to 1, regardless of the response pattern.
Adding a comparison of 2-back and 3-back allows the SVs of those two levels to be more differentiated, but leaves the SV of 1-back unchanged.
Adding three more comparisons of the same levels but using the easier level as reference does approach the true preference, but has two disadvantages.
First, the SVs are still distorted by the SVs returned by the original paradigm, and second, having more task levels would lead to an exponential increase in comparisons.
Therefore, the solution lies in reducing the number of necessary comparisons by presenting only one ED round for each possible pair of levels, and by starting each round with a choice between equal prices.
For example, the participant is presented with the choice of receiving 1€ for 2-back or 1€ for 4-back.
The level chosen by the participant will then be used as the level with a flexible value, which starts at 1€ and is changed in every iteration.
The level that was not chosen will be set to a fixed value of 2€.
This procedure allows to compute SVs based on actual individual preference instead of objective task load.
Each level's SV is calculated as the mean of this level's SVs from all comparisons in which it appeared.
If the participant has a clear preference for one level, this level's SV will be 1.
If not, then no level's SV will be 1, but each level's SV can still be interpreted as an absolute and relative value, so each participant's ED behaviour can still be quantified.
Since we aim to establish this paradigm for the assessment of tasks with no objective task load, e.g. emotion regulation tasks, we call it the Cognitive and Emotion Regulation Effort Discounting Paradigm (CERED).
In the present study, we will validate the CERED paradigm by conceptually replicating the findings of Westbrook et al. [-@Westbrook2013]. Additionally, we will compare the ED behaviour of participants regarding the n-back task and an emotion regulation task. The full results of the latter will be published in a second Registered Report. The COG-ED paradigm has been applied to tasks with different domains before, showing that SVs across task domains correlate [@Crawford2021], but these tasks had an objective order of task load, which is not the case for emotion regulation.

*Fig.1* Subjective values for an n-back task with three levels, returned by different modifications of the COG-ED paradigm for a participant with the true preference 2-back \> 3-back \> 1-back.

Our hypotheses were derived from the results of Westbrook et al. [-@Westbrook2013], and detailed in the attached design table..
Regarding the associations of subjective and objective task load we hypothesize that (1a) the signal detection parameter *d'* declines with increasing n-back level, (1b) reaction time increases with increasing n-back level, and (1c) perceived task load increases with n-back level.
Regarding the associations of task load and ED we hypothesize that (2a) SVs decline with increasing n-back level, and (2b) SVs decline with increasing n-back level even after controlling for declining task performance.
Here we added they hypothesis that (2c) SVs decline stronger with increasing task load for individuals with low compared to high NFC scores.
And regarding individual differences in ED we hypothesize that (3a) SVs predict individual NFC scores, and (3b) perceived task load does not predict individual NFC scores.

```{r preprocessing, echo=FALSE, message=FALSE, warning=FALSE}

  # create new data frames for the specification curve analysis
  # the data frame names are a combination of the letters from each of these categories, indicating how they will be preprocessed:
  #
  # across which dimensions the transformation and outlier exclusion will be done:
  #   (AA) across subjects, across n-back levels
  #   (AW) across subjects, within n-back levels
  #   (WW) within subjects, within n-back levels
  #   (WA) within subjects, across n-back levels
  # RT transformations:
  #   (R) raw/none
  #   (L) log
  #   (I) inverse
  #   (S) square-root
  # RT outlier exclusion:
  #   (N) none
  #   (2) 2 MADs from the median
  #   (5) 2.5 MADs from the median
  #   (3) 3 MADs from the median
  #   (O) 0-100 ms after stimulus onset
  #   (T) 0-200 ms after stimulus onset
  #
  # Example: the data frame "AWL3" has log-transformed RT data with no data points beyond 3 MADs
  # from the median
  #
  # Some combinations are nonsensical, so we will not include them: Raw data sets (__R__) with either no outlier
  # exclusion (___N_) or time-based outlier exclusion (___T_) do not need the different dimensions (A/W), and
  # time-based exclusion is nonsensical for transformed data sets.

  
  # create a list that contains the basic data frame of the n-back data for each of the pipelines

  pipelines_data <- replicate(63, data_nback, simplify = FALSE)
  pipelines_data <- setNames(pipelines_data, c("AARN","AAR2","AAR5","AAR3","AARO","AART",
                                               "AALN","AAL2","AAL5","AAL3",
                                               "AAIN","AAI2","AAI5","AAI3",
                                               "AASN","AAS2","AAS5","AAS3",
                                               "AWR2","AWR5","AWR3",
                                               "AWLN","AWL2","AWL5","AWL3",
                                               "AWIN","AWI2","AWI5","AWI3",
                                               "AWSN","AWS2","AWS5","AWS3",
                                               "WWR2","WWR5","WWR3",
                                               "WWLN","WWL2","WWL5","WWL3",
                                               "WWIN","WWI2","WWI5","WWI3",
                                               "WWSN","WWS2","WWS5","WWS3",
                                               "WAR2","WAR5","WAR3",
                                               "WALN","WAL2","WAL5","WAL3",
                                               "WAIN","WAI2","WAI5","WAI3",
                                               "WASN","WAS2","WAS5","WAS3"))

  for (i in 1:length(pipelines_data)) {
    
    # extract the name of the current data frame
    
    pipeline_name <- strsplit(names(pipelines_data)[i], "")
    
    # the first decision is whether transformations and exclusions will be applied across/within subjects/levels
    
    if (pipeline_name[[1]][1] == "A" & pipeline_name[[1]][2] == "A") {
      
          # the second decision is the type of transformation, depending on the third letter in the data frame name
          
          if (pipeline_name[[1]][3] == "L") {
            
            pipelines_data[[i]]$rt[pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1] <-
              log10(pipelines_data[[i]]$rt[pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1])
            pipelines_data[[i]]$rt[pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 0] <-
              log10(pipelines_data[[i]]$rt[pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 0])
            
          } else if (pipeline_name[[1]][3] == "I") {
            
            pipelines_data[[i]]$rt[pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1] <-
              1/(pipelines_data[[i]]$rt[pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1])
            pipelines_data[[i]]$rt[pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 0] <-
              1/(pipelines_data[[i]]$rt[pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 0])
            
          } else if (pipeline_name[[1]][3] == "S") {
            
            pipelines_data[[i]]$rt[pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1] <-
              sqrt(pipelines_data[[i]]$rt[pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1])
            pipelines_data[[i]]$rt[pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 0] <-
              sqrt(pipelines_data[[i]]$rt[pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 0])
          }
      
          # compute median and median absolute deviation
      
          pipemedian <- median(pipelines_data[[i]]$rt[pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1], na.rm = TRUE)
          pipemad <- mad(pipelines_data[[i]]$rt[pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1], na.rm = TRUE)
          
          # the third decision is the outlier exclusion
      
          if (pipeline_name[[1]][4] == "2") {
            
            pipelines_data[[i]] <- pipelines_data[[i]][c(which(pipelines_data[[i]]$rt[pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1] < (pipemedian + 2 * pipemad)
                                                               & pipelines_data[[i]]$rt[pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1] > (pipemedian - 2 * pipemad))), ]
                
          } else if (pipeline_name[[1]][4] == "5") {
            
            pipelines_data[[i]] <- pipelines_data[[i]][c(which(pipelines_data[[i]]$rt[pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1] < (pipemedian + 2.5 * pipemad)
                                                               & pipelines_data[[i]]$rt[pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1] > (pipemedian - 2.5 * pipemad))), ]
          } else if (pipeline_name[[1]][4] == "3") {
            
            pipelines_data[[i]] <- pipelines_data[[i]][c(which(pipelines_data[[i]]$rt[pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1] < (pipemedian + 3 * pipemad)
                                                               & pipelines_data[[i]]$rt[pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1] > (pipemedian - 3 * pipemad))), ]
          }
      
    } else if (pipeline_name[[1]][1] == "A" & pipeline_name[[1]][2] == "W") {
      
        # apply the transformations and exclusions across subjects but within levels
      
        for (x in 1:4) {
            
            # the second decision is the type of transformation, depending on the third letter in the data frame name
            
            if (pipeline_name[[1]][3] == "L") {
            
              pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1] <-
                log10(pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1])
              pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 0] <-
                log10(pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 0])
            
            } else if (pipeline_name[[1]][3] == "I") {
            
              pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1] <-
                1/(pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1])
              pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 0] <-
                1/(pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 0])
            
            } else if (pipeline_name[[1]][3] == "S") {
            
              pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1] <-
                sqrt(pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1])
              pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 0] <-
                sqrt(pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 0])

            }
            
            # compute median and median absolute deviation
          
            pipemedian <- median(pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1], na.rm = TRUE)
            pipemad <- mad(pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1], na.rm = TRUE)
            
            # the third decision is the outlier exclusion
          
            if (pipeline_name[[1]][4] == "2") {
              
              ifelse(length(which(pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 &
                                    (pipelines_data[[i]]$rt > (pipemedian + 2 * pipemad) | pipelines_data[[i]]$rt < (pipemedian - 2 * pipemad)))) > 0,
                     pipelines_data[[i]] <-
                       pipelines_data[[i]][-c(which(pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 &
                                                      (pipelines_data[[i]]$rt > (pipemedian + 2 * pipemad) | pipelines_data[[i]]$rt < (pipemedian - 2 * pipemad)))), ],
                     pipelines_data[[i]] <- pipelines_data[[i]])
                  
            } else if (pipeline_name[[1]][4] == "5") {
              
              ifelse(length(which(pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 &
                                    (pipelines_data[[i]]$rt > (pipemedian + 2.5 * pipemad) | pipelines_data[[i]]$rt < (pipemedian - 2.5 * pipemad)))) > 0,
                     pipelines_data[[i]] <-
                       pipelines_data[[i]][-c(which(pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 &
                                                    (pipelines_data[[i]]$rt > (pipemedian + 2.5 * pipemad) | pipelines_data[[i]]$rt < (pipemedian - 2.5 * pipemad)))), ],
                     pipelines_data[[i]] <- pipelines_data[[i]])
              
            } else if (pipeline_name[[1]][4] == "3") {
              
              ifelse(length(which(pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 &
                                    (pipelines_data[[i]]$rt > (pipemedian + 3 * pipemad) | pipelines_data[[i]]$rt < (pipemedian - 3 * pipemad)))) > 0,
                     pipelines_data[[i]] <-
                       pipelines_data[[i]][-c(which(pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 &
                                                    (pipelines_data[[i]]$rt > (pipemedian + 3 * pipemad) | pipelines_data[[i]]$rt < (pipemedian - 3 * pipemad)))), ],
                     pipelines_data[[i]] <- pipelines_data[[i]])
            }
        }
      
      
    } else if (pipeline_name[[1]][1] == "W" & pipeline_name[[1]][2] == "W") {
      
        # apply the transformations and exclusions within subjects and within levels
      
        for (x in 1:4) {
            
          for (y in 1:length(table(pipelines_data[[i]]$subject))) {
            
            # save the name of the subject as a temporary variable
            
            pipesubject <- names(table(pipelines_data[[i]]$subject))[y]
          
            # the second decision is the type of transformation, depending on the third letter in the data frame name
            
            if (pipeline_name[[1]][3] == "L") {
            
              pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 &
                                       pipelines_data[[i]]$subject == pipesubject] <-
                log10(pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 & pipelines_data[[i]]$subject == pipesubject])
              pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 0 &
                                       pipelines_data[[i]]$subject == pipesubject] <-
                log10(pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 0 & pipelines_data[[i]]$subject == pipesubject])
            
            } else if (pipeline_name[[1]][3] == "I") {
            
              pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 &
                                       pipelines_data[[i]]$subject == pipesubject] <-
                1/(pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 & pipelines_data[[i]]$subject == pipesubject])
              pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 0 &
                                       pipelines_data[[i]]$subject == pipesubject] <-
                1/(pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 0 & pipelines_data[[i]]$subject == pipesubject])
            
            } else if (pipeline_name[[1]][3] == "S") {
            
              pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 &
                                       pipelines_data[[i]]$subject == pipesubject] <-
                sqrt(pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 & pipelines_data[[i]]$subject == pipesubject])
              pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 0 &
                                       pipelines_data[[i]]$subject == pipesubject] <-
                sqrt(pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 0 & pipelines_data[[i]]$subject == pipesubject])
            }
            
            # compute median and median absolute deviation
          
            pipemedian <- median(pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 & pipelines_data[[i]]$subject == pipesubject], na.rm = TRUE)
            pipemad <- mad(pipelines_data[[i]]$rt[pipelines_data[[i]]$level == x & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 & pipelines_data[[i]]$subject == pipesubject], na.rm = TRUE)
            
            # the third decision is the outlier exclusion
          
            if (pipeline_name[[1]][4] == "2") {
              
              ifelse(length(which(pipelines_data[[i]]$level == x & pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 &
                                    (pipelines_data[[i]]$rt > (pipemedian + 2 * pipemad) | pipelines_data[[i]]$rt < (pipemedian - 2 * pipemad)))) > 0,
                     pipelines_data[[i]] <-
                       pipelines_data[[i]][-c(which(pipelines_data[[i]]$level == x & pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 &
                                                      (pipelines_data[[i]]$rt > (pipemedian + 2 * pipemad) | pipelines_data[[i]]$rt < (pipemedian - 2 * pipemad)))), ],
                     pipelines_data[[i]] <- pipelines_data[[i]])
              
            } else if (pipeline_name[[1]][4] == "5") {
              
              ifelse(length(which(pipelines_data[[i]]$level == x & pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 &
                                    (pipelines_data[[i]]$rt > (pipemedian + 2.5 * pipemad) | pipelines_data[[i]]$rt < (pipemedian - 2.5 * pipemad)))) > 0,
                     pipelines_data[[i]] <-
                       pipelines_data[[i]][-c(which(pipelines_data[[i]]$level == x & pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 &
                                                      (pipelines_data[[i]]$rt > (pipemedian + 2.5 * pipemad) | pipelines_data[[i]]$rt < (pipemedian - 2.5 * pipemad)))), ],
                     pipelines_data[[i]] <- pipelines_data[[i]])
              
            } else if (pipeline_name[[1]][4] == "3") {
              
              ifelse(length(which(pipelines_data[[i]]$level == x & pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 &
                                    (pipelines_data[[i]]$rt > (pipemedian + 3 * pipemad) | pipelines_data[[i]]$rt < (pipemedian - 3 * pipemad)))) > 0,
                     pipelines_data[[i]] <-
                       pipelines_data[[i]][-c(which(pipelines_data[[i]]$level == x & pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 &
                                                      (pipelines_data[[i]]$rt > (pipemedian + 3 * pipemad) | pipelines_data[[i]]$rt < (pipemedian - 3 * pipemad)))), ],
                     pipelines_data[[i]] <- pipelines_data[[i]])
            }
          }
        }
      
    } else if (pipeline_name[[1]][1] == "W" & pipeline_name[[1]][2] == "A") {
      
      # apply the transformations and exclusions within subjects but across levels
      
        for (y in 1:length(table(pipelines_data[[i]]$subject))) {
            
            # save the name of the subject as a temporary variable
            
            pipesubject <- names(table(pipelines_data[[i]]$subject))[y]
            
            # the second decision is the type of transformation, depending on the third letter in the data frame name
            
            if (pipeline_name[[1]][3] == "L") {
            
              pipelines_data[[i]]$rt[pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1] <-
                log10(pipelines_data[[i]]$rt[pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1])
              pipelines_data[[i]]$rt[pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 0] <-
                log10(pipelines_data[[i]]$rt[pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 0])
            
            } else if (pipeline_name[[1]][3] == "I") {
            
              pipelines_data[[i]]$rt[pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1] <-
                1/(pipelines_data[[i]]$rt[pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1])
              pipelines_data[[i]]$rt[pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 0] <-
                1/(pipelines_data[[i]]$rt[pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 0])
            
            } else if (pipeline_name[[1]][3] == "S") {
            
              pipelines_data[[i]]$rt[pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1] <-
                sqrt(pipelines_data[[i]]$rt[pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1])
              pipelines_data[[i]]$rt[pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 0] <-
                sqrt(pipelines_data[[i]]$rt[pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 0])

            }
            
            # compute median and median absolute deviation
          
            pipemedian <- median(pipelines_data[[i]]$rt[pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1], na.rm = TRUE)
            pipemad <- mad(pipelines_data[[i]]$rt[pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1], na.rm = TRUE)
            
            # the third decision is the outlier exclusion
          
            if (pipeline_name[[1]][4] == "2") {
              
              ifelse(length(which(pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 &
                                    (pipelines_data[[i]]$rt > (pipemedian + 2 * pipemad) | pipelines_data[[i]]$rt < (pipemedian - 2 * pipemad)))) > 0,
                     pipelines_data[[i]] <-
                       pipelines_data[[i]][-c(which(pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 &
                                                      (pipelines_data[[i]]$rt > (pipemedian + 2 * pipemad) | pipelines_data[[i]]$rt < (pipemedian - 2 * pipemad)))), ],
                     pipelines_data[[i]] <- pipelines_data[[i]])
              
            } else if (pipeline_name[[1]][4] == "5") {
              
              ifelse(length(which(pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 &
                                    (pipelines_data[[i]]$rt > (pipemedian + 2.5 * pipemad) | pipelines_data[[i]]$rt < (pipemedian - 2.5 * pipemad)))) > 0,
                     pipelines_data[[i]] <-
                       pipelines_data[[i]][-c(which(pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 &
                                                      (pipelines_data[[i]]$rt > (pipemedian + 2.5 * pipemad) | pipelines_data[[i]]$rt < (pipemedian - 2.5 * pipemad)))), ],
                     pipelines_data[[i]] <- pipelines_data[[i]])
              
            } else if (pipeline_name[[1]][4] == "3") {
              
              ifelse(length(which(pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 &
                                    (pipelines_data[[i]]$rt > (pipemedian + 3 * pipemad) | pipelines_data[[i]]$rt < (pipemedian - 3 * pipemad)))) > 0,
                     pipelines_data[[i]] <-
                       pipelines_data[[i]][-c(which(pipelines_data[[i]]$subject == pipesubject & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1 &
                                                      (pipelines_data[[i]]$rt > (pipemedian + 3 * pipemad) | pipelines_data[[i]]$rt < (pipemedian - 3 * pipemad)))), ],
                     pipelines_data[[i]] <- pipelines_data[[i]])
            }
        }
      
    }
    
    # the time-based exclusions are done outside of the A/A-A/W-W/W-W/A-conditions because they are independent of dimension:
    
    # exclude RTs faster than 100 or 200 ms after stimulus onset if the fourth letter in the data frame name is an "O" or a "T"
    # also making sure that there are even any trials below 100/200 ms, otherwise you get an error message
    
    if (pipeline_name[[1]][4] == "O") {
      
      ifelse(nrow(pipelines_data[[i]][-c(which(pipelines_data[[i]]$rt < 0.1 & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1)), ]) > 0,
             pipelines_data[[i]] <- pipelines_data[[i]][-c(which(pipelines_data[[i]]$rt < 0.1 & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1)), ],
             pipelines_data[[i]] <- pipelines_data[[i]])
    
    } else if (pipeline_name[[1]][4] == "T") {
      
      ifelse(nrow(pipelines_data[[i]][-c(which(pipelines_data[[i]]$rt < 0.2 & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1)), ]) > 0,
             pipelines_data[[i]] <- pipelines_data[[i]][-c(which(pipelines_data[[i]]$rt < 0.2 & pipelines_data[[i]]$response == 1 & pipelines_data[[i]]$correct == 1)), ],
             pipelines_data[[i]] <- pipelines_data[[i]])
      
    }
    
  }
  
  
```

```{r pipelines_dprime, echo=FALSE, message=FALSE, warning=FALSE}
  
  # calculate d' for every pipeline because it depends on the total number of target and non-target trials

  for (j in 1:length(pipelines_data)) {

    # compute index of rows in which the levels change
    
    levelindex <- c(1,which(pipelines_data[[j]]$level != dplyr::lag(pipelines_data[[j]]$level)),nrow(pipelines_data[[j]]))
    
    # set up empty data frame for the loop to feed into
    
    dprime <- data.frame(subject = character(), level = double(), hitrate = double(), falsealarmrate = double())
    
    # calculate hits and false alarms per participant
    
    for (i in 1:(length(levelindex)-1)) {
      
      # set the number of targets and non-targets
      num_targets <- length(which(pipelines_data[[j]]$target[c(levelindex[i]:(levelindex[i+1])-1)] == 1))
      num_nontargets <- length(which(pipelines_data[[j]]$target[c(levelindex[i]:(levelindex[i+1])-1)] == 0))
      
      hits <- length(which(pipelines_data[[j]]$target[c(levelindex[i]:(levelindex[i+1])-1)] == 1 &
                             pipelines_data[[j]]$correct[c(levelindex[i]:(levelindex[i+1])-1)] == 1) + (levelindex[i]-1))
      falsealarms <- length(which(pipelines_data[[j]]$response[c(levelindex[i]:(levelindex[i+1])-1)] == 1 &
                             pipelines_data[[j]]$correct[c(levelindex[i]:(levelindex[i+1])-1)] == 0) + (levelindex[i]-1))
      newdata <- data.frame(subject = pipelines_data[[j]]$subject[levelindex[i]],
                            level = pipelines_data[[j]]$level[levelindex[i]],
                            hitrate = hits/num_targets,
                            falsealarmrate = falsealarms/num_nontargets)
      dprime <- rbind(dprime, newdata)
      
    }
    
    # z-transform the hit rate and the false alarm rate
    
    dprime$hitrate.z = NA
    dprime$falsealarmrate.z = NA
    
    for (i in 1:4) {
      
      dprime$hitrate.z[which(dprime$level == i)]        <- scale(dprime$hitrate[which(dprime$level == i)])
      dprime$falsealarmrate.z[which(dprime$level == i)] <- scale(dprime$falsealarmrate[which(dprime$level == i)])
      
    }
    
    # calculate d'
    
    dprime$d <- dprime$hitrate.z - dprime$falsealarmrate.z
    
    # feed d# trialwise into the pipeline data frame
    
    for (i in 1:nrow(pipelines_data[[j]])) {
    
      pipelines_data[[j]]$dprime[i] <- dprime$d[dprime$subject == pipelines_data[[j]]$subject[i] & dprime$level == pipelines_data[[j]]$level[i]]
    
    }
  }
  
```


# Methods

The paradigm was written and presented using *Psychopy* [@Peirce2019]. We used *R Studio* [@RCT2020; @RStudioTeam2020] with the main packages *afex* [@Singmann2021] and *bayestestR* [@Makowski2019] for all our analyses.

## Ethics information

## Pilot data

The sample of the pilot study consisted of $N=$ `r length(setindex)` participants (`r round((table(data_quest$gender)[2]/length(setindex))*100, digits = 1)`% female, $M=$`r round(mean(data_quest$age, na.rm = TRUE), digits = 1)`($SD=$`r round(sd(data_quest$age, na.rm = TRUE), digits = 1)`) years old).
One participant's data was removed because they misunderstood the instruction.
Due to a technical error the subjective task load data of one participant was incomplete, so the hypotheses involving the NASA Task Load Index were analyzed with $n=$ `r length(setindex)-1` data sets.

## Design

Healthy participants aged 18 to 30 years will be recruited using the software *ORSEE* [@Greiner2015].
Participants will fill out the personality questionnaires online and then visit the lab for two sessions one week apart.
NFC will be assessed using the 16-item short form of the Need for Cognition Scale [@Bless1994; @Cacioppo1984].
Responses to each item (e.g., "Thinking is not my idea of fun", recoded) will be recorded on a 7-point Likert scale.
The NFC scale shows comparably high internal consistency [Cronbach's $\alpha$ \> .80; @Bless1994; @Fleischhauer2010].
Several other personality questionnaires will be used in this study but are the topic of the Registered Report for the second lab session.
A full list of measures can be found in our [Github repository](https://github.com/ChScheffel/CERED).
In the first session, participants provide informed consent and demographic data before completing the computer-based paradigm.
The paradigm starts with the n-back levels one to four, presented sequentially with two runs per level, consisting of 64 consonants (16 targets, 48 non-targets) per run.
The levels are referred to by color (1-back black, 2-back red, 3-back blue, 4-back green) to avoid anchor effects in the ED procedure.
To assess perceived task load, we will use the 6-item NASA Task Load Index (NASA-TLX) [@Hart1988], where participants evaluate their subjective perception of mental load, physical load, effort, frustration, performance, and time pressure during the task on a 20-point scale.
After each level, participants fill out the NASA-TLX on a tablet.
Then, they complete the ED procedure on screen, where each possible pairing of the four n-back levels is presented in a randomized order.
Participants are instructed to decide as realistically as possible, because one of their choices from the last iteration steps will be randomly chosen for one final run of n-back.
This is only done to incentivise truthful behavior in the ED procedure, so the n-back data of this part will not be analyzed.
The second session consists of an emotion regulation task with negative pictures and the instruction to suppress facial reactions, detach cognitively from the picture content, and distract oneself, respectively.
The paradigm follows the same structure of task and ED procedure, but participants can decide which strategy they want to reapply in the last block.
Participants will receive 30€ in total or course credit for participation.
Study data will be collected and managed using REDCap electronic data capture tools hosted at Technische Universität Dresden [@Harris2009; @Harris2019].

## Sampling plan

A sample size analysis with G*Power [@Faul2007; @Faul2009], based on the results of the ANOVA of Westbrook et al. [-@Westbrook2013] which showed an increase in reaction time with higher n-back levels, indicated that we should collect data from at least 53 participants, assuming $\eta2=0.04$, $\alpha=.05$, and $\beta=.95$.
The power analyses of all other hypotheses yielded smaller necessary sample sizes.
To account for technical errors and exclusions of physiological data of the second lab session due to excessive noise, we aim to collect data of 60 to 70 participants.

## Analysis plan

Data collection and analysis will not be performed blind to the conditions of the experiments.
We aim to conduct all analysis as described in Westbrook et al. [-@Westbrook2013], but the level of detail was not always sufficient, so there might be deviations regarding data cleaning and degrees of freedom.
The performance measure *d'* will be computed as the difference of the *z*-transformed hit rate and the *z*-transformed false alarm rate [@Macmillan1990].
Reaction time (RT) data will be trimmed by excluding all trials with responses faster than 100 ms, as the relevant cognitive processes cannot have been completed before [@Whelan2008; @Berger2021].
Aggregated RT values will be described using the median and the median of absolute deviation (MAD) as robust estimates of center and variability, respectively [@Lachaud2011].
Error- and post-error trials will be excluded in repeated measures analyses of variance (rmANOVA) and controlled for in multi-level-model (MLM), because RT on the latter is longer due to more cautious behavior [@Dutilh2012; @Houtman2012].
To test our hypotheses, we will perform a series of rmANOVAs and an MLM with orthogonal sum-to-zero contrasts in order to meaningfully interpret results [@Singmann2019]. 
Declining performance will be investigated by calculating an rmANOVA with three paired contrasts comparing *d'* between two levels of 2-, 3-, and 4-back at a time.
Another rmANOVA with three paired contrasts will be computed to compare the mean RT between two levels of 2-, 3-, and 4-back at a time.
To investigate changes in NASA-TLX ratings, six rmANOVAs will be computed, one for each NASA-TLX subscale, and each with six paired contrasts comparing the ratings between two levels of 1-, 2-, 3-, and 4-back at a time.
For each ED round, SVs will be calculated by adding or subtracting 0.015625 from the last monetary value of the flexible level, depending on the participant's last choice.
Then, these final monetary values will be divided by 2€, and the SV of each level per participant will be computed by averaging all final values of each level, regardless of whether it was fixed or flexible.
An rmANOVA with six paired contrasts will be computed, comparing the SVs between two levels of 1-, 2-, 3-, and 4-back at a time.
Tukey method will be used for the paired contrasts of each rmANOVA, including *p*-value adjustment.

To determine the influence of task performance in the association of SVs and n-back level, we will set up a MLM using the $lmerTest$ package. 
We will apply restricted maximum likelihood (REML) to fit the model.
First, we will calculate the intraclass correlation (ICC) on the basis of the null model.
Second, we will estimate a random slopes model of SVs including n-back load level as level-1-predictor and, additionally, NFC as level-2-predictor. 
Within the model, we will control for *d'*, RT, correct, and post-correct trials.
$$
SV \sim level\ * NFC + d' + RT + correct + postcorrect + (level|subject)
$$
Level-1-predictors will be centered within cluster, whereas the level-2-predictor will be centered at the grand mean as recommended by Enders & Tofighi [-@Enders2007]. 
We will visually inspect the residuals of the final model.
The approximately normal distribution indicates no evidence to perform model criticism.  
Third, we will perform a simple slopes analysis with n-back level as predictor and NFC as moderator. 
To evaluate the moderating effect, we will calculate the Johnson-Neyman interval.

To ensure the validity of the MLM, we will conduct a specification curve analysis [@Simonsohn2020], which will include 63 possible preprocessing pipelines of the RT data.
These pipelines specify which transformation was applied (none, log, inverse, or square-root), which outliers were excluded (none, 2, 2.5, or 3 $MAD$ from the median, RTs below 100 or 200 ms), and across which dimensions the transformations and exclusions were applied (across/within subjects and across/within n-back levels).
The MLM will be run with each of the 63 pipelines, which will also include our main pipeline (untransformed data, exclusion of RTs below 100 ms).
The ratio of pipelines that lead to significant versus non-significant effects will provide an indication of how robust the effect actually is.

The association of ED and NFC will be examined with a regression using the AUC of each participant's SVs to predict their NFC score.
A second regression will additionally include the mean of the NASA-TLX subscales' AUCs of each participant as a predictor.
Since we do not have a fixed SV of 1 for 1-back, we cannot apply the "AUC" computation of Westbrook et al. [-@Westbrook2013], which was the mean of the AUCs of the SVs of each higher n-back level and 1-back, yielding values between 0 and 1.
Consequently, we will choose a different way of quantifying the individual degree of ED.
A classic AUC cannot differentiate between a subject who prefers 1-back and a subject who prefers 4-back if the magnitude of the ascent is the same, but it can reflect the overall willingness to exert effort.
This is the opposite for the sum of the ascent between SVs.
Therefore, we multiply both indicators, arriving at a value reflecting both degree and direction of preference, called $AxAUC$.

The results of each analysis will be assessed on the basis of both *p*-value and the Bayes factor $BF10$, calculated using the *BayesFactor* package [@Morey2021].

## Data availability

The data of this study can be downloaded from osf.io/vnj8x/.

## Code availability

The paradigm code, as well as the R Markdown file used to analyze the data and write this document is available at our [Github repository](https://github.com/ChScheffel/CERED).


```{r Hypothesis_1a, echo=FALSE, message=FALSE, warning=FALSE}

  # H1a: The signal detection measure d’ declines with increasing n-back level.
  
  # repeated measures ANOVA with three linear contrasts, contrasting the d’ of two n-back levels (2,3,4) at a time
  
      # make a temporary copy of the data frame without 1-back
      
      h1a_data <- pipelines_data[["AARN"]][pipelines_data[["AARN"]]$level != 1, ]
      h1a_data <- unique(h1a_data[ ,c("subject","level","dprime")])
      h1a_data$level <- as.factor(h1a_data$level)
      
      # calculate ANOVA
      
      hypothesis1a_rmanova <- afex::aov_ez(data = h1a_data,
                                           dv = "dprime",
                                           id = "subject",
                                           within = "level",
                                           type = 3,
                                           include_aov = TRUE)
      
      # obtain estimated marginal means for ANOVA model
      
      hypothesis1a_emm <- emmeans(object = hypothesis1a_rmanova$aov,
                                  specs = "level")
      
      # calculate pairwise comparisons on estimated marginal means
      
      hypothesis1a_contrasts <- as.data.frame(pairs(hypothesis1a_emm))
    
  # get Bayes factors
      
  hypothesis1a_BF <- anovaBF(formula = dprime ~ level, data = h1a_data, progress = FALSE)
  hypothesis1a_contrasts$BF10 <- c(extractBF(ttestBF(x = h1a_data$dprime[h1a_data$level == 2], y = h1a_data$dprime[h1a_data$level == 3],
                                                     progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1a_data$dprime[h1a_data$level == 2], y = h1a_data$dprime[h1a_data$level == 4],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1a_data$dprime[h1a_data$level == 3], y = h1a_data$dprime[h1a_data$level == 4],
                                                   progress = FALSE, paired = TRUE))$bf)
      
  # remove the temporary variable
  
  remove(h1a_data)

```

## Results of the pilot study

We collected data from $N = 16$ participants,
One participant's NASA-TLX data is incomplete due to a technical error, so hypotheses 1c and 3b are analyzed using the 15 complete data sets.
Contrary to our expectations, the rmANOVA revealed no decrease in performance *d'* with increasing n-back level (`r apa_print(hypothesis1a_rmanova)$full_result`).

```{r Hypothesis_1b, echo=FALSE, message=FALSE, warning=FALSE}

  # H1b: Reaction time increases with increasing n-back level.
  
  # set up empty data frame for the loop to feed into
  
  rt <- data.frame(subject = character(), level = double(), medianrt = double())

  # compute index of rows in which the levels change
    
  levelindex <- c(1,which(pipelines_data[["AARO"]]$level != dplyr::lag(pipelines_data[["AARO"]]$level)),nrow(pipelines_data[["AARO"]]))
  
  # calculate median reaction time per participant per level
  
  for (i in 1:(length(levelindex)-1)) {
    
    medianrt <- median(pipelines_data[["AARO"]]$rt[which(pipelines_data[["AARO"]]$correct[c(levelindex[i]:(levelindex[i+1])-1)] == 1)
                                 +(levelindex[i]-1)], na.rm = TRUE)
    
    newdata <- data.frame(subject = pipelines_data[["AARO"]]$subject[levelindex[i]],
                          level = pipelines_data[["AARO"]]$level[levelindex[i]],
                          medianrt = medianrt)
    rt <- rbind(rt, newdata)
    
  }

  # ANOVA with three linear contrasts, contrasting the median rt of two n-back levels (2,3,4) at a time
  
      # make a temporary copy of the data frame without 1-back
      
      h1b_data <- rt[rt$level != 1,]
      h1b_data$level <- as.factor(h1b_data$level)
      
      # calculate ANOVA
      
      hypothesis1b_rmanova <- afex::aov_ez(data = h1b_data,
                                           dv = "medianrt",
                                           id = "subject",
                                           within = "level",
                                           type = 3,
                                           include_aov = TRUE)
      
      # obtain estimated marginal means for ANOVA model
      
      hypothesis1b_emm <- emmeans(object = hypothesis1b_rmanova$aov,
                                  specs = "level")
      # calculate pairwise comparisons on estimated marginal means
      
      hypothesis1b_contrasts <- as.data.frame(pairs(hypothesis1b_emm))
    
  # get Bayes factors
  
  hypothesis1b_BF <- anovaBF(formula = medianrt ~ level, data = h1b_data, progress = FALSE)
  hypothesis1b_contrasts$BF10 <- c(extractBF(ttestBF(x = h1b_data$medianrt[h1b_data$level == 2], y = h1b_data$medianrt[h1b_data$level == 3],
                                                     progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1b_data$medianrt[h1b_data$level == 2], y = h1b_data$medianrt[h1b_data$level == 4],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1b_data$medianrt[h1b_data$level == 3], y = h1b_data$medianrt[h1b_data$level == 4],
                                                   progress = FALSE, paired = TRUE))$bf)
  
  # remove the temporary variable
  
  remove(h1b_data, rt)

```

However, RTs increased with increasing n-back level (`r apa_print(hypothesis1b_rmanova)$full_result`).
RTs were longer for 3- than 2-back (`r apa_print(pairs(emmeans(object = hypothesis1b_rmanova$aov,specs = "level")))[1]`), but not different between 2- and 4-back or 3- and 4-back.
Even though *d'* did not decrease, the increases in RT indicate an increase in objective task load.

```{r Hypothesis_1c, echo=FALSE, message=FALSE, warning=FALSE}

  # H1c: Ratings on all NASA-TLX dimensions increase with increasing n-back level.

  # set up empty data frame for the loop to feed into

  data_ntlx <- data.frame(subject = character(), level = double(),
                          mental = double(), physical = double(), time = double(),
                          performance = double(), effort = double(), frustration = double())
  
  # feed NASA-TLX data per participant per level into data frame
  
  for (i in c(1:5,7:(length(setindex)-1))) { # we exclude the sixth subject (ID F30T02) here, because their NTLX data for n = 1 is missing
    
    for (j in 1:4) {
      
      newdata <- data.frame(subject = data_quest$subject[setindex[i]], level = j,
                            mental = data_quest$nasa_tlx_01[setindex[i]+j+2],
                            physical = data_quest$nasa_tlx_02[setindex[i]+j+2],
                            time = data_quest$nasa_tlx_03[setindex[i]+j+2],
                            performance = data_quest$nasa_tlx_04[setindex[i]+j+2],
                            effort = data_quest$nasa_tlx_05[setindex[i]+j+2],
                            frustration = data_quest$nasa_tlx_06[setindex[i]+j+2])
      data_ntlx <- rbind(data_ntlx, newdata)
    }
  }

  # six ANOVAs with six linear contrasts, contrasting the subscale scores of two n-back levels (1,2,3,4) at a time
  
      # make a temporary copy of the NASA-TLX data frame
      
      h1c_data <- data_ntlx
      h1c_data$level <- as.factor(h1c_data$level)
      
      # calculate ANOVAs
      
      hypothesis1c_mental_rmanova <- afex::aov_ez(data = h1c_data,
                                                  dv = "mental", id = "subject", within = "level",
                                                  type = 3, include_aov = TRUE)
      hypothesis1c_physical_rmanova <- afex::aov_ez(data = h1c_data,
                                                  dv = "physical", id = "subject", within = "level",
                                                  type = 3, include_aov = TRUE)
      hypothesis1c_time_rmanova <- afex::aov_ez(data = h1c_data,
                                                  dv = "time", id = "subject", within = "level",
                                                  type = 3, include_aov = TRUE)
      hypothesis1c_performance_rmanova <- afex::aov_ez(data = h1c_data,
                                                  dv = "performance", id = "subject", within = "level",
                                                  type = 3, include_aov = TRUE)
      hypothesis1c_effort_rmanova <- afex::aov_ez(data = h1c_data,
                                                  dv = "effort", id = "subject", within = "level",
                                                  type = 3, include_aov = TRUE)
      hypothesis1c_frustration_rmanova <- afex::aov_ez(data = h1c_data,
                                                  dv = "frustration", id = "subject", within = "level",
                                                  type = 3, include_aov = TRUE)
      
      # obtain estimated marginal means for ANOVA model and
      # calculate pairwise comparisons on estimated marginal means
      
      hypothesis1c_emm <- emmeans(object = hypothesis1c_mental_rmanova$aov, specs = "level")
      hypothesis1c_mental_contrasts <- as.data.frame(pairs(hypothesis1c_emm))
      
      hypothesis1c_emm <- emmeans(object = hypothesis1c_physical_rmanova$aov, specs = "level")
      hypothesis1c_physical_contrasts <- as.data.frame(pairs(hypothesis1c_emm))
      
      hypothesis1c_emm <- emmeans(object = hypothesis1c_time_rmanova$aov, specs = "level")
      hypothesis1c_time_contrasts <- as.data.frame(pairs(hypothesis1c_emm))
      
      hypothesis1c_emm <- emmeans(object = hypothesis1c_performance_rmanova$aov, specs = "level")
      hypothesis1c_performance_contrasts <- as.data.frame(pairs(hypothesis1c_emm))
      
      hypothesis1c_emm <- emmeans(object = hypothesis1c_effort_rmanova$aov, specs = "level")
      hypothesis1c_effort_contrasts <- as.data.frame(pairs(hypothesis1c_emm))
      
      hypothesis1c_emm <- emmeans(object = hypothesis1c_frustration_rmanova$aov, specs = "level")
      hypothesis1c_frustration_contrasts <- as.data.frame(pairs(hypothesis1c_emm))
    
  # get Bayes factors

  hypothesis1c_mental_BF <- anovaBF(formula = mental ~ level, data = h1c_data, progress = FALSE)
  hypothesis1c_mental_contrasts$BF10 <- c(extractBF(ttestBF(x = h1c_data$mental[h1c_data$level == 1], y = h1c_data$mental[h1c_data$level == 2],
                                                            progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$mental[h1c_data$level == 1], y = h1c_data$mental[h1c_data$level == 3],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$mental[h1c_data$level == 1], y = h1c_data$mental[h1c_data$level == 4],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$mental[h1c_data$level == 2], y = h1c_data$mental[h1c_data$level == 3],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$mental[h1c_data$level == 2], y = h1c_data$mental[h1c_data$level == 4],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$mental[h1c_data$level == 3], y = h1c_data$mental[h1c_data$level == 4],
                                                   progress = FALSE, paired = TRUE))$bf)
  hypothesis1c_physical_BF <- anovaBF(formula = physical ~ level, data = h1c_data, progress = FALSE)
  hypothesis1c_physical_contrasts$BF10 <- c(extractBF(ttestBF(x = h1c_data$physical[h1c_data$level == 1], y = h1c_data$physical[h1c_data$level == 2],
                                                              progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$physical[h1c_data$level == 1], y = h1c_data$physical[h1c_data$level == 3],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$physical[h1c_data$level == 1], y = h1c_data$physical[h1c_data$level == 4],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$physical[h1c_data$level == 2], y = h1c_data$physical[h1c_data$level == 3],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$physical[h1c_data$level == 2], y = h1c_data$physical[h1c_data$level == 4],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$physical[h1c_data$level == 3], y = h1c_data$physical[h1c_data$level == 4],
                                                   progress = FALSE, paired = TRUE))$bf)
  hypothesis1c_time_BF <- anovaBF(formula = time ~ level, data = h1c_data, progress = FALSE)
  hypothesis1c_time_contrasts$BF10 <- c(extractBF(ttestBF(x = h1c_data$time[h1c_data$level == 1], y = h1c_data$time[h1c_data$level == 2],
                                                          progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$time[h1c_data$level == 1], y = h1c_data$time[h1c_data$level == 3],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$time[h1c_data$level == 1], y = h1c_data$time[h1c_data$level == 4],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$time[h1c_data$level == 2], y = h1c_data$time[h1c_data$level == 3],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$time[h1c_data$level == 2], y = h1c_data$time[h1c_data$level == 4],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$time[h1c_data$level == 3], y = h1c_data$time[h1c_data$level == 4],
                                                   progress = FALSE, paired = TRUE))$bf)
  hypothesis1c_performance_BF <- anovaBF(formula = performance ~ level, data = h1c_data, progress = FALSE)
  hypothesis1c_performance_contrasts$BF10 <- c(extractBF(ttestBF(x = h1c_data$performance[h1c_data$level == 1], y = h1c_data$performance[h1c_data$level == 2],
                                                                 progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$performance[h1c_data$level == 1], y = h1c_data$performance[h1c_data$level == 3],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$performance[h1c_data$level == 1], y = h1c_data$performance[h1c_data$level == 4],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$performance[h1c_data$level == 2], y = h1c_data$performance[h1c_data$level == 3],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$performance[h1c_data$level == 2], y = h1c_data$performance[h1c_data$level == 4],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$performance[h1c_data$level == 3], y = h1c_data$performance[h1c_data$level == 4],
                                                   progress = FALSE, paired = TRUE))$bf)
  hypothesis1c_effort_BF <- anovaBF(formula = effort ~ level, data = h1c_data, progress = FALSE)
  hypothesis1c_effort_contrasts$BF10 <- c(extractBF(ttestBF(x = h1c_data$effort[h1c_data$level == 1], y = h1c_data$effort[h1c_data$level == 2],
                                                            progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$effort[h1c_data$level == 1], y = h1c_data$effort[h1c_data$level == 3],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$effort[h1c_data$level == 1], y = h1c_data$effort[h1c_data$level == 4],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$effort[h1c_data$level == 2], y = h1c_data$effort[h1c_data$level == 3],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$effort[h1c_data$level == 2], y = h1c_data$effort[h1c_data$level == 4],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$effort[h1c_data$level == 3], y = h1c_data$effort[h1c_data$level == 4],
                                                   progress = FALSE, paired = TRUE))$bf)
  hypothesis1c_frustration_BF <- anovaBF(formula = frustration ~ level, data = h1c_data, progress = FALSE)
  hypothesis1c_frustration_contrasts$BF10 <- c(extractBF(ttestBF(x = h1c_data$frustration[h1c_data$level == 1], y = h1c_data$frustration[h1c_data$level == 2],
                                                                 progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$frustration[h1c_data$level == 1], y = h1c_data$frustration[h1c_data$level == 3],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$frustration[h1c_data$level == 1], y = h1c_data$frustration[h1c_data$level == 4],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$frustration[h1c_data$level == 2], y = h1c_data$frustration[h1c_data$level == 3],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$frustration[h1c_data$level == 2], y = h1c_data$frustration[h1c_data$level == 4],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h1c_data$frustration[h1c_data$level == 3], y = h1c_data$frustration[h1c_data$level == 4],
                                                   progress = FALSE, paired = TRUE))$bf)
  
  # remove the temporary variable
  
  remove(h1c_data, hypothesis1c_emm)
      
```

Increases in subjective task load were investigated for each NASA-TLX subscale, now including 1-back.
Ratings on the mental load and effort subscales increased between all n-back levels ($p<.001$) except between 3- and 4-back.
Ratings on the physical load and the performance subscales only differed between 1- and 3-back (`r apa_print(pairs(emmeans(object = hypothesis1c_physical_rmanova$aov,specs = "level")))$statistic$X1_X3`, and `r apa_print(pairs(emmeans(object = hypothesis1c_performance_rmanova$aov,specs = "level")))$statistic$X1_X3`, respectively) and 1- and 4-back (`r apa_print(pairs(emmeans(object = hypothesis1c_physical_rmanova$aov,specs = "level")))$statistic$X1_X4`, and `r `apa_print(pairs(emmeans(object = hypothesis1c_performance_rmanova$aov,specs = "level")))$statistic$X1_X4`, respectively).
Ratings on the frustration and time pressure subscales increased between all n-back levels ($p<.001$) except between 1- and 2-back and 3- and 4-back.
Overall, these ratings showed that the increase in task load was being perceived as such.

```{r Hypothesis_2a, echo=FALSE, message=FALSE, warning=FALSE}

  # H2a: Subjective values decline with increasing n-back level.

  # ANOVA with six linear contrasts, contrasting the SVs of two n-back levels (1,2,3,4) at a time
  
  # make a temporary copy of the data frame
  
  h2a_data <- unique(pipelines_data[["AARO"]][ ,c("subject","level","sv")])
  h2a_data$level <- as.factor(h2a_data$level)
  
  # calculate ANOVA
  
  hypothesis2a_rmanova <- afex::aov_ez(data = h2a_data,
                                       dv = "sv", id = "subject", within = "level",
                                       type = 3, include_aov = TRUE)
  
  # obtain estimated marginal means for ANOVA model
  
  hypothesis2a_emm <- emmeans(object = hypothesis2a_rmanova$aov,
                              specs = "level")
  
  # calculate pairwise comparisons on estimated marginal means
  
  hypothesis2a_contrasts <- as.data.frame(pairs(hypothesis2a_emm))

  # get Bayes factors
  
  hypothesis2a_BF <- anovaBF(formula = sv ~ level, data = h2a_data, progress = FALSE)
  hypothesis2a_contrasts$BF10 <- c(extractBF(ttestBF(x = h2a_data$sv[h2a_data$level == 1], y = h2a_data$sv[h2a_data$level == 2],
                                                     progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h2a_data$sv[h2a_data$level == 1], y = h2a_data$sv[h2a_data$level == 3],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h2a_data$sv[h2a_data$level == 1], y = h2a_data$sv[h2a_data$level == 4],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h2a_data$sv[h2a_data$level == 2], y = h2a_data$sv[h2a_data$level == 3],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h2a_data$sv[h2a_data$level == 2], y = h2a_data$sv[h2a_data$level == 4],
                                                   progress = FALSE, paired = TRUE))$bf,
                                 extractBF(ttestBF(x = h2a_data$sv[h2a_data$level == 3], y = h2a_data$sv[h2a_data$level == 4],
                                                   progress = FALSE, paired = TRUE))$bf)
  
  # remove the temporary variable
  
  remove(h2a_data)

```

The rmANOVA indicated significant differences between SVs depending on n-back level (`r apa_print(hypothesis2a_rmanova)$full_result`).
SVs were higher for 1- than 3-back (`r apa_print(pairs(emmeans(object = hypothesis2a_rmanova$aov,specs = "level")))$statistic$X1_X3`), for 1- than 4-back (`r apa_print(pairs(emmeans(object = hypothesis2a_rmanova$aov,specs = "level")))$statistic$X1_X4`), and for 2- than 4-back (`r apa_print(pairs(emmeans(object = hypothesis2a_rmanova$aov,specs = "level")))$statistic$X2_X4`).
Importantly, the lack of difference between the SVs of 1- and 2-back indicates that when given the choice, not all participants preferred the easiest level.
This can be considered preliminary proof-of-concept, as this behavioural pattern can only emerge in the CERED paradigm, but not in the original COG-ED paradigm.

```{r Hypothesis_2b_2c, echo=FALSE, message=FALSE, warning=FALSE, fig.show='hide'}

  # H2b: Subjective values decline with increasing n-back level, even after controlling for declining task
  # performance measured by signal detection d’ and reaction time.

  # H2c: SVs decline stronger with increasing task load for individuals with low compared to high NFC scores.

  # detach afex in order to use lmerTest
  detach("package:afex", unload = TRUE)
  
  # get all relevant variables -------------------------------------------------
    
  h2b_data <- pipelines_data[["AARO"]]
  
  # get subset for MLM without RT = NA
  
  h2b_data <- droplevels(subset(h2b_data[ ,c("subject", "level", "sv", "dprime", "correct", "postcorrect", "rt", "nfc")],
                               subset = !is.na(rt)
                               & level > 1)) #FIXME
  
  
  # center predictors ----------------------------------------------------------
  
  ## center level 1 predictors
  # two ways: centering at the grand mean (CGM) vs. centering within cluster (CWC) = group mean centering
  # level 1 predictor (SV) is of substantive interest
  # > CWC
  
  # dprime
  h2b_data$dprime.cwc <- h2b_data$dprime - (ave(h2b_data$dprime, h2b_data$subject, FUN = function(x) mean(x, na.rm = T)))
  
  # RT
  h2b_data$rt.cwc <- h2b_data$rt - (ave(h2b_data$rt, h2b_data$subject, FUN = function(x) mean(x, na.rm = T)))
  
  # level
  h2b_data$level.cwc <- h2b_data$level - (ave(h2b_data$level, h2b_data$subject, FUN = function(x) mean(x, na.rm = T)))
  
  # correct 
  h2b_data$correct.cwc <- h2b_data$correct - (ave(h2b_data$correct, h2b_data$subject, FUN = function(x) mean(x, na.rm = T)))

  # postcorrect
  h2b_data$postcorrect.cwc <- h2b_data$postcorrect - (ave(h2b_data$postcorrect, h2b_data$subject, FUN = function(x) mean(x, na.rm = T)))
  
  ## level 2 predictor
  # > CGM

  # NFC
  h2b_data$nfc.cgm <- scale(h2b_data$nfc, scale = F)
  
  
  # null model -----------------------------------------------------------------
  m0_h2b <- lmer(sv ~ 1 + (1|subject), 
                 data = h2b_data,
                 REML = T)
  
  # intraclass correlation (ICC)
  # % of variance can be explained by differences between persons
  var_m0_h2b <- as.data.frame(VarCorr(m0_h2b))
  icc_h2b <- var_m0_h2b$vcov[1] / (var_m0_h2b$vcov[1] + var_m0_h2b$vcov[2]) 
  
  
  # random slopes model --------------------------------------------------------
  
  ## maximal model ---- 
  m1_h2b <- lmer(sv ~ level.cwc * nfc.cgm + dprime.cwc + rt.cwc + correct.cwc + postcorrect.cwc + (level.cwc|subject), 
                 data = h2b_data,
                 REML = T) # parameters estimated by restricted log-likelihood maximization
  
  
  ## plot model fit of the final model ----
  m1_h2b_fit <- plot_model(m1_h2b, type = "diag")
  
  
  # get Bayes factors ----------------------------------------------------------
  
  # the random factor needs to be a factor
  h2b_data$subject <- factor(h2b_data$subject)
  
  # H2b
  h2b_full_BF <- lmBF(sv ~ level.cwc + nfc.cgm + dprime.cwc + rt.cwc + correct.cwc + postcorrect.cwc + subject,
                      data = h2b_data, whichRandom = 'subject', progress = FALSE)
  h2b_null_BF <- lmBF(sv ~ 1 + nfc.cgm + dprime.cwc + rt.cwc + correct.cwc + postcorrect.cwc + subject,
                      data = h2b_data, whichRandom = 'subject', progress = FALSE)
  h2b_BF <- h2b_full_BF / h2b_null_BF
  
  
  # H2c
  h2c_full_BF <- lmBF(sv ~ level.cwc * nfc.cgm + dprime.cwc + rt.cwc + correct.cwc + postcorrect.cwc + subject,
                      data = h2b_data, whichRandom = 'subject', progress = FALSE)
  h2c_null_BF <- lmBF(sv ~ level.cwc + nfc.cgm + dprime.cwc + rt.cwc + correct.cwc + postcorrect.cwc + subject,
                      data = h2b_data, whichRandom = 'subject', progress = FALSE)
  h2c_BF <- h2c_full_BF / h2c_null_BF
  
  
  # prepare MLM results for reporting ------------------------------------------
  
  # get random and fixed effects
  m1_h2b.ranef <- as.data.frame(summary(m1_h2b)$varcor)
  m1_h2b.fixef <- summary(m1_h2b)$coefficients
  
  # prepare table
  h2b_result.table <- as.data.frame(cbind(row.names(m1_h2b.fixef[-c(6,7),]), 
                                          m1_h2b.fixef[-c(6,7),c(1, 2, 5)]))
  h2b_result.table$ranef.sd <- NA
  h2b_result.table$ranef.sd[c(1,2)] <- m1_h2b.ranef$sdcor[c(1,2)]
 
  colnames(h2b_result.table)[1] <- "Parameter"
  colnames(h2b_result.table)[2] <- "Beta"
  colnames(h2b_result.table)[3] <- "$SE$"
  colnames(h2b_result.table)[4] <- "$p$-value"
  colnames(h2b_result.table)[5] <- "Random Effects (SD)"

  row.names(h2b_result.table) <- NULL
  h2b_result.table$Parameter[1:6] <- c("Intercept", "n-back level", "NFC", "d'", "RT", "level x NFC")

  h2b_result.table[2:5] <- lapply(h2b_result.table[2:5], as.numeric)
  h2b_result.table[c(2,3,5)] <- round(h2b_result.table[c(2,3,5)], digits = 2)
  h2b_result.table[4] <- round(h2b_result.table[4], digits = 3)
  
  h2b_result.table$`$p$-value`[which(h2b_result.table$`$p$-value`<.01)] <- 
    paste0(h2b_result.table$`$p$-value`[which(h2b_result.table$`$p$-value`<.01)],"*")
  h2b_result.table$`$p$-value`[which(h2b_result.table$`$p$-value`<.05)] <- 
    paste0(h2b_result.table$`$p$-value`[which(h2b_result.table$`$p$-value`<.05)],"*")
  h2b_result.table$`$p$-value`[which(h2b_result.table$`$p$-value`<.001)] <- 
    paste0("<.001***")
  
  h2b_result.table$`Random Effects (SD)`[3:6] <- paste0("")
   
  table_1 <-
    kbl(h2b_result.table,
    caption = "Effects of n-back load level on subjective value controlled 
    for task performance (d' and reaction time), correct and postcorrect trials.",
    booktabs = T,                          # no vertical lines
    escape = F,                            # correctly print special characters)
    align = c("l",rep("r",7))) %>%         # right aligns the text in every numerical column
    kable_styling(latex_options = c("striped")) %>%
    footnote(general = "NFC = Need for Cognition, SE = standard error. ***$p$ < .001, **$p$ < .01, *$p$ < 0.5.",
            escape = F,                    # correctly print special characters
            threeparttable = T)            # line breaks in the footnote
   
    
  # simple slopes analysis -----------------------------------------------------
  
  m1_h2c.ss <- sim_slopes(m1_h2b, pred = level.cwc, modx = nfc.cgm, centered = "none", 
                    cond.int = T,                       # print conditional intercepts
                    control.fdr = T,                    # adjust false discovery rate
                    confint = T)                        # add confidence intervals
  
  #create table
  h2c_ss.table <- data.frame("Value of NFC" = c("- 1 SD", "Mean", "+ 1 SD"),
                             round(m1_h2c.ss$slopes[c(2:3)], digits = 2),
                             c(paste0("[", round(m1_h2c.ss$slopes[1,4], digits = 2), ",", round(m1_h2c.ss$slopes[1,5], digits = 2), "]"),
                               paste0("[", round(m1_h2c.ss$slopes[2,4], digits = 2), ",", round(m1_h2c.ss$slopes[2,5], digits = 2), "]"),
                               paste0("[", round(m1_h2c.ss$slopes[3,4], digits = 2), ",", round(m1_h2c.ss$slopes[3,5], digits = 2), "]")),
                             round(m1_h2c.ss$slopes[7], digits = 3),
                             round(m1_h2c.ss$ints[c(2,3)], digits = 2))
  colnames(h2c_ss.table) <- c("Value of NFC", "Beta", "$SE$", "95% CI", "$p$-value", "Beta", "$SE$" )
  # columns 2:5 belong to "Slopes of NFC"
  # columns 6:7 belong to "Conditional Intercept"
  
  h2c_ss.table$`$p$-value`  [which(h2c_ss.table$`$p$-value`<.01)] <- 
    paste0(h2c_ss.table$`$p$-value`[which(h2c_ss.table$`$p$-value`<.01)],"*")
  h2c_ss.table$`$p$-value`[which(h2c_ss.table$`$p$-value`<.05)] <- 
    paste0(h2c_ss.table$`$p$-value`[which(h2c_ss.table$`$p$-value`<.05)],"*")
  h2c_ss.table$`$p$-value`[which(h2c_ss.table$`$p$-value`<.001)] <- 
    paste0("<.001***")
  
  # remove leading zeros in the p-value column
  
  h2c_ss.table$`$p$-value` <- str_replace(h2c_ss.table$`$p$-value`, "0.", ".")
  
  table_2 <-
    kbl(h2c_ss.table,
    caption = "Interaction between NFC and n-back load level.",
    # "Slopes of n-back level for different NFC values."
    booktabs = T,                          # no vertical lines
    escape = F,                            # correctly print special characters)
    align = c("l",rep("r",6))) %>%         # right aligns the text in every numerical column
    kable_styling(latex_options = c("striped")) %>%
    add_header_above(c(" " = 1, "Slopes of NFC" = 4, "Conditional Intercept" = 2)) %>%
    footnote(general = "NFC = Need for Cognition, SE = standard error. ***$p$ < .001, **$p$ < .01, *$p$ < 0.5.",
            escape = F,                    # correctly print special characters
            threeparttable = T)            # line breaks in the footnote
  
  
  # calculate Johnson-Neyman intervals
  h2c_jn <- johnson_neyman(model = m1_h2b, pred = level.cwc, modx = nfc.cgm, control.fdr = T)
  h2c_jn.int <- h2c_jn$bounds
  
  # save plot
  h2c_jn.plot <- h2c_jn$plot
  
  # create interaction plot
  h2c_ss.plot <- interact_plot(m1_h2b, pred = level.cwc, modx = nfc.cgm, centered = "none",
                               plot.points = T, point.shape = T,
                               x.label = "n-back level", y.label = "subjective value",
                               legend.main = "NFC", interval = T) + theme_apa() +
    scale_x_continuous(breaks = c(-1,0,1), labels = c("2","3","4"))
  
```

```{r SpecificationCurveAnalysis, echo=FALSE, message=FALSE, warning=FALSE, fig.show='hide'}

  # here we repeat the multi level model with all analysis pipelines

  # prepare empty data frame for the loop to feed into

  sca_results <- data.frame(pipeline = character(), beta = double(), pvalue = double(), predictor = character(), BF10 = double())

  # loop through the pipelines

  for (i in 1:length(pipelines_data)) {
    
    # make a temporary copy of the data frame
    
    sca_data <- pipelines_data[[i]]
    
    # get a subset without RT = NA
    
    sca_data <- droplevels(subset(sca_data[ ,c("subject", "level", "sv", "dprime", "correct", "postcorrect", "rt", "nfc")], subset = !is.na(rt)))
    
    # center the predictors
    
        # centering the level 1 predictors (d', RT, level, correct, postcorrect) within cluster
        
        sca_data$dprime.cwc       <- sca_data$dprime - (ave(sca_data$dprime, sca_data$subject, FUN = function(x) mean(x, na.rm = T)))
        sca_data$rt.cwc           <- sca_data$rt - (ave(sca_data$rt, sca_data$subject, FUN = function(x) mean(x, na.rm = T)))
        sca_data$level.cwc        <- sca_data$level - (ave(sca_data$level, sca_data$subject, FUN = function(x) mean(x, na.rm = T)))
        sca_data$correct.cwc      <- sca_data$correct - (ave(sca_data$correct, sca_data$subject, FUN = function(x) mean(x, na.rm = T)))
        sca_data$postcorrect.cwc  <- sca_data$postcorrect - (ave(sca_data$postcorrect, sca_data$subject, FUN = function(x) mean(x, na.rm = T)))
        
        # centering the level 2 predictor NFC at the grand mean

        sca_data$nfc.cgm <- scale(sca_data$nfc, scale = F)
        
    # define the null model
    
    m0_sca <- lmer(sv ~ 1 + (1|subject), data = sca_data, REML = T)
    
    # random slopes model
    
    m1_sca <- lmer(sv ~ level.cwc * nfc.cgm + dprime.cwc + rt.cwc + correct.cwc + postcorrect.cwc + (level.cwc|subject),
                   data = sca_data, REML = T)
    
    # convert random factor to type factor
    
    sca_data$subject <- factor(sca_data$subject)
  
    # compute Bayes factor
    
    sca_full_BF <- lmBF(sv ~ level.cwc + nfc.cgm + dprime.cwc + rt.cwc + correct.cwc + postcorrect.cwc + subject,
                        data = sca_data, whichRandom = 'subject', progress = FALSE)
    sca_null_BF <- lmBF(sv ~ 1 + nfc.cgm + dprime.cwc + rt.cwc + correct.cwc + postcorrect.cwc + subject,
                        data = sca_data, whichRandom = 'subject', progress = FALSE)
    sca_BF <- sca_full_BF / sca_null_BF
      
    # combine current results and the bigger data frame
    
    newdata <- data.frame(pipeline = c(names(pipelines_data[i]),names(pipelines_data[i])),
                          beta = c(summary(m1_sca)$coefficients[2,1],summary(m1_sca)$coefficients[3,1]),
                          pvalue = c(summary(m1_sca)$coefficients[2,5],summary(m1_sca)$coefficients[3,5]),
                          predictor = c("Level", "NFC"),
                          BF10 = c(extractBF(sca_BF)$bf, extractBF(sca_BF)$bf))
    sca_results <- rbind(sca_results, newdata)
  
  }

```

```{r SCA_plot, echo=FALSE, message=FALSE, warning=FALSE, fig.show='hide'}

  # add a row number and sort the data frame by the fixed effects estimate of the predictor 'level'

  sca_results <- cbind(sca_results, num = rep(c(1:(nrow(sca_results)/2)), each = 2))
  sca_results <- sca_results[order(sca_results$predictor, sca_results$beta, decreasing = TRUE), ]
  sca_results[sca_results$predictor == "NFC", ] <- sca_results[match(sca_results$num[sca_results$predictor == "Level"],
                                                                     sca_results$num[sca_results$predictor == "NFC"]),]
  
  # lock it in place by turning it into a factor
  
  sca_results$num <- factor(sca_results$num, levels = sca_results$num[sca_results$predictor == "NFC"])
  
  # add a column to plot only points that are significant
  
  sca_results$sign <- ifelse(sca_results$pvalue < .01, sca_results$beta, NA)
  
  # add columns to the data frame that describe the pipeline
  
  sca_results$Dim <- ifelse(substr(sca_results$pipeline,1,2) == "AA", 2,
                            ifelse(substr(sca_results$pipeline,1,2) == "AW", 3,
                                   ifelse(substr(sca_results$pipeline,1,2) == "WW", 4,
                                          ifelse(substr(sca_results$pipeline,1,2) == "WA", 5, NA))))
  sca_results$Trans <- ifelse(substr(sca_results$pipeline,3,3) == "R", 7,
                              ifelse(substr(sca_results$pipeline,3,3) == "L", 8,
                                     ifelse(substr(sca_results$pipeline,3,3) == "L", 8,
                                            ifelse(substr(sca_results$pipeline,3,3) == "I", 9,
                                                   ifelse(substr(sca_results$pipeline,3,3) == "S", 10, NA)))))
  sca_results$Excl <- ifelse(substr(sca_results$pipeline,4,4) == "N", 12,
                             ifelse(substr(sca_results$pipeline,4,4) == "2", 13,
                                    ifelse(substr(sca_results$pipeline,4,4) == "5", 14,
                                           ifelse(substr(sca_results$pipeline,4,4) == "3", 15,
                                                  ifelse(substr(sca_results$pipeline,4,4) == "O", 16, 
                                                         ifelse(substr(sca_results$pipeline,4,4) == "T", 17, NA))))))
  

  # create the upper panel first, which will show the estimates of 'level' and 'nfc'
  
  sca_upperplot <- ggplot(data = sca_results, aes(x = num, y = beta)) +
    geom_line(aes(group = predictor)) +
    geom_point(data = sca_results, aes(x = num, y = sign)) +
    geom_text(x = 3, y = -0.01, label = "NFC") +
    geom_text(x = 3, y = -0.12, label = "Level") +
    theme_classic() +
    labs(x = NULL, y = "Fixed effects estimate \u03b2") +
    scale_y_continuous(lim = c(NA,0.01)) +
    theme(axis.text.x = element_blank(),
          axis.line.y = element_line(size = 1, color = "black"), axis.title.y = element_text(margin = margin(r = 10)),
          legend.position = "none")

  # create the lower part of the plot that indicates the pipeline specifications
  
  sca_lowerplot <- ggplot(data = sca_results) +
    geom_hline(yintercept = c(1,6,11), color = "grey", size = 0.5) +
    geom_hline(yintercept = c(2:5,7:10,12:17), color = "grey", linetype = "dashed", size = 0.2) +
    geom_point(aes(x = num, y = Dim)) +
    geom_point(aes(x = num, y = Trans)) +
    geom_point(aes(x = num, y = Excl)) +
    theme_classic() +
    labs(x = "Analysis pipeline", y = NULL) +
    scale_y_reverse(breaks = c(1:17), lim = c(17,0.5), labels = c(expression(bold("Dimension")),
                                                                "Across S, across C", "Across S, within C",
                                                                "Within S, within C", "Within S, across C",
                                                                expression(bold("Transformation")),
                                                                "Raw/None", "Log", "Inverse", "Square-root",
                                                                expression(bold("Exclusion")),
                                                                "None", "2 MAD from median", " 2.5 MAD from median",
                                                                "3 MAD from median", "100ms after onset", "200ms after onset")) +
    theme(axis.text.x = element_blank(), axis.title.x = element_text(margin = margin(t = 10)),
          axis.line.y = element_line(size = 1, color = "black"),
          legend.position = "none")
  
  # put both plots into one
  
  sca_plot <- ggarrange(sca_upperplot, sca_lowerplot, nrow = 2, heights = c(1,2.5))

```

The MLM revealed that n-back level was a reliable predictor of SV (`r apa_print(m1_h2b)$full_result$level_cwc`), even after controlling for declining task performance (d’ and RT) as well as correct and post-correct answers. 
The results of the MLM are detailed in Table 1. 
`r table_1`
Differences between subjects could explain `r round((icc_h2b*100), digits = 0)` % of the total variance in SVs ($ICC =$ `r round(icc_h2b, digits = 2)`).
However, NFC had no statistically significant effect on SVs (`r apa_print(m1_h2b)$full_result$nfc_cgm`).
The simple slopes analysis revealed a significant difference in slope of n-back level for three different expressions of NFC (Table 2, Figure 2).
`r table_2`
`r h2c_ss.plot`
The Johnson-Neyman plot (Figure 2) visualizes the significance of the slope of n-back level at different values of NFC.
The Johnson-Neyman interval is [`r h2c_jn.int`].
Consequently, the slope of n-back level was not significant for individuals with very low NFC values.    
`r h2c_jn.plot`

## alternative: `r h2b_jn` 

```{r Hypothesis_3a, echo=FALSE, message=FALSE, warning=FALSE}

  # H3a: Subjective values positively predict individual NCS scores.

  # make a temporary copy of the data frame
  
  data_SV <- unique(pipelines_data[["AARO"]][ ,c("subject","level","sv")])

  # create an index for the rows in which the participant ID changes

  subjectindex <- c(1,which(data_SV$subject != dplyr::lag(data_SV$subject)),nrow(data_SV))

  # prepare empty data frame for the loop to feed into

  h3_data <- data.frame(subject = character(), axauc = double())

  # calculate AUC of SVs per subject
  
  for (i in 1:(length(subjectindex)-1)) {
    
    newdata <- data.frame(subject = data_SV$subject[subjectindex[i]],
                          axauc = auc(data_SV$level[subjectindex[i]:(subjectindex[i]+3)], data_SV$sv[subjectindex[i]:(subjectindex[i]+3)], method = "trapezoid") *
                            ((data_SV$sv[subjectindex[i]+3] - data_SV$sv[subjectindex[i]+2]) +
                               (data_SV$sv[subjectindex[i]+2] - data_SV$sv[subjectindex[i]+1]) +
                               (data_SV$sv[subjectindex[i]+1] - data_SV$sv[subjectindex[i]])))
    h3_data <- rbind(h3_data, newdata)
    
  }

  # add NFC values to data frame
  
  for (i in 1:(nrow(h3_data))) {
    
    h3_data$nfc[i] <- pipelines_data[["AARO"]]$nfc[pipelines_data[["AARO"]]$subject == h3_data$subject[i]]
    
  }
  
  # calculate linear model to estimate prediction of NFC by SVs
  
  hypothesis3a <- summary(lm(h3_data$nfc ~ h3_data$axauc))
  
  # get Bayes factor
  
  hypothesis3a_BF <- regressionBF(formula = nfc ~ axauc, data = h3_data, progress = FALSE)
  
  
```

The $AxAUC$ value did not predict any amount of variance in individual NFC scores (`r apa_print(hypothesis3a)$statistic$modelfit$r2`, `r apa_print(hypothesis3a)$estimate$modelfit$r2`).

```{r Hypothesis_3b, echo=FALSE, message=FALSE, warning=FALSE}

  # H3b: NASA-TLX scores negatively predict individual NCS scores.
  
  # create an index for the rows in which the participant ID changes

  subjectindex <- c(1,which(data_ntlx$subject != dplyr::lag(data_ntlx$subject)),nrow(data_ntlx))
  
  # prepare temporary data frame for loop to feed into
  
  ntlx <- data.frame(subject = character(), auc_mental = double(), auc_physical = double(), auc_time = double(),
                          auc_performance = double(), auc_effort = double(), auc_frustration = double())

  # calculate AUCs per NASA-TLX subscale per participant

  for (i in 1:(length(subjectindex)-1)) {
    
    newdata <- data.frame(subject = data_ntlx$subject[subjectindex[i]],
                          auc_mental = auc(data_ntlx$level[subjectindex[i]:(subjectindex[i+1]-1)],
                                           data_ntlx$mental[subjectindex[i]:(subjectindex[i+1]-1)], method = "trapezoid", sort = FALSE),
                          auc_physical = auc(data_ntlx$level[subjectindex[i]:(subjectindex[i+1]-1)],
                                           data_ntlx$physical[subjectindex[i]:(subjectindex[i+1]-1)], method = "trapezoid", sort = FALSE),
                          auc_time = auc(data_ntlx$level[subjectindex[i]:(subjectindex[i+1]-1)],
                                           data_ntlx$time[subjectindex[i]:(subjectindex[i+1]-1)], method = "trapezoid", sort = FALSE),
                          auc_performance = auc(data_ntlx$level[subjectindex[i]:(subjectindex[i+1]-1)],
                                           data_ntlx$performance[subjectindex[i]:(subjectindex[i+1]-1)], method = "trapezoid", sort = FALSE),
                          auc_effort = auc(data_ntlx$level[subjectindex[i]:(subjectindex[i+1]-1)],
                                           data_ntlx$effort[subjectindex[i]:(subjectindex[i+1]-1)], method = "trapezoid", sort = FALSE),
                          auc_frustration = auc(data_ntlx$level[subjectindex[i]:(subjectindex[i+1]-1)],
                                           data_ntlx$frustration[subjectindex[i]:(subjectindex[i+1]-1)], method = "trapezoid", sort = FALSE))
    ntlx <- rbind(ntlx, newdata)
    
  }
  
  # add column containing the average of the NASA-TLX subscale AUCs
  
  ntlx <- cbind(ntlx, auc_ntlx = rowMeans(ntlx[ ,grep("auc", colnames(ntlx))]))
  
  # merge data frames based on subject
  
  h3_data <- merge(h3_data, ntlx)
  
  # delete temporary data frame
  
  remove(ntlx, newdata)
  
  # compute multiple linear regression to predict NCS based on SV AUC and NASA-TLX AUC
  
  hypothesis3b <- summary(lm(h3_data$nfc ~ h3_data$axauc + h3_data$auc_ntlx))
  
  # get Bayes factor
  
  hypothesis3b_BF <- regressionBF(formula = nfc ~ axauc + auc_ntlx, data = h3_data, progress = FALSE)

```

When including the AUC of all NASA-TLX subscales as a predictor, it could explain variance in NFC beyond the one (not) explained by the SVs (`r apa_print(hypothesis3b)$statistic$modelfit$r2`, `r apa_print(hypothesis3b)$estimate$modelfit$r2`).
An increase in one NASA-TLX AUC value corresponded, on average, to a decrease of `r round(hypothesis3b$coefficients[2], digits = 1)` on the NFC scale (`r apa_print(hypothesis3b)$estimate$h3_data_auc_ntlx`).

\newpage

# Discussion

# (summary and interpretation of h2b_results)



# References

```{=tex}
\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
```
::: {#refs custom-style="Bibliography"}
:::

\newpage

# Acknowledgements

This research was partly funded by the German Research Foundation (DFG) as part of the Collaborative Research Center (CRC) 940.
The funders have/had no role in study design, data collection and analysis, decision to publish or preparation of the manuscript.

# Author Contributions


# Competing Interests

The authors declare no competing interests.

\newpage

# Figure Captions

\newpage

# Design Table

\newpage

# Supplement

## Results of the pilot study


### Hypothesis 1a: The signal detection measure d' declines with increasing n-back level.

ANOVA:

`r apa_print(hypothesis1a_rmanova)$full_result`

Paired contrasts:

`r hypothesis1a_contrasts`


### Hypothesis 1b: Reaction time increases with increasing n-back level.

ANOVA:

`r apa_print(hypothesis1b_rmanova)$full_result`

Paired contrasts:

`r hypothesis1b_contrasts`


### Hypothesis 1c: Ratings on all NASA-TLX dimensions increase with increasing n-back level.

Mental subscale ANOVA:

`r apa_print(hypothesis1c_mental_rmanova)$full_result`, $BF10=$ `r extractBF(hypothesis1c_mental_BF)$bf`

Mental subscale paired contrasts:

`r hypothesis1c_mental_contrasts`


Physical subscale ANOVA:

`r apa_print(hypothesis1c_physical_rmanova)$full_result`, $BF10=$ `r extractBF(hypothesis1c_physical_BF)$bf`

Physical subscale paired contrasts:

`r hypothesis1c_physical_contrasts`


Time subscale ANOVA:

`r apa_print(hypothesis1c_time_rmanova)$full_result`, $BF10=$ `r extractBF(hypothesis1c_time_BF)$bf`

Time subscale paired contrasts:

`r hypothesis1c_time_contrasts`


Performance subscale ANOVA:

`r apa_print(hypothesis1c_performance_rmanova)$full_result`, $BF10=$ `r extractBF(hypothesis1c_performance_BF)$bf`

Performance subscale paired contrasts:

`r hypothesis1c_performance_contrasts`


Effort subscale ANOVA:

`r apa_print(hypothesis1c_effort_rmanova)$full_result`, $BF10=$ `r extractBF(hypothesis1c_effort_BF)$bf`

Effort subscale paired contrasts:

`r hypothesis1c_effort_contrasts`


Frustration subscale ANOVA:

`r apa_print(hypothesis1c_frustration_rmanova)$full_result`, $BF10=$ `r extractBF(hypothesis1c_frustration_BF)$bf`

Frustration subscale paired contrasts:

`r hypothesis1c_frustration_contrasts`


### Hypothesis 2a: Subjective values decline with increasing n-back level.

ANOVA:

`r apa_print(hypothesis2a_rmanova)$full_result`, $BF10=$ `r extractBF(hypothesis2a_BF)$bf`

Paired contrasts:

`r hypothesis2a_contrasts`


### Hypothesis 2b: Subjective values decline with increasing n-back level, even after controlling for declining task performance measured by signal detection d’ and reaction time.

Multi level model:

`r table_1`


### Hypothesis 2c: Subjective values decline stronger with increasing task load for individuals with low compared to high NFC scores.

Simple slopes analysis:

`r h2b_ss.table`
`r h2b_ss.plot`

Johnson-Neyman intervals:

`r h2b_jn.int`


### Hypothesis 3a: Subjective values positively predict individual NCS scores.

Intercept:
`r apa_print(hypothesis3a)$estimate$Intercept`

Predictor $AxAUC$:
`r apa_print(hypothesis3a)$estimate$h3_data_axauc`

Fit:
`r apa_print(hypothesis3a)$estimate$modelfit$r2`

$BF10=$ `r extractBF(hypothesis3a_BF)$bf`


### Hypothesis 3b: NASA-TLX scores negatively predict individual NFC scores.

Intercept:
`r apa_print(hypothesis3b)$estimate$Intercept`

Predictor $AxAUC$:
`r apa_print(hypothesis3b)$estimate$h3_data_axauc`

Predictor AUC NASA-TLX:
`r apa_print(hypothesis3b)$estimate$h3_data_auc_ntlx`

Fit:
`r apa_print(hypothesis3a)$estimate$modelfit$r2`

$BF10=$ `r extractBF(hypothesis3b_BF)$bf`

\endgroup
