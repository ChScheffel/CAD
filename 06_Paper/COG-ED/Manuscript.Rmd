---
title             : "COG-ED Manuscript"
author            : "Josephine"
date              : "13 8 2021"
output            : html_document
bibliography      : ref_COG-ED.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(bibtex)
```

# Introduction

In everyday life, effort and reward are closely intertwined [@Botvinick2009].
With each decision a person makes, they have to evaluate whether the effort required to reach a goal is worth being exerted, given the reward they receive when reaching the goal.
A reward is subjectively more valuable if it is obtained with less effort, so the required effort is used as a reference point for estimating the reward value [@Botvinick2009].
However, the cost of the effort itself is also subjective, and research has not yet established which function best describes the relationship between effort and cost [@Kool2018].
Investigating effort and cost is challenging because “effort is not a property of the target task alone, but also a function of the individual’s cognitive capacities, as well as the degree of effort voluntarily mobilized for the task, which in turn is a function of the individual’s reward sensitivity” [@Kool2018, p. 209].

One task that is often used to investigate effort is the n-back task.
In this working memory task, a continuous stream of stimuli, e.g. letters, is presented on screen.
Participants indicate via button press whether the current stimulus is the same as *n* stimuli before, with *n* being the level of difficulty between one and six [@Mackworth1959]; and are asked to respond as quickly and as accurately as they can.
The n-back task requires simultaneous storage of past stimuli and processing of new stimuli [@Jonides1997].
It is well suited to investigate effort because it is an almost continuous manipulation of task load, as has been shown by monotonic increases in error rates and reaction times [@Jaeggi2010] as well as monotonic increases in brain activity in areas associated with working memory [@Jonides1997; @Owen2005].
However, reliability measures of the n-back task are mixed, presumably due to ceiling effects in performance in the easiest level [@Jaeggi2010].
Additionally, associations of n-back performance and measures such as executive functioning and fluid intelligence are often inconsistent [@Jaeggi2010].

A way to quantify the subjective cost of each n-back level has been developed by Westbrook, Kester, and Braver [-@Westbrook2013], called the Cognitive Effort Discounting Paradigm (COG-ED).
First, the participants complete the n-back levels to familiarize themselves with the task.
Then, level one is compared with each more difficult level by asking the participants to decide between receiving 2\$ for the more difficult level or 1\$ for level one.
If they choose the more difficult level, the reward for level one increases by 0.50\$, if the choose level one, it decreases by 0.50\$.
This is repeated five more times, with each adjustment of the level one reward being half as big as in the previous step, while the reward for the more difficult level remains fixed at 2\$.
The idea is to estimate the point of subjective equivalence, i.e. the monetary ratio in which both offers are equally preferred [@Westbrook2013]. 
The subjective value (SV) of each difficult level is then calculated by dividing the final reward value of level one by the fixed 2\$ reward of the more difficult level.
Westbrook et al. [-@Westbrook2013] used these SVs to investigate inter-individual differences in effort discounting (ED) by computing an area under the curve (AUC).
Younger participants showed lower ED, i.e. they needed a lower monetary incentive for choosing the more difficult levels over level one.

## Effort discounting and Need for Cognition 
The individual degree of ED in the study by Westbrook et al. [-@Westbrook2013] was also associated with the participants' Need for Cognition (NFC) score, a personality trait describing individuals who actively seek and enjoy effortful cognitive activities [@Cacioppo1982].
Westbrook et al. [-@Westbrook2013] conceptualized NFC as a trait measure of effortful task engagement, providing a subjective self-report of ED for each participant which could then be related to the SVs as an objective measure of ED.
On the surface, this association stands to reason, as individuals with higher NFC are more motivated to mobilize cognitive effort because they perceive it as intrinsically rewarding.
However, the relation of NFC and SVs might be confounded with task performance itself, since subjective task values have been shown to depend on both the exerted effort [@Wang2017] and the expected performance [@Yee2021].
Findings on NFC and n-back performance are heterogenous.
On one hand individuals with higher NFC neither had better n-back performance [@Gaertner2021] nor better working memory [@Fleischhauer 2010; @Hill2013], on the other hand they showed greater attention allocation [@Enge2008] and brain flexibility [@He2019].
Nevertheless, a possible association of NFC and task performance might be secondary, since task load has been shown to be a better predictor of SVs than task performance [@Culbreth2016; @Westbrook2013; @Westbrook2019].
But since other studies utilizing the COG-ED paradigm found the association of NFC and SVs to disappear after correcting for performance [@Kramer2021] or found no association of NFC and SVs at all [@Crawford2021], more research is needed to shed light on this issue.

## The present study
The present study contributes to the investigation of effort and SVs by changing one fundamental assumption of the original COG-ED paradigm: The assumption that the easiest n-back level has the highest SV.
We adapted the COG-ED paradigm in such a way that it allows the computation of SVs for different n-back levels without presuming that all individuals inherently prefer the easiest level (i.e., 1-back).
Additionally, our COG-ED adaptation allows the computations of SVs, even if the individual does not have a clear preference for one task level.
In the present study, we will validate this adaptation by replicating the findings of Westbrook et al. [-@Westbrook2013].
Furthermore, the COG-ED paradigm has been applied to tasks with different domains before, showing that SVs across task domains correlate [@Crawford2021].
However, these tasks had an objective order of task load in the form of increasing n-back levels or decreasing intensity of auditory signals.
In order to establish an ED paradigm for task varieties that do not have an objective order of task load, we will also apply the COG-ED adaption to a task with different emotion regulation strategies.


```{r libraries, echo=FALSE, message=FALSE, warning=FALSE}

  library(here)         # to set a directory without defined paths
  library(tidyverse)    # plotting and managing data
  

```

```{r import, echo=FALSE, message=FALSE, warning=FALSE}

  # set top level directory to source file

  here::i_am("Manuscript.Rmd")
  
  # import n-back and effort discounting data into a list each

  datalist_nback = lapply(list.files(here("Sampledata"), pattern = '.*nback.*csv', full.names = TRUE),
                          read.csv, stringsAsFactors = FALSE, header = TRUE)
  datalist_ED = lapply(list.files(here("Sampledata"), pattern = '.*_ED.*csv', full.names = TRUE),
                          read.csv, stringsAsFactors = FALSE, header = TRUE)
  
  # create empty data frames for loops to feed into
  
  data_nback <- data.frame(subject = character(), level = double(), target = character(),
                           response = character(), correct = double(), rt = double())
  data_ED <- data.frame(subject = character(), step = double(), choice = character(),
                           LBvalue = double(), LBlevel = double(), RBvalue = double(), RBlevel = double())

  
  # put relevant data into a dataframes
  
  for (i in 1:length(datalist_nback)) {
    
    newdata <- data.frame(datalist_nback[[i]][["Participant"]], datalist_nback[[i]][["currentlevel"]],
                          datalist_nback[[i]][["Stimulus"]], datalist_nback[[i]][["trial_resp.keys"]],
                          datalist_nback[[i]][["trial_resp.corr"]], datalist_nback[[i]][["trial_resp.rt"]])
    colnames(newdata) <- names(data_nback)
    data_nback <- rbind(data_nback, newdata)
  }
  
  for (i in 1:length(datalist_ED)) {
    
    newdata <- data.frame(datalist_ED[[i]][["Participant"]][2:length(datalist_ED[[i]][["Participant"]])],
                          datalist_ED[[i]][["EDround.thisN"]][2:length(datalist_ED[[i]][["EDround.thisN"]])],
                          datalist_ED[[i]][["EDclick.clicked_name"]][2:length(datalist_ED[[i]][["EDclick.clicked_name"]])],
                          datalist_ED[[i]][["EDleftbutton.value"]][2:length(datalist_ED[[i]][["EDleftbutton.value"]])],
                          datalist_ED[[i]][["EDleftbutton.nback"]][2:length(datalist_ED[[i]][["EDleftbutton.nback"]])],
                          datalist_ED[[i]][["EDrightbutton.value"]][2:length(datalist_ED[[i]][["EDrightbutton.value"]])],
                          datalist_ED[[i]][["EDrightbutton.nback"]][2:length(datalist_ED[[i]][["EDrightbutton.nback"]])])
    colnames(newdata) <- names(data_ED)
    data_ED <- rbind(data_ED, newdata)
  }
  
  # replace some columns with 'easy to work with' values
  
  # the target column will contain 1 for targets and 0 for all non-targets
  data_nback[data_nback == "Target"] <- 1
  data_nback[data_nback == "Pretarget"|data_nback == "Lure"|data_nback == "Distractor"] <- 0
  data_nback$target <- as.numeric(data_nback$target)
  # the response column will contain 1 for responses and 0 for all non-responses
  data_nback[data_nback == "left"|data_nback == "right"] <- 1
  data_nback[data_nback == "None"] <- 0
  data_nback$response <- as.numeric(data_nback$response)
  # the choice column will contain 1 for the left button and 2 for the right button
  data_ED[data_ED == "EDleftbutton"] <- 1
  data_ED[data_ED == "EDrightbutton"] <- 2
  data_ED$choice <- as.numeric(data_ED$choice)
  
  # since only the last choice of each comparison is relevant, we will keep only those rows
  
  data_ED <- data_ED[data_ED$step == 6,]
  data_ED <- subset(data_ED, select = -c(step))
  
  # import questionnaire data from RedCap
  
  data_quest <- read.csv(here("Sampledata","COGERED_DATA.csv"), stringsAsFactors = FALSE, header = TRUE)
  colnames(data_quest)[1] <- "set" # rename the first column

```

```{r SVcomputation, echo=FALSE, message=FALSE, warning=FALSE}

  # apply the addition or subtraction of 0.015625 to the last choices

  for (i in 1:nrow(data_ED)) {
    
    data_ED$fixedlevel[i] <- data_ED[i,grep("Bvalue", colnames(data_ED))[which(data_ED[i,grep("Bvalue", colnames(data_ED))] == 2.00)] + 1]
    data_ED$flexlevel[i] <- data_ED[i,grep("Bvalue", colnames(data_ED))[which(data_ED[i,grep("Bvalue", colnames(data_ED))] != 2.00)] + 1]
    
    if (data_ED$choice[i] == 1) {
      if (data_ED$LBvalue[i] == 2.00) {
        data_ED$flexvalue[i] <- round(data_ED$RBvalue[i] + 0.015625, digits = 2)
      } else {
        data_ED$flexvalue[i] <- round(data_ED$LBvalue[i] - 0.015625, digits = 2)
      }
    } else {
      if (data_ED$RBvalue[i] == 2.00) {
        data_ED$flexvalue[i] <- round(data_ED$LBvalue[i] + 0.015625, digits = 2)
      } else {
        data_ED$flexvalue[i] <- round(data_ED$RBvalue[i] - 0.015625, digits = 2)
      }
    }
    
  }

  # create vector indicating in which rows the data of a new subject begins

  subjectindex <- c(1,which(data_ED$subject != dplyr::lag(data_ED$subject)),nrow(data_ED))
  
  # create empty data frame for the loop to feed into
  
  data_SV <- data.frame(subject = character(), sv1 = double(), sv2 = double(), sv3 = double(), sv4 = double())
  
  # compute subjective values per n-back level and feed into data frame
  
  for (i in 1:(length(subjectindex)-1)) {
    
    # initialize empty vectors
    
    tempone <- double()
    temptwo <- double()
    tempthree <- double()
    tempfour <- double()
    
    # check for every number, whether it appears in the fixedlevel and flexlevel columns
    # divide flexvalue by 2 if it appears in the fixedlevel columns
    # append 1 if it appears in the flexlevel column
    
    # for 1-back
    
        if (is_empty(which(data_ED$fixedlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 1)) == FALSE) {
          tempone <- append(tempone, data_ED$flexvalue[subjectindex[i]-1 +
                                                         which(data_ED$fixedlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 1)]/2)
        } else {
          # do nothing
        }
        
        if (is_empty(which(data_ED$flexlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 1)) == FALSE) {
          tempone <- append(tempone, rep(1, length(which(data_ED$flexlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 1))))
        } else {
          # do nothing
        }
    
    # for 2-back
    
        if (is_empty(which(data_ED$fixedlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 2)) == FALSE) {
          temptwo <- append(temptwo, data_ED$flexvalue[subjectindex[i]-1 +
                                                         which(data_ED$fixedlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 2)]/2)
        } else {
          # do nothing
        }
        
        if (is_empty(which(data_ED$flexlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 2)) == FALSE) {
          temptwo <- append(temptwo, rep(1, length(which(data_ED$flexlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 2))))
        } else {
          # do nothing
        }
    
    # for 3-back
    
        if (is_empty(which(data_ED$fixedlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 3)) == FALSE) {
          tempthree <- append(tempthree, data_ED$flexvalue[subjectindex[i]-1 +
                                                             which(data_ED$fixedlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 3)]/2)
        } else {
          # do nothing
        }
        
        if (is_empty(which(data_ED$flexlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 3)) == FALSE) {
          tempthree <- append(tempthree, rep(1, length(which(data_ED$flexlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 3))))
        } else {
          # do nothing
        }
    
    # for 4-back
    
        if (is_empty(which(data_ED$fixedlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 4)) == FALSE) {
          tempfour <- append(tempfour, data_ED$flexvalue[subjectindex[i]-1 +
                                                           which(data_ED$fixedlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 4)]/2)
        } else {
          # do nothing
        }
        
        if (is_empty(which(data_ED$flexlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 4)) == FALSE) {
          tempfour <- append(tempfour, rep(1, length(which(data_ED$flexlevel[c(subjectindex[i]:(subjectindex[i+1]-1))] == 4))))
        } else {
          # do nothing
        }
    
    # put the mean subjective value of the three values per n-back level in the respective column and add to data frame
    
    newdata <- data.frame(data_ED$subject[subjectindex[i]], mean(tempone), mean(temptwo), mean(tempthree), mean(tempfour))
    colnames(newdata) <- names(data_SV)
    data_SV <- rbind(data_SV, newdata)
    
  }
  
  # remove temporary variables
  
  remove(tempone, temptwo, tempthree, tempfour)
  
```

```{r Hypothesis_1a, echo=FALSE, message=FALSE, warning=FALSE}

  # H1a: Performance measured by signal detection d’ declines with increasing n-back level.

  # set the number of targets and non-targets, so in case the paradigm will be changed it is easily accessible
  # they are multiplied by 2, because there are two runs per n-back level

  num_targets <- 16*2
  num_nontargets <- 48*2
  
  # compute index of rows in which the levels change
  
  levelindex <- c(1,which(data_nback$level != dplyr::lag(data_nback$level)),nrow(data_nback))
  
  # set up empty data frame for the loop to feed into
  
  dprime <- data.frame(subject = character(), level = double(), hitrate = double(), falsealarmrate = double())
  
  # calculate hits and false alarms per participant
  
  for (i in 1:(length(levelindex)-1)) {
    
    hits <- length(which(data_nback$target[c(levelindex[i]:(levelindex[i+1])-1)] == 1 &
                           data_nback$correct[c(levelindex[i]:(levelindex[i+1])-1)] == 1) + (levelindex[i]-1))
    falsealarms <- length(which(data_nback$target[c(levelindex[i]:(levelindex[i+1])-1)] == 0 &
                           data_nback$correct[c(levelindex[i]:(levelindex[i+1])-1)] == 0) + (levelindex[i]-1))
    newdata <- data.frame(subject = data_nback$subject[levelindex[i]],
                          level = data_nback$level[levelindex[i]],
                          hitrate = hits/num_targets,
                          falsealarmrate = falsealarms/num_nontargets)
    dprime <- rbind(dprime, newdata)
    
  }
  
  # z-transform the hit rate and the false alarm rate
  
  for (i in 1:4) {
    
    # calculate the mean and sd of hit rate and false alarm rate per n-back level i
    
    mean_hitrate <- mean(dprime$hitrate[dprime$level == i])
    sd_hitrate <- sd(dprime$hitrate[dprime$level == i])
    mean_falsealarmrate <- mean(dprime$falsealarmrate[dprime$level == i])
    sd_falsealarmrate <- sd(dprime$falsealarmrate[dprime$level == i])
    
    for (j in 1:length(which(dprime$level == i))) {
      
      # z-transform each subject j's hit rate and false alarm rate within the level i
      
      dprime$hitrate[which(dprime$level == i)[j]] <- (dprime$hitrate[which(dprime$level == i)[j]] - mean_hitrate)/sd_hitrate
      dprime$falsealarmrate[which(dprime$level == i)[j]] <- (dprime$falsealarmrate[which(dprime$level == i)[j]] -
                                                               mean_falsealarmrate)/sd_falsealarmrate
    }
  }
  
  # remove temporary variables
  
  remove(mean_hitrate, sd_hitrate, mean_falsealarmrate, sd_falsealarmrate)
  
  # calculate d'
  
  dprime$d <- dprime$hitrate - dprime$falsealarmrate
  
  # ANOVA with three linear contrasts, contrasting the d’ of two n-back levels (2,3,4) at a time
  
      # make a temporary copy of the dprime data frame without 1-back
      
      h1a_data <- dprime[dprime$level != 1,]
      h1a_data$level <- as.factor(h1a_data$level)
      
      # define contrasts
      
      contrasts(h1a_data$level) <- cbind(c(1,-1,0), c(0,1,-1), c(1,0,-1))
      
      # calculate ANOVA
      
      hypothesis1a_anova <- summary(aov(h1a_data$d ~ h1a_data$level))
      hypothesis1a_posthoc <- TukeyHSD(aov(h1a_data$d ~ h1a_data$level))
      remove(h1a_data)

```

```{r Hypothesis_1b, echo=FALSE, message=FALSE, warning=FALSE}

  # H1b: Performance measured by reaction time declines with increasing n-back level.
  
  # set up empty data frame for the loop to feed into
  
  rt <- data.frame(subject = character(), level = double(), meanrt = double())
  
  # calculate mean reaction time per participant per level
  
  for (i in 1:(length(levelindex)-1)) {
    
    meanrt <- mean(data_nback$rt[which(data_nback$correct[c(levelindex[i]:(levelindex[i+1])-1)] == 1)
                                 +(levelindex[i]-1)], na.rm = TRUE)
    
    newdata <- data.frame(subject = data_nback$subject[levelindex[i]],
                          level = data_nback$level[levelindex[i]],
                          meanrt = meanrt)
    rt <- rbind(rt, newdata)
    
  }

  # ANOVA with three linear contrasts, contrasting the mean rt of two n-back levels (2,3,4) at a time
  
      # make a temporary copy of the rt data frame without 1-back
      
      h1b_data <- rt[rt$level != 1,]
      h1b_data$level <- as.factor(h1b_data$level)
      
      # define contrasts
      
      contrasts(h1b_data$level) <- cbind(c(1,-1,0), c(0,1,-1), c(1,0,-1))
      
      # calculate ANOVA
      
      hypothesis1b_anova <- summary(aov(h1b_data$meanrt ~ h1b_data$level))
      hypothesis1b_posthoc <- TukeyHSD(aov(h1b_data$meanrt ~ h1b_data$level))
      remove(h1b_data)

```

```{r Hypothesis_1c, echo=FALSE, message=FALSE, warning=FALSE}

  # H1c: Ratings on all NTLX dimensions increase with increasing n-back level.

  # compute index of rows in which the data sets change
  
  setindex <- c(1,which(data_quest$set != dplyr::lag(data_quest$set)),nrow(data_quest))

  # set up empty data frame for the loop to feed into

  data_ntlx <- data.frame(subject = character(), level = double(),
                          mental = double(), physical = double(), time = double(),
                          performance = double(), effort = double(), frustration = double())
  
  # feed NTLX data per participant per level into data frame
  
  for (i in 1:(length(setindex)-1)) {
    
    for (j in 1:4) {
      
      newdata <- data.frame(subject = data_quest$subject[setindex[i]], level = j,
                            mental = data_quest$nasa_tlx_01[setindex[i]+j+2],
                            physical = data_quest$nasa_tlx_02[setindex[i]+j+2],
                            time = data_quest$nasa_tlx_03[setindex[i]+j+2],
                            performance = data_quest$nasa_tlx_04[setindex[i]+j+2],
                            effort = data_quest$nasa_tlx_05[setindex[i]+j+2],
                            frustration = data_quest$nasa_tlx_06[setindex[i]+j+2])
      data_ntlx <- rbind(data_ntlx, newdata)
    }
  }

  # six ANOVAs with six linear contrasts, contrasting the subscale scores of two n-back levels (1,2,3,4) at a time
  
      # make a temporary copy of the NTLX data frame
      
      h1c_data <- data_ntlx
      h1c_data$level <- as.factor(h1c_data$level)
      
      # define contrasts
      
      contrasts(h1c_data$level) <- cbind(c(1,-1,0,0), c(0,1,-1,0), c(0,0,1,-1),
                                         c(1,0,-1,0), c(1,0,0,-1), c(0,1,0,-1))
      
      # calculate ANOVAs
      
      hypothesis1c1_anova <- summary(aov(h1c_data$mental ~ h1c_data$level))
      hypothesis1c1_posthoc <- TukeyHSD(aov(h1c_data$mental ~ h1c_data$level))

      hypothesis1c2_anova <- summary(aov(h1c_data$physical ~ h1c_data$level))
      hypothesis1c2_posthoc <- TukeyHSD(aov(h1c_data$physical ~ h1c_data$level))

      hypothesis1c3_anova <- summary(aov(h1c_data$time ~ h1c_data$level))
      hypothesis1c3_posthoc <- TukeyHSD(aov(h1c_data$time ~ h1c_data$level))

      hypothesis1c4_anova <- summary(aov(h1c_data$performance ~ h1c_data$level))
      hypothesis1c4_posthoc <- TukeyHSD(aov(h1c_data$performance ~ h1c_data$level))

      hypothesis1c5_anova <- summary(aov(h1c_data$effort ~ h1c_data$level))
      hypothesis1c5_posthoc <- TukeyHSD(aov(h1c_data$effort ~ h1c_data$level))

      hypothesis1c6_anova <- summary(aov(h1c_data$frustration ~ h1c_data$level))
      hypothesis1c6_posthoc <- TukeyHSD(aov(h1c_data$frustration ~ h1c_data$level))

      remove(h1c_data)

```

```{r Hypothesis_2a, echo=FALSE, message=FALSE, warning=FALSE}

  # H2a: Subjective values decline with increasing n-back level.

# for each participant subjective values (SVs) for 1-, 2-, 3-, and 4-back will be calculated
# an ANOVA with six linear contrasts will be calculated, contrasting the SVs of two n-back levels at a time

```

```{r Hypothesis_2b, echo=FALSE, message=FALSE, warning=FALSE}

  # H2b: Subjective values decline with increasing n-back level, even after controlling for declining task
  # performance measured by signal detection d’ and reaction time.


```

```{r Hypothesis_3a, echo=FALSE, message=FALSE, warning=FALSE}

  # H3a: Subjective values predict individual NCS scores.

# for each participant subjective values for 1-, 2-, 3-, and 4-back will be calculated
# an area under the curve (AUC) will be calculated per participant
# regression
```

```{r Hypothesis_3b, echo=FALSE, message=FALSE, warning=FALSE}

  # H3b: NTLX scores do not predict individual NCS scores.

# per participant, calculate one AUC for each NTLX subscale, then average the AUC within each participant
# predictor 1 is NTLX-AUC, predictor 2 is SV-AUC
# multiple regression to predict NFC
```

```{r Hypothesis_3c, echo=FALSE, message=FALSE, warning=FALSE}

  # H3c: The NTLX dimensions effort and mental load predict individual NCS scores.

# repeat H3b analysis with only the effort NTLX subscale AUC, not the composite of all subscales
```

