---
title             : "When easy is not preferred: An effort discounting paradigm for estimating subjective values of tasks"
shorttitle        : "The CERED paradigm for estimating subjective values"
author: 
  - name          : "Josephine Zerna"
    orcid         : "0000-0003-2892-884X"
    affiliation   : "1"
    corresponding : yes
    address       : "Zellescher Weg 17, 01069 Dresden, Germany"
    email         : "josephine.zerna@tu-dresden.de"
    equal_contrib : yes
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - Conceptualization
      - Methodology
      - Funding acquisition
      - Formal analysis
      - Investigation
      - Project administration
      - Software
      - Visualization
      - Writing - original draft preparation
      - Writing - review & editing
  - name          : "Christoph Scheffel"
    orcid         : "0000-0001-5963-9229"
    affiliation   : "1"
    equal_contrib : yes
    role:
      - Conceptualization
      - Methodology
      - Funding acquisition
      - Investigation
      - Project administration
      - Software
      - Writing - review & editing
  - name          : "Corinna Kührt"
    orcid         : "0000-0002-6418-6479"
    affiliation   : "1"
    role:
      - Formal analysis
      - Writing - original draft preparation
      - Writing - review & editing
      - Visualization
  - name          : "Alexander Strobel"
    orcid         : "0000-0002-9426-5397"
    affiliation   : "1"
    role: 
      - Conceptualization
      - Funding acquistion
      - Writing - review & editing
affiliation:
  - id            : "1"
    institution   : "Faculty of Psychology, Technische Universität Dresden, 01069 Dresden, Germany"
authornote: |
abstract: |
  When individuals set goals, they consider the subjective value (SV) of the anticipated reward and the required effort, a trade-off that is of great interest to psychological research.
  One approach to quantify the SVs of levels of a cognitive task is the Cognitive Effort Discounting Paradigm by Westbrook and colleagues (2013).
  However, it fails to acknowledge the highly subjective nature of effort, as it assumes a unidirectional, inverse relationship between task load and SVs.
  Therefore, it cannot map differences in effort perception that arise from traits like Need for Cognition, since individuals who enjoy effortful cognitive activities likely do not prefer the easiest level.
  We aim to replicate the analysis of Westbrook and colleagues with our adaptation, the Cognitive and Emotion Regulation Effort Discounting paradigm, which quantifies SVs without assuming that the easiest level is preferred, thereby enabling the quantification of SVs for tasks without objective order of task load.
  
keywords          : "effort discounting, registered report, specification curve analysis, need for cognition, n-back"
wordcount         : "X"
bibliography      : CERED.bib
floatsintext      : yes
figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no
documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
csl               : nature.csl
always_allow_html : true
header-includes   :
    - \usepackage{booktabs}
    - \usepackage{longtable}
    - \usepackage{array}
    - \usepackage{multirow}
    - \usepackage{wrapfig}
    - \usepackage{float}
    - \usepackage{colortbl}
    - \usepackage{pdflscape}
    - \usepackage{tabu}
    - \usepackage{threeparttable}
    - \usepackage{threeparttablex}
    - \usepackage[normalem]{ulem}
    - \usepackage{makecell}
    - \usepackage{xcolor}
    - \usepackage{setspace}\doublespacing
    - \usepackage[final]{pdfpages}
    - \usepackage{chngcntr}

---
\renewcommand\thesection{\Alph{section}}
\counterwithout{figure}{section}
\setcounter{figure}{0}

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}

  # set the output for figures and tables to the width of the text throughout the entire script

  knitr::opts_chunk$set(out.width = "\\textwidth")

  # load libraries

  library(bibtex)       # for referencing, "bibtex" package
  library(here)         # for path independent file referencing, "here" package
  library(papaja)       # APA conform output, "papaja" package
  library(kableExtra)   # for great tables in R Markdown, "kableExtra" package
  library(interactions) # for simple slopes plots, "interactions" package
  library(BayesFactor)  # computing Bayes factors, "BayesFactor" package
  library(ggplot2)      # for plotting, "ggplot2" package
  library(egg)          # for paneling plots, "egg" package
  library(knitr)        # for including plots and such, "knitr" package
  library(effectsize)   # for effect sizes and CIs, "effectsize" package
  
  # set top level directory to source file

  here::i_am("flag_project_root_CERED.txt")
  
  # load the workspace variables that have been computed with the Analysis.R script
  
  load(here("06_Paper","COG-ED","Workspace.RData"))

```

# Introduction

In everyday life, effort and reward are closely intertwined [@Botvinick2009].
With each decision a person makes, they have to evaluate whether the effort required to reach a goal is worth being exerted, given the reward they receive when reaching the goal.
A reward is subjectively more valuable if it is obtained with less effort, so the required effort is used as a reference point for estimating the reward value [@Botvinick2009].
However, the cost of the effort itself is also subjective, and research has not yet established which function best describes the relationship between effort and cost [@Kool2018].
Investigating effort and cost is challenging because "effort is not a property of the target task alone, but also a function of the individual's cognitive capacities, as well as the degree of effort voluntarily mobilized for the task, which in turn is a function of the individual's reward sensitivity" (p. 209) [@Kool2018, p. 209].

One task that is often used to investigate effort is the *n*-back task, a working memory task in which a continuous stream of stimuli, e.g. letters, is presented on screen.
Participants indicate via button press whether the current stimulus is the same as *n* stimuli before, with *n* being the level of difficulty between one and six [@Mackworth1959].
The *n*-back task is well suited to investigate effort because it is an almost continuous manipulation of task load as has been shown by monotonic increases in error rates, reaction times [@Jaeggi2010], and brain activity in areas associated with working memory [@Jonides1997; @Owen2005].
However, its reliability measures are mixed, and associations of *n*-back performance and measures such as executive functioning and fluid intelligence are often inconsistent [@Jaeggi2010].

A way to quantify the subjective cost of each *n*-back level has been developed by Westbrook, Kester, and Braver [-@Westbrook2013], called the Cognitive Effort Discounting Paradigm (COG-ED).
First, the participants complete the *n*-back levels to familiarize themselves with the task.
Then, 1-back is compared with each more difficult level by asking the participants to decide between receiving 2\$ for the more difficult level or 1\$ for 1-back.
If they choose the more difficult level, the reward for 1-back increases by 0.50\$, if they choose 1-back, it decreases by 0.50\$.
This is repeated five more times, with each adjustment of the 1-back reward being half of the previous step, while the reward for the more difficult level remains fixed at 2\$.
The idea is to estimate the point of subjective equivalence, i.e., the monetary ratio at which both offers are equally preferred [@Westbrook2013].
The subjective value (SV) of each difficulty level is then calculated by dividing the final reward value of 1-back by the fixed 2\$ reward.
Westbrook et al. [-@Westbrook2013] used these SVs to investigate inter-individual differences in effort discounting.
Younger participants showed lower effort discounting, i.e., they needed a lower monetary incentive for choosing the more difficult levels over 1-back.

The individual degree of effort discounting in the study by Westbrook et al. [-@Westbrook2013] was also associated with the participants' scores in Need for Cognition (NFC), a personality trait describing an individual's tendency to actively seek out and enjoy effortful cognitive activities [@Cacioppo1982].
Westbrook et al. [-@Westbrook2013] conceptualized NFC as a trait measure of effortful task engagement, providing a subjective self-report of effort discounting for each participant which could then be related to the SVs as an objective measure of effort discounting.
On the surface, this association stands to reason, as individuals with higher NFC are more motivated to mobilize cognitive effort because they perceive it as intrinsically rewarding.
Additionally, it has been shown that individuals avoid cognitive effort only to a certain degree, possibly to retain a sense of self-control [@Wu2021], a trait more prominent in individuals with high NFC [@Bertrams2012; @Nishiguchi2016; @Xu2021].
However, the relation of NFC and SVs might be confounded, since other studies utilizing the COG-ED paradigm found the association of NFC and SVs to disappear after correcting for performance [@Kramer2021] or found no association of NFC and SVs at all [@Crawford2021].
On the other hand, task load has been shown to be a better predictor of SVs than task performance [@Culbreth2016; @Westbrook2013; @Westbrook2019], so more research is needed to shed light on this issue.

With the present study, we alter one fundamental assumption of the original COG-ED paradigm: that the easiest *n*-back level has the highest SV.
We therefore adapted the COG-ED paradigm in such a way that it allows the computation of SVs for different *n*-back levels without presuming that all individuals inherently prefer the easiest level.
Figure\ 1 illustrates how different modifications of the COG-ED paradigm return SVs that do or do not reflect the true preference of a hypothetical participant, who likes 2-back most, 3-back less, and 1-back least.
The COG-ED paradigm sets the SV of 1-back to 1, regardless of the response pattern.
Adding a comparison of 2-back and 3-back allows the SVs of those two levels to be more differentiated, but leaves the SV of 1-back unchanged.
Adding three more comparisons of the same levels but using the easier level as reference does approach the true preference, but has two disadvantages.
First, the SVs are still distorted by the SVs returned by the original paradigm, and second, having more task levels would lead to an exponential increase in comparisons.
Therefore, the solution lies in reducing the number of necessary comparisons by presenting only one effort discounting round for each possible pair of levels, and by starting each round with a choice between equal rewards.
For example, the participant is presented with the choice of receiving 1€ for 2-back or 1€ for 4-back.
The level chosen by the participant will then be used as the level with a flexible value, which starts at 1€ and is changed in every iteration.
The level that was not chosen will be set to a fixed value of 2€.
This procedure allows to compute SVs based on actual individual preference instead of objective task load.
Each level's SV is calculated as the mean of this level's SVs from all comparisons in which it appeared.
If the participant has a clear preference for one level, this level's SV will be 1.
If not, then no level's SV will be 1, but each level's SV can still be interpreted as an absolute and relative value, so each participant's effort discounting behaviour can still be quantified.
Since we also aim to establish this paradigm for the assessment of tasks with no objective task load, e.g., emotion regulation tasks<!-- perhaps add ref. to the other ms. on this issue? -->, we call it the Cognitive and Emotion Regulation Effort Discounting Paradigm (CERED). <!-- not sure whether you should call it like this; while it reflects the so-called "Entstehungszusammenhang", it does not necessarily reflect the so-called "Begründungszusammenhang", i.e., the proposed approach goes beyond emotion regulation -->
In the present study, we will validate the CERED paradigm by conceptually replicating the findings of Westbrook et al. [-@Westbrook2013].
Additionally, we will compare the effort discounting behavior of participants regarding the *n*-back task and an emotion regulation task.
The full results of the latter will be published in a second Registered Report<!-- again: add (interim) ref. -->.
The COG-ED paradigm has been applied to tasks in different domains before, showing that SVs across task domains correlate [@Crawford2021], but these tasks had an objective order of task load, which is not the case for the choice of emotion regulation strategies or other paradigms where there is no objective order of task load.

```{r figure1, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="An example for subjective values for an n-back task with three levels, returned by different modifications of the COG-ED paradigm for a hypothetical participant with the true preference 2-back > 3-back > 1-back. The grey boxes are the choice options shown to the participant. The participant's final reward value of the flexible level is displayed after the first arrow. The resulting subjective value of each level is displayed after the second arrow, in the notation \"SV 3-back(1-back)\" for the subjective value of 3-back when 1-back is the other choice. The Solution and Additional Benefit panel follow the same logic, but are preceded by a choice between equal rewards, and the participant's first choice indicated by an exclamation mark.", fig.pos="H"} 
  
  include_graphics(here("99_Thinktank", "Other", "Paradigm_Scheme.png"))

```

Our hypotheses were derived from the results of Westbrook et al. [-@Westbrook2013].
Regarding the associations of subjective and objective task load we hypothesize that (1a) the signal detection parameter *d'* declines with increasing *n*-back level, (1b) reaction time increases with increasing *n*-back level, and (1c) perceived task load increases with increasing *n*-back level.
Regarding the associations of task load and effort discounting we hypothesize that (2a) SVs decline with increasing *n*-back level, and (2b) they do so even after controlling for declining task performance.
A hypothesis that was not investigated in the original study is that (2c) SVs decline stronger with increasing task load for individuals with low compared to high NFC scores.
And regarding individual differences in effort discounting we hypothesize that (3a) SVs predict individual NFC scores, and (3b) perceived task load does not predict individual NFC scores.
Each hypothesis is detailed in the [Design Table](#DesignTableSection) in the Appendix.

# Methods

We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study [cf. @Simmons2012].
The paradigm was written and presented using *Psychopy* [@Peirce2019].
We used *R* with *R Studio* [@RCT2020; @RStudioTeam2020] with the main packages *afex* [@Singmann2021] and *BayesFactor* [@Morey2021] for all our analyses.

## Ethics information

The study protocol complies with all relevant ethical regulations and was approved by the ethics committee of the Technische Universität Dresden (reference number EK...).
Prior to testing, written informed consent will be obtained.
Participants will receive 30€ in total or course credit for participation.

## Pilot data

The sample of the pilot study consisted of $N=`r length(setindex)-1`$ participants (`r round((table(data_quest$gender)[2]/(length(setindex)-1))*100, digits = 1)`% female, $M=`r printnum(mean(data_quest[,"age"], na.rm = TRUE))`$ ($SD=`r printnum(sd(data_quest[,"age"], na.rm = TRUE))`$)\ years old).
One participant's data was removed because they misunderstood the instruction.
Due to a technical error the subjective task load data of one participant was incomplete, so the hypotheses involving the NASA Task Load Index were analyzed with $n=`r length(setindex)-2`$ data sets.
The results showed increases in subjective and objective task load measures with higher *n*-back level.
Importantly, SVs were lower for higher *n*-back levels, but not different between 1- and 2-back, which can be considered preliminary proof-of-concept, as this phenomon can only emerge in this version of the paradigm.
A multi-level model (MLM) revealed that *n*-back level was a reliable predictor of SV, even after controlling for declining task performance (d’ and RT) as well as correct and post-correct answers, while NFC was not, most likely due to the small sample size for individual differences analyses.
The specification curve analysis showed that this pattern was true for all 63 pipelines.
Finally, while the $AxAUC$ value did not predict any amount of variance in individual NFC scores, the $AUC$ of NASA-TLX scores did.
All results are detailed in the Supplementary Material.

## Design

Healthy participants aged 18 to 30\ years will be recruited using the software *ORSEE* [@Greiner2015].
Participants will complete the personality questionnaires online and then visit the lab for two sessions one week apart.
NFC will be assessed using the 16-item short form of the Need for Cognition Scale [@Cacioppo1984; @Bless1994].
Responses to each item (e.g., "Thinking is not my idea of fun", recoded) will be recorded on a 7-point Likert scale.
The NFC scale shows comparably high internal consistency (Cronbach's $\alpha>.80$) [@Bless1994; @Fleischhauer2010].
Several other personality questionnaires will be used in this study but are the topic of the Registered Report for the second lab session. <!-- again: add ref. -->
A full list of measures can be found in our [Github repository](https://github.com/ChScheffel/CERED).
In the first session, participants provide informed consent and demographic data before completing the computer-based paradigm.
The paradigm starts with the *n*-back levels one to four, presented sequentially with two runs per level, consisting of 64 consonants (16 targets, 48 non-targets) per run.
The levels are referred to by color (1-back black, 2-back red, 3-back blue, 4-back green) to avoid anchor effects in the effort discounting procedure.
To assess perceived task load, we will use the 6-item NASA Task Load Index (NASA-TLX) [@Hart1988], where participants evaluate their subjective perception of mental load, physical load, effort, frustration, performance, and time pressure during the task on a 20-point scale.
After each level, participants fill out the NASA-TLX on a tablet.
Then, they complete the effort discounting procedure on screen, where each possible pairing of the four *n*-back levels is presented in a randomized order.
Participants are instructed to decide as realistically as possible, because one of their choices from the last iteration steps will be randomly chosen for one final run of *n*-back.
This is only done to incentivise truthful behavior in the effort discounting procedure, so the *n*-back data of this part will not be analyzed.
The second session consists of an emotion regulation task with negative pictures and the instruction to suppress facial reactions, detach cognitively from the picture content, and distract oneself, respectively.
The paradigm follows the same structure of task and effort discounting procedure, but participants can decide which strategy they want to reapply in the last block.
Study data will be collected and managed using REDCap electronic data capture tools hosted at Technische Universität Dresden [@Harris2009; @Harris2019].

## Sampling plan

Sample size determination was mainly based on the results of the analyses of Westbrook et al. [-@Westbrook2013] (see [Design Table](#DesignTableSection)).
The hypothesis that yielded the largest necessary sample size was a repeated measures ANOVA with within-between interaction of NFC and *n*-back level influencing SVs.
Sample size analysis with *G\*Power* [@Faul2007; @Faul2009] indicated that we should collect data from at least 72 participants, assuming $\alpha=.05$ and $\beta=.95$.
However, the sample size analysis for the hypotheses of the second lab session revealed a larger necessary sample size of 85 participants to find an effect of $d=-0.32$ of emotion regulation on facial muscle activity with $\alpha=.05$ and $\beta=.95$.
To account for technical errors, noisy physiological data, or participants who indicate that they did not follow the instructions, we aim to collect about $50\%$ more data sets than necessary, $N=120$ in total.

## Analysis plan

Data collection and analysis will not be performed blind to the conditions of the experiments.
We will exclude the data of a participant from all analyses, if the participant states that they did not follow the instructions or if the investigator notes that the participant misunderstood the instructions.
No data will be replaced.
We aim to conduct all analysis as described in Westbrook et al. [-@Westbrook2013], but the level of detail was not always sufficient, so there might be deviations regarding data cleaning and degrees of freedom.
The performance measure *d'* will be computed as the difference of the *z*-transformed hit rate and the *z*-transformed false alarm rate [@Macmillan1990].
Reaction time (RT) data will be trimmed by excluding all trials with responses faster than 100\ ms, as the relevant cognitive processes cannot have been completed before [@Whelan2008; @Berger2021].
Aggregated RT values will be described using the median and the median of absolute deviation ($MAD$) as robust estimates of center and variability, respectively [@Lachaud2011].
Error- and post-error trials will be excluded in repeated measures analyses of variance (rmANOVA) and controlled for in an MLM, because RT on the latter is longer due to more cautious behavior [@Dutilh2012; @Houtman2012].
To test our hypotheses, we will perform a series of rmANOVAs and an MLM with orthogonal sum-to-zero contrasts in order to meaningfully interpret results [@Singmann2019]. 
Declining performance will be investigated by calculating an rmANOVA with three paired contrasts comparing *d'* between two levels of 2-, 3-, and 4-back at a time.
Another rmANOVA with three paired contrasts will be computed to compare the mean RT between two levels of 2-, 3-, and 4-back at a time.
To investigate changes in NASA-TLX ratings, six rmANOVAs will be computed, one for each NASA-TLX subscale, and each with six paired contrasts comparing the ratings between two levels of 1-, 2-, 3-, and 4-back at a time.
For each effort discounting round, SVs will be calculated by adding or subtracting 0.015625 from the last monetary value of the flexible level, depending on the participant's last choice.
This value is the result of dividing the first adjustment of 0.50€ by 2 five times, once in each effort discounting round.
Then, these final monetary values will be divided by 2€, and the SV of each level per participant will be computed by averaging all final values of each level, regardless of whether it was fixed or flexible.
An rmANOVA with six paired contrasts will be computed, comparing the SVs between two levels of 1-, 2-, 3-, and 4-back at a time.
Estimated marginal means will be used for the paired contrasts of each rmANOVA, including Tukey method for *p*-value adjustment.

To determine the influence of task performance on the association of SVs and *n*-back level, we will set up an MLM using the $lmerTest$ package [@Kuznetsova2017]. 
We will apply restricted maximum likelihood (REML) to fit the model.
As an effect size measure for random effects we will firstly calculate the intraclass correlation (ICC), which displays the proportion of variance that is explained by differences between persons.
Second, we will estimate a random slopes model of SVs including n-back level as level-1-predictor and, additionally, NFC as level-2-predictor. 
Within the model, we will control for *d'*, RT, correct, and post-correct trials.
$$
SV \sim level\ * NFC + d' + RT + correct + postcorrect + (level|subject)
$$
Level-1-predictors will be centered within cluster, whereas the level-2-predictor will be centered at the grand mean as recommended by Enders & Tofighi [-@Enders2007]. 
By this, the model yields interpretable parameter estimates. 
We will visually inspect the residuals of the final model.
The approximately normal distribution indicates no evidence to perform model criticism.  
As effect size measures, we calculate pseudo *R²* for our model and *f²* to estimate the effects of n-back level and NFC according to Lorah [-@Lorah2018].
Third, we will perform a simple slopes analysis with n-back level as predictor and NFC as moderator. 
To evaluate the moderating effect, we will calculate the Johnson-Neyman interval.
To ensure the validity of the MLM, we will conduct a specification curve analysis [@Simonsohn2020], which will include 63 possible preprocessing pipelines of the RT data.
These pipelines specify which transformation was applied (none, log, inverse, or square-root), which outliers were excluded (none, 2, 2.5, or 3\ $MAD$ from the median, RTs below 100\ or\ 200\ ms), and across which dimensions the transformations and exclusions were applied (across/within subjects and across/within *n*-back levels).
The MLM will be run with each of the 63\ pipelines, which will also include our main pipeline (untransformed data, exclusion of RTs below 100\ ms).
The ratio of pipelines that lead to significant versus non-significant effects will provide an indication of how robust the effect actually is.

The association of effort discounting and NFC will be examined with a regression using the $AUC$ of each participant's SVs to predict their NFC score.
A second regression will additionally include the mean of the NASA-TLX subscales' $AUCs$ of each participant as a predictor.
Since we do not have a fixed SV of 1 for 1-back, we cannot apply the computation of Westbrook et al. [-@Westbrook2013], which was the mean of the $AUCs$ of the SVs of each higher n-back level and 1-back, yielding values between 0\ and\ 1.
Consequently, we will choose a different way of quantifying the individual degree of effort discounting.
A classic $AUC$ cannot differentiate between a subject who prefers 1-back and a subject who prefers 4-back if the magnitude of the ascent is the same, but it can reflect the overall willingness to exert effort.
This is the opposite for the sum of the ascent between SVs.
Therefore, we multiply both indicators, arriving at a value reflecting both degree and direction of preference, called $AxAUC$.

The results of each analysis will be assessed on the basis of both $p$-value and the Bayes factor $BF10$, calculated with the *BayesFactor* package [@Morey2021] using the default prior widths of the functions *anovaBF*, *lmBF* and *regressionBF*.

## Data availability

The data of this study can be downloaded from [osf.io/vnj8x/](https://osf.io/vnj8x/).

## Code availability

The paradigm code as well as the R Markdown file used to analyze the data and write this document is available at [github.com/ChScheffel/CERED](https://github.com/ChScheffel/CERED).

\newpage

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup

\newpage

# Acknowledgements

This research is partly funded by the German Research Foundation (DFG) as part of the Collaborative Research Center (CRC) 940.
Additionally, we have applied for funding of the participants' compensation from centralized funds of the Faculty of Psychology at Technische Universität Dresden.
Applications for the centralized funds will be reviewed in May of 2022.
Regardless of whether or not this additional funding will be granted, the study can commence immediately.
The funders have/had no role in study design, data collection and analysis, decision to publish or preparation of the manuscript.


# Author Contributions

JZ, CS, and AS conceptualized the study and acquired funding.
JZ and CS developed the methodology, investigated, administered the project, and wrote the software.
JZ and CK did the formal analysis, visualized the results, and prepared the original draft.
All authors reviewed, edited, and approved the final version of the manuscript.


# Competing Interests

The authors declare no competing interests.

\newpage
\setcounter{figure}{0}

# Figures and figure Captions

```{r figure1appendix, echo=FALSE, message=FALSE, warning=FALSE}

  include_graphics(here("99_Thinktank", "Other", "Paradigm_Scheme.png"))

```

*Figure 1.* An example for subjective values for an n-back task with three levels, returned by different modifications of the COG-ED paradigm for a hypothetical participant with the true preference 2-back > 3-back > 1-back. The grey boxes are the choice options shown to the participant. The participant's final reward value of the flexible level is displayed after the first arrow. The resulting subjective value of each level is displayed after the second arrow, in the notation "SV 3-back(1-back)" for the subjective value of 3-back when 1-back is the other choice. The Solution and Additional Benefit panel follow the same logic, but are preceded by a choice between equal rewards, and the participant's first choice indicated by an exclamation mark.

\newpage

# Design Table {#DesignTableSection}

(Starts on next page)

\includepdf[pages={-},landscape=true]{Design_Table_T1.pdf}

\newpage

# Supplement

\counterwithin{figure}{section}
\counterwithin{table}{section}
\setcounter{section}{19}
\setcounter{figure}{0}
\setcounter{table}{0}

## Results of the pilot study


## Hypothesis 1a: The signal detection measure d' declines with increasing n-back level.

ANOVA:

`r apa_print(hypothesis1a_rmanova)$statistic`, $\eta_{p}^{2}=$ `r format(F_to_eta2(f = hypothesis1a_rmanova$anova_table[1,"F"], df = hypothesis1a_rmanova$anova_table[1,"num Df"], df_error = hypothesis1a_rmanova$anova_table[1,"den Df"]), digits = 2)[1,1]`, 95%\ CI `r format(F_to_eta2(f = hypothesis1a_rmanova$anova_table[1,"F"], df = hypothesis1a_rmanova$anova_table[1,"num Df"], df_error = hypothesis1a_rmanova$anova_table[1,"den Df"]), digits = 2)[1,2]`, $BF10=$ `r round(extractBF(hypothesis1a_BF)$bf, digits = 2)`

Paired contrasts:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
apa_table(
  hypothesis1a_contrasts,
  caption = "Paired contrasts for the rmANOVA comparing $d'$ between n-back levels",
  note = "The column Contrast contains the $n$ of the n-back levels. $SE$ = standard error, $df$ = degrees of freedom, $t$ = $t$-statistic, $p$ = $p$-value, CI = confidence interval.",
  escape = FALSE,
  placement = "H"
)
```

\newpage

## Hypothesis 1b: Reaction time increases with increasing n-back level.

ANOVA:

`r apa_print(hypothesis1b_rmanova)$statistic`, $\eta_{p}^{2}=$ `r format(F_to_eta2(f = hypothesis1b_rmanova$anova_table[1,"F"], df = hypothesis1b_rmanova$anova_table[1,"num Df"], df_error = hypothesis1b_rmanova$anova_table[1,"den Df"]), digits = 2)[1,1]`, 95%\ CI `r format(F_to_eta2(f = hypothesis1b_rmanova$anova_table[1,"F"], df = hypothesis1b_rmanova$anova_table[1,"num Df"], df_error = hypothesis1b_rmanova$anova_table[1,"den Df"]), digits = 2)[1,2]`, $BF10=$ `r round(extractBF(hypothesis1b_BF)$bf, digits = 2)`

Paired contrasts:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
apa_table(
  hypothesis1b_contrasts,
  caption = "Paired contrasts for the rmANOVA comparing reaction time between n-back levels",
  note = "The column Contrast contains the $n$ of the n-back levels. $SE$ = standard error, $df$ = degrees of freedom, $t$ = $t$-statistic, $p$ = $p$-value, CI = confidence interval.",
  escape = FALSE,
  placement = "H"
)
```

\newpage

## Hypothesis 1c: Ratings on all NASA-TLX dimensions increase with increasing n-back level.

Mental subscale ANOVA:

`r apa_print(hypothesis1c_mental_rmanova)$statistic`, $\eta_{p}^{2}=$ `r format(F_to_eta2(f = hypothesis1c_mental_rmanova$anova_table[1,"F"], df = hypothesis1c_mental_rmanova$anova_table[1,"num Df"], df_error = hypothesis1c_mental_rmanova$anova_table[1,"den Df"]), digits = 2)[1,1]`, 95%\ CI `r format(F_to_eta2(f = hypothesis1c_mental_rmanova$anova_table[1,"F"], df = hypothesis1c_mental_rmanova$anova_table[1,"num Df"], df_error = hypothesis1c_mental_rmanova$anova_table[1,"den Df"]), digits = 2)[1,2]`, $BF10=$ `r round(extractBF(hypothesis1c_mental_BF)$bf, digits = 2)`

Mental subscale paired contrasts:

```{r, echo=FALSE, message=FALSE, warning=FALSE} 
apa_table(
  hypothesis1c_mental_contrasts,
  caption = "Paired contrasts for the rmANOVA comparing ratings on the NASA-TLX Mental subscale between n-back levels",
  note = "The column Contrast contains the $n$ of the n-back levels. $SE$ = standard error, $df$ = degrees of freedom, $t$ = $t$-statistic, $p$ = $p$-value, CI = confidence interval.",
  escape = FALSE,
  placement = "H"
)
```

Physical subscale ANOVA:

`r apa_print(hypothesis1c_physical_rmanova)$statistic`, $\eta_{p}^{2}=$ `r format(F_to_eta2(f = hypothesis1c_physical_rmanova$anova_table[1,"F"], df = hypothesis1c_physical_rmanova$anova_table[1,"num Df"], df_error = hypothesis1c_physical_rmanova$anova_table[1,"den Df"]), digits = 2)[1,1]`, 95%\ CI `r format(F_to_eta2(f = hypothesis1c_physical_rmanova$anova_table[1,"F"], df = hypothesis1c_physical_rmanova$anova_table[1,"num Df"], df_error = hypothesis1c_physical_rmanova$anova_table[1,"den Df"]), digits = 2)[1,2]`, $BF10=$ `r round(extractBF(hypothesis1c_physical_BF)$bf, digits = 2)`

Physical subscale paired contrasts:

```{r, echo=FALSE, message=FALSE, warning=FALSE} 
apa_table(
  hypothesis1c_physical_contrasts,
  caption = "Paired contrasts for the rmANOVA comparing ratings on the NASA-TLX Physical subscale between n-back levels",
  note = "The column Contrast contains the $n$ of the n-back levels. $SE$ = standard error, $df$ = degrees of freedom, $t$ = $t$-statistic, $p$ = $p$-value, CI = confidence interval.",
  escape = FALSE,
  placement = "H"
)
```

Time subscale ANOVA:

`r apa_print(hypothesis1c_time_rmanova)$statistic`, $\eta_{p}^{2}=$ `r format(F_to_eta2(f = hypothesis1c_time_rmanova$anova_table[1,"F"], df = hypothesis1c_time_rmanova$anova_table[1,"num Df"], df_error = hypothesis1c_time_rmanova$anova_table[1,"den Df"]), digits = 2)[1,1]`, 95%\ CI `r format(F_to_eta2(f = hypothesis1c_time_rmanova$anova_table[1,"F"], df = hypothesis1c_time_rmanova$anova_table[1,"num Df"], df_error = hypothesis1c_time_rmanova$anova_table[1,"den Df"]), digits = 2)[1,2]`, $BF10=$ `r round(extractBF(hypothesis1c_time_BF)$bf, digits = 2)`

Time subscale paired contrasts:

```{r, echo=FALSE, message=FALSE, warning=FALSE} 
apa_table(
  hypothesis1c_time_contrasts,
  caption = "Paired contrasts for the rmANOVA comparing ratings on the NASA-TLX Time subscale between n-back levels",
  note = "The column Contrast contains the $n$ of the n-back levels. $SE$ = standard error, $df$ = degrees of freedom, $t$ = $t$-statistic, $p$ = $p$-value, CI = confidence interval.",
  escape = FALSE,
  placement = "H"
)
```

Performance subscale ANOVA:

`r apa_print(hypothesis1c_performance_rmanova)$statistic`, $\eta_{p}^{2}=$ `r format(F_to_eta2(f = hypothesis1c_performance_rmanova$anova_table[1,"F"], df = hypothesis1c_performance_rmanova$anova_table[1,"num Df"], df_error = hypothesis1c_performance_rmanova$anova_table[1,"den Df"]), digits = 2)[1,1]`, 95%\ CI `r format(F_to_eta2(f = hypothesis1c_performance_rmanova$anova_table[1,"F"], df = hypothesis1c_performance_rmanova$anova_table[1,"num Df"], df_error = hypothesis1c_performance_rmanova$anova_table[1,"den Df"]), digits = 2)[1,2]`, $BF10=$ `r round(extractBF(hypothesis1c_performance_BF)$bf, digits = 2)`

Performance subscale paired contrasts:

```{r, echo=FALSE, message=FALSE, warning=FALSE} 
apa_table(
  hypothesis1c_performance_contrasts,
  caption = "Paired contrasts for the rmANOVA comparing ratings on the NASA-TLX Performance subscale between n-back levels",
  note = "The column Contrast contains the $n$ of the n-back levels. $SE$ = standard error, $df$ = degrees of freedom, $t$ = $t$-statistic, $p$ = $p$-value, CI = confidence interval.",
  escape = FALSE,
  placement = "H"
)
```

Effort subscale ANOVA:

`r apa_print(hypothesis1c_effort_rmanova)$statistic`, $\eta_{p}^{2}=$ `r format(F_to_eta2(f = hypothesis1c_effort_rmanova$anova_table[1,"F"], df = hypothesis1c_effort_rmanova$anova_table[1,"num Df"], df_error = hypothesis1c_effort_rmanova$anova_table[1,"den Df"]), digits = 2)[1,1]`, 95%\ CI `r format(F_to_eta2(f = hypothesis1c_effort_rmanova$anova_table[1,"F"], df = hypothesis1c_effort_rmanova$anova_table[1,"num Df"], df_error = hypothesis1c_effort_rmanova$anova_table[1,"den Df"]), digits = 2)[1,2]`, $BF10=$ `r round(extractBF(hypothesis1c_effort_BF)$bf, digits = 2)`

Effort subscale paired contrasts:

```{r, echo=FALSE, message=FALSE, warning=FALSE} 
apa_table(
  hypothesis1c_effort_contrasts,
  caption = "Paired contrasts for the rmANOVA comparing ratings on the NASA-TLX Effort subscale between n-back levels",
  note = "The column Contrast contains the $n$ of the n-back levels. $SE$ = standard error, $df$ = degrees of freedom, $t$ = $t$-statistic, $p$ = $p$-value, CI = confidence interval.",
  escape = FALSE,
  placement = "H"
)
```

Frustration subscale ANOVA:

`r apa_print(hypothesis1c_frustration_rmanova)$statistic`, $\eta_{p}^{2}=$ `r format(F_to_eta2(f = hypothesis1c_frustration_rmanova$anova_table[1,"F"], df = hypothesis1c_frustration_rmanova$anova_table[1,"num Df"], df_error = hypothesis1c_frustration_rmanova$anova_table[1,"den Df"]), digits = 2)[1,1]`, 95%\ CI `r format(F_to_eta2(f = hypothesis1c_frustration_rmanova$anova_table[1,"F"], df = hypothesis1c_frustration_rmanova$anova_table[1,"num Df"], df_error = hypothesis1c_frustration_rmanova$anova_table[1,"den Df"]), digits = 2)[1,2]`, $BF10=$ `r round(extractBF(hypothesis1c_frustration_BF)$bf, digits = 2)`

Frustration subscale paired contrasts:

```{r, echo=FALSE, message=FALSE, warning=FALSE} 
apa_table(
  hypothesis1c_frustration_contrasts,
  caption = "Paired contrasts for the rmANOVA comparing ratings on the NASA-TLX Frustration subscale between n-back levels",
  note = "The column Contrast contains the $n$ of the n-back levels. $SE$ = standard error, $df$ = degrees of freedom, $t$ = $t$-statistic, $p$ = $p$-value, CI = confidence interval.",
  escape = FALSE,
  placement = "H"
)
```

\newpage

## Hypothesis 2a: Subjective values decline with increasing n-back level.

ANOVA:

`r apa_print(hypothesis2a_rmanova)$statistic`, $\eta_{p}^{2}=$ `r format(F_to_eta2(f = hypothesis2a_rmanova$anova_table[1,"F"], df = hypothesis2a_rmanova$anova_table[1,"num Df"], df_error = hypothesis2a_rmanova$anova_table[1,"den Df"]), digits = 2)[1,1]`, 95%\ CI `r format(F_to_eta2(f = hypothesis2a_rmanova$anova_table[1,"F"], df = hypothesis2a_rmanova$anova_table[1,"num Df"], df_error = hypothesis2a_rmanova$anova_table[1,"den Df"]), digits = 2)[1,2]`, $BF10=$ `r round(extractBF(hypothesis2a_BF)$bf, digits = 2)`

Paired contrasts:

```{r, echo=FALSE, message=FALSE, warning=FALSE} 
apa_table(
  hypothesis2a_contrasts,
  caption = "Paired contrasts for the rmANOVA comparing subjective values between n-back levels",
  note = "The column Contrast contains the $n$ of the n-back levels. $SE$ = standard error, $df$ = degrees of freedom, $t$ = $t$-statistic, $p$ = $p$-value, CI = confidence interval.",
  escape = FALSE,
  placement = "H"
)
```

\newpage

## Hypothesis 2b: Subjective values decline with increasing n-back level, even after controlling for declining task performance measured by signal detection d’ and reaction time.

Multi level model:

```{r,echo=FALSE, message=FALSE, warning=FALSE}
kable(h2b_result.table,
        caption = "Effects of n-back load level on subjective value controlled 
    for task performance (d' and reaction time), correct and postcorrect trials.",
        booktabs = T,                          # no vertical lines
        escape = F,                            # correctly print special characters)
        align = c("l",rep("r",7))) %>%         # right aligns the text in every numerical column
    kable_styling(latex_options = c("striped")) %>%
    footnote(general = "NFC = Need for Cognition, SE = standard error. ***$p$ < .001, **$p$ < .01, *$p$ < 0.5.",
             escape = F,                    # correctly print special characters
             threeparttable = T)            # line breaks in the footnote
```

The Bayes Factor $BF10$ of the multi level model approached infinity.

The conditional $R^2$ of the model describes the proportion of variance explained by both fixed and random effects, and is $R^2=$ `r format(h2b_total_r2[1,2], digits = 2)`.

The effect size is $f^2=$ `r format(h2b_f2, digits = 2)`.

\newpage

## Hypothesis 2c: Subjective values decline stronger with increasing task load for individuals with low compared to high NFC scores.

Simple slopes analysis:

```{r,echo=FALSE, message=FALSE, warning=FALSE}
kable(h2c_ss.table,
        caption = "Interaction between NFC and n-back load level.",
        # "Slopes of n-back level for different NFC values."
        booktabs = T,                          # no vertical lines
        escape = F,                            # correctly print special characters)
        align = c("l",rep("r",6))) %>%         # right aligns the text in every numerical column
    kable_styling(latex_options = c("striped")) %>%
    add_header_above(c(" " = 1, "Slopes of NFC" = 4, "Conditional Intercept" = 2)) %>%
    footnote(general = "NFC = Need for Cognition, SE = standard error. ***$p$ < .001, **$p$ < .01, *$p$ < 0.5.",
             escape = F,                    # correctly print special characters
             threeparttable = T)            # line breaks in the footnote
```

```{r FigHyp2c, echo=FALSE, message=FALSE, warning=FALSE, fig.cap=paste("Simple slopes analysis for how n-back level predicts the subjective value, depending on the participant's NFC. Slope of $1SD$ below the mean: $\\beta=$ ", round(m1_h2c.ss$slopes$Est.[1], digits = 2), ", $SE=$ ", round(m1_h2c.ss$slopes$S.E.[1], digits = 2), ", $p=$ ", round(m1_h2c.ss$slopes$p[1], digits = 3), ", slope of the mean: $\\beta=$ ", round(m1_h2c.ss$slopes$Est.[2], digits = 2), ", $SE=$ ", round(m1_h2c.ss$slopes$S.E.[2], digits = 2), ", $p=$ ", round(m1_h2c.ss$slopes$p[2], digits = 3), " slope of $1SD$ above the mean: $\\beta=$ ", round(m1_h2c.ss$slopes$Est.[3], digits = 2), ", $SE=$ ", round(m1_h2c.ss$slopes$S.E.[3], digits = 2), ", $p=$ ", round(m1_h2c.ss$slopes$p[3], digits = 3), ". NFC = Need for Cognition, SD = standard deviation.", sep=""), fig.pos="H"}

interact_plot(m1_h2b, pred = level.cwc, modx = nfc.cgm, centered = "none",
                               plot.points = TRUE, point.shape = TRUE,
                               x.label = "n-back level", y.label = "subjective value",
                               legend.main = "NFC", interval = TRUE) + theme_apa() +
scale_x_continuous(breaks = c(-1,0,1), labels = c("2","3","4"))
```

Johnson-Neyman interval: `r paste("[", round(h2c_jn.int[1], digits = 2), ", ", round(h2c_jn.int[2], digits = 2), "]", sep = "")`

Bayes Factor: $BF10=$ `r format(extractBF(h2c_BF)$bf, digits = 2)`

The effect size is $f^2=$ `r format(h2c_f2, digits = 2)`.

\newpage

## Specification curve analysis:

```{r FigSCA, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Results of the specification curve analysis for the multi level model. The upper panel shows the fixed effect estimates for Need for Cognition and n-back level as predictors of subjective values. Estimates with $p<.05$ are indicated by a dot on the line. $N=15$. The lower panel shows the preprocessing steps of each corresponding pipeline. The $BF10$ of each pipeline's multi level model approached infinity.", fig.pos="H"}

# create the upper panel first, which will show the estimates of 'level' and 'nfc'
  
  sca_upperplot <- ggplot(data = sca_results, aes(x = num, y = beta)) +
    geom_line(aes(group = predictor)) +
    geom_point(data = sca_results, aes(x = num, y = sign)) +
    geom_text(x = 3, y = -0.02, label = "NFC", size = 3) +
    geom_text(x = 3, y = -0.13, label = "Level", size = 3) +
    theme_classic() +
    labs(x = NULL, y = "Fixed effects\nestimate \u03b2") +
    scale_y_continuous(lim = c(NA,0.01)) +
    theme(axis.text.x = element_blank(),
          axis.line.y = element_line(size = 1, color = "black"), axis.title.y = element_text(margin = margin(r = 10)),
          legend.position = "none")

  # create the lower part of the plot that indicates the pipeline specifications
  
  sca_lowerplot <- ggplot(data = sca_results) +
    geom_hline(yintercept = c(1,6,11), color = "grey", size = 0.5) +
    geom_hline(yintercept = c(2:5,7:10,12:17), color = "grey", linetype = "dashed", size = 0.2) +
    geom_point(aes(x = num, y = Dim)) +
    geom_point(aes(x = num, y = Trans)) +
    geom_point(aes(x = num, y = Excl)) +
    theme_classic() +
    labs(x = "Analysis pipeline", y = NULL) +
    scale_y_reverse(breaks = c(1:17), lim = c(17,0.5), labels = c(expression(bold("Dimension")),
                                                                "Across S, across C", "Across S, within C",
                                                                "Within S, within C", "Within S, across C",
                                                                expression(bold("Transformation")),
                                                                "Raw/None", "Log", "Inverse", "Square-root",
                                                                expression(bold("Exclusion")),
                                                                "None", "2 MAD from median", " 2.5 MAD from median",
                                                                "3 MAD from median", "100ms after onset", "200ms after onset")) +
    theme(axis.text.x = element_blank(), axis.title.x = element_text(margin = margin(t = 10)),
          axis.line.y = element_line(size = 1, color = "black"),
          legend.position = "none")
  
  # put both plots into one
  
  ggarrange(sca_upperplot, sca_lowerplot, nrow = 2, heights = c(1,2.5))
  
```

\newpage

## Hypothesis 3a: Subjective values positively predict individual NCS scores.

Intercept:
`r apa_print(hypothesis3a)$estimate$Intercept`

Predictor $AxAUC$:
`r apa_print(hypothesis3a)$estimate$h3_data_axauc`

Fit:
`r apa_print(hypothesis3a)$estimate$modelfit$r2`

Effect size and confidence interval:

$\eta_{p}^{2}=$ `r format(F_to_eta2(f = hypothesis3a$fstatistic[1], df = hypothesis3a$fstatistic[2], df_error = hypothesis3a$fstatistic[3], ci = 0.95), digits = 2)[1,1]`, 95%\ CI `r format(F_to_eta2(f = hypothesis3a$fstatistic[1], df = hypothesis3a$fstatistic[2], df_error = hypothesis3a$fstatistic[3], ci = 0.95), digits = 2)[1,2]`

Bayes factor:

$BF10=$ `r extractBF(hypothesis3a_BF)$bf`

\newpage

## Hypothesis 3b: NASA-TLX scores negatively predict individual NFC scores.

Intercept:
`r apa_print(hypothesis3b)$estimate$Intercept`

Predictor $AxAUC$:
`r apa_print(hypothesis3b)$estimate$h3_data_axauc`

Predictor $AUC$ NASA-TLX:
`r apa_print(hypothesis3b)$estimate$h3_data_auc_ntlx`

Fit:
`r apa_print(hypothesis3b)$estimate$modelfit$r2`

Effect size and confidence interval:

$\eta_{p}^{2}=$ `r format(F_to_eta2(f = hypothesis3b$fstatistic[1], df = hypothesis3b$fstatistic[2], df_error = hypothesis3b$fstatistic[3], ci = 0.95), digits = 2)[1,1]`, 95%\ CI `r format(F_to_eta2(f = hypothesis3b$fstatistic[1], df = hypothesis3b$fstatistic[2], df_error = hypothesis3b$fstatistic[3], ci = 0.95), digits = 2)[1,2]`

Bayes factors:

$BF10=$ `r extractBF(hypothesis3b_BF)$bf[1]` for predictor $AxAUC$

$BF10=$ `r extractBF(hypothesis3b_BF)$bf[2]` for predictor $AUC$ NASA-TLX

